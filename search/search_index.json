{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Spatial-omics pipeline and analysis","text":"<p>Built on top of SpatialData, Sopa enables processing and analyses of image-based spatial-omics using a standard data structure and output. We currently support the following technologies: Xenium, MERSCOPE, CosMX, PhenoCycler, MACSIMA, Hyperion. Sopa was designed for generability and low memory consumption on large images (scales to <code>1TB+</code> images).</p> <p>The pipeline outputs contain: (i) Xenium Explorer files for interactive visualization, (ii) an HTML report for quick quality controls, and (iii) a SpatialData <code>.zarr</code> directory for further analyses.</p>"},{"location":"#overview","title":"Overview","text":"<p>The following illustration describes the main steps of <code>sopa</code>:</p> <p> </p>"},{"location":"#why-use-sopa","title":"Why use <code>sopa</code>","text":"<ul> <li><code>sopa</code> is designed to be memory-efficient, and it scales to large datasets with millions of cells</li> <li>Depending on your need, you can use our Snakemake pipeline, our CLI, or our API</li> <li>It's straightforward to move on to another spatial-omics technology since <code>sopa</code> is general to every image-based spatial-omics</li> <li>You can open any data with the Xenium Explorer, which is a user-friendly software with many functions</li> <li>Spatial statistics are optimized since geometric operations use <code>shapely</code> internally</li> <li>You can customize <code>sopa</code> and add your own segmentation or annotation tool if desired</li> <li><code>sopa</code> integrates naturally with other community tools such as Scanpy or Squidpy.</li> </ul>"},{"location":"cite_us/","title":"Cite us","text":"<p>Our article is not published yet. In the meantime, you can cite our preprint:</p> <pre><code>@article {Blampey2023.12.22.571863,\n    author = {Quentin Blampey &amp; Kevin Mulder et al.},\n    title = {Sopa: a technology-invariant pipeline for analyses of image-based spatial-omics},\n    elocation-id = {2023.12.22.571863},\n    year = {2023},\n    doi = {10.1101/2023.12.22.571863},\n    publisher = {Cold Spring Harbor Laboratory},\n    URL = {https://www.biorxiv.org/content/early/2023/12/23/2023.12.22.571863},\n    eprint = {https://www.biorxiv.org/content/early/2023/12/23/2023.12.22.571863.full.pdf},\n    journal = {bioRxiv}\n}\n</code></pre> <p>This library has been developed by Quentin Blampey, PhD student in Biomathematics / Deep Learning. The following institutions funded this work:</p> <ul> <li>Lab of Mathematics and Computer Science (MICS), CentraleSup\u00e9lec (Engineering School, Paris-Saclay University).</li> <li>PRISM center, Gustave Roussy Institute (Cancer campus, Paris-Saclay University).</li> </ul>"},{"location":"cli/","title":"CLI (command-line-interface)","text":""},{"location":"cli/#usage","title":"Usage","text":"<p>When installing <code>sopa</code> as written in our getting-started guidelines, a new command named <code>sopa</code> becomes available.</p> <p>CLI helper</p> <p>Run <code>sopa --help</code> to get details about all the command line purposes. You can also use this helper on any subcommand, for instance, <code>sopa read --help</code>.</p> <pre><code>// Run the Sopa CLI helper\n$ sopa --help\n Usage: sopa [OPTIONS] COMMAND [ARGS]...    \n\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 aggregate     Aggregate transcripts/channels inside cells      \u2502\n\u2502 annotate      Perform cell-type annotation                     \u2502\n\u2502 check         Run some sanity checks                           \u2502\n\u2502 crop          Crop an image based on a user-defined polygon    \u2502\n\u2502 explorer      Conversion to the Xenium Explorer's inputs       \u2502\n\u2502 patchify      Create patches with overlaps                     \u2502\n\u2502 read          Read any technology + write a SpatialData object \u2502\n\u2502 report        Create a web-report with figures/QCs             \u2502\n\u2502 resolve       Resolve the segmentation conflicts over patches  \u2502\n\u2502 segmentation  Perform cell segmentation on patches             \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n// Example: run cellpose segmentation\n$ sopa segmentation cellpose sdata.zarr\n... [Logs] ...\n</code></pre>"},{"location":"cli/#notes","title":"Notes","text":"<p>If you don't know in which order to run these commands, refer to the image in the homepage, or see our CLI usage tutorial.</p> <p>When running the <code>sopa</code> CLI, some arguments are required, while some are optional. For instance, for the <code>sopa read</code> command, <code>sdata_path</code> is an argument, and a path has to be given directly, while <code>technology</code> is an option (in this case, the <code>--technology</code> prefix has to be used). For instance, if you read MERSCOPE data, it will be:</p> <pre><code>sopa read /path/to/merscope/directory --technology merscope\n</code></pre> <p>Note that <code>/path/to/merscope/directory</code> refers to <code>sdata_path</code>, which is an argument. You should not add the suffix <code>--sdata_path</code>, as it is an argument.</p> <p>Required options</p> <p>All the arguments are required, as shown by the <code>[required]</code> hint on the CLI helper. Note that some options may also be required too (in this case, the term <code>[required]</code> will appear on the CLI helper). But they still need to be called as a normal option.</p>"},{"location":"cli/#sopa-commands","title":"<code>sopa</code> commands","text":"<p>Usage:</p> <pre><code>$ sopa [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>aggregate</code>: Create an <code>anndata</code> table containing the...</li> <li><code>annotate</code>: Perform cell-type annotation (based on...</li> <li><code>check</code>: Run some sanity checks (e.g., on the YAML...</li> <li><code>crop</code>: Crop an image based on a user-defined...</li> <li><code>explorer</code>: Convertion to the Xenium Explorer's...</li> <li><code>patchify</code>: Create patches with overlaps.</li> <li><code>read</code>: Read any technology data, and write a...</li> <li><code>report</code>: Create a HTML report of the pipeline run...</li> <li><code>resolve</code>: Resolve the segmentation conflicts over...</li> <li><code>segmentation</code>: Perform cell segmentation on patches.</li> </ul>"},{"location":"cli/#sopa-aggregate","title":"<code>sopa aggregate</code>","text":"<p>Create an <code>anndata</code> table containing the transcript count and/or the channel intensities per cell</p> <p>Usage:</p> <pre><code>$ sopa aggregate [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--gene-column TEXT</code>: Column of the transcript dataframe representing the gene names. If not provided, it will not compute transcript count</li> <li><code>--average-intensities / --no-average-intensities</code>: Whether to average the channel intensities inside each cell  [default: no-average-intensities]</li> <li><code>--expand-radius-ratio FLOAT</code>: Cells polygons will be expanded by <code>expand_radius_ratio * mean_radius</code> for channels averaging only. This help better aggregate boundary stainings  [default: 0]</li> <li><code>--min-transcripts INTEGER</code>: Cells with less transcript than this integer will be filtered  [default: 0]</li> <li><code>--min-intensity-ratio FLOAT</code>: Cells whose mean channel intensity is less than <code>min_intensity_ratio * quantile_90</code> will be filtered  [default: 0]</li> <li><code>--image-key TEXT</code>: Optional image key of the SpatialData object. By default, considers the only one image. It can be useful if another image is added later on</li> <li><code>--method-name TEXT</code>: If segmentation was performed with a generic method, this is the name of the method used.</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-annotate","title":"<code>sopa annotate</code>","text":"<p>Perform cell-type annotation (based on transcripts and/or channel intensities)</p> <p>Usage:</p> <pre><code>$ sopa annotate [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>fluorescence</code>: Simple annotation based on fluorescence,...</li> <li><code>tangram</code>: Tangram segmentation (i.e., uses an...</li> </ul>"},{"location":"cli/#sopa-annotate-fluorescence","title":"<code>sopa annotate fluorescence</code>","text":"<p>Simple annotation based on fluorescence, where each provided channel corresponds to one cell type.</p> <p>For each cell, one z-score statistic is computed and the population with the highest z-score is attributed.</p> <p>Usage:</p> <pre><code>$ sopa annotate fluorescence [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--marker-cell-dict TEXT</code>: [required]</li> <li><code>--cell-type-key TEXT</code>: Key added in <code>adata.obs</code> corresponding to the cell type  [default: cell_type]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-annotate-tangram","title":"<code>sopa annotate tangram</code>","text":"<p>Tangram segmentation (i.e., uses an annotated scRNAseq reference to transfer cell-types)</p> <p>Usage:</p> <pre><code>$ sopa annotate tangram [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--sc-reference-path TEXT</code>: Path to the scRNAseq annotated reference, as a <code>.h5ad</code> file  [required]</li> <li><code>--cell-type-key TEXT</code>: Key of <code>adata_ref.obs</code> containing the cell-types  [required]</li> <li><code>--reference-preprocessing TEXT</code>: Preprocessing method applied to the reference. Either None (raw counts), or <code>normalized</code> (sc.pp.normalize_total) or <code>log1p</code> (sc.pp.normalize_total and sc.pp.log1p)</li> <li><code>--bag-size INTEGER</code>: Number of cells in each bag of the spatial table. Low values will decrease the memory usage  [default: 10000]</li> <li><code>--max-obs-reference INTEGER</code>: Maximum samples to be considered in the reference for tangram. Low values will decrease the memory usage  [default: 10000]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-check","title":"<code>sopa check</code>","text":"<p>Run some sanity checks (e.g., on the YAML config, on the tangram reference, ...)</p> <p>Usage:</p> <pre><code>$ sopa check [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>config</code>: Perform sanity checks on a sopa yaml config</li> <li><code>reference</code>: Perform sanity checks on a tangram...</li> </ul>"},{"location":"cli/#sopa-check-config","title":"<code>sopa check config</code>","text":"<p>Perform sanity checks on a sopa yaml config</p> <p>Usage:</p> <pre><code>$ sopa check config [OPTIONS] PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>PATH</code>: Path to the YAML config  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-check-reference","title":"<code>sopa check reference</code>","text":"<p>Perform sanity checks on a tangram scRNAseq reference</p> <p>Usage:</p> <pre><code>$ sopa check reference [OPTIONS] REFERENCE_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>REFERENCE_PATH</code>: Path to the scRNAseq reference as a <code>.h5ad</code> file  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--cell-type-key TEXT</code>: Key of adata.obs containing the cell types  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-crop","title":"<code>sopa crop</code>","text":"<p>Crop an image based on a user-defined polygon (interactive mode).</p> <p>Usage</p> <ul> <li> <p>[Locally] Only <code>--sdata-path</code> is required</p> </li> <li> <p>[On a cluster] Run <code>sopa crop</code> with <code>--sdata-path</code> and <code>--intermediate-image</code> on the cluster. Then, download the image locally, and run <code>sopa crop</code> with <code>--intermediate-image</code> and <code>--intermediate-polygon</code>. Then, upload the polygon and run <code>sopa crop</code> on the cluster with <code>--sdata-path</code> and <code>--intermediate-polygon</code>.</p> </li> </ul> <p>Usage:</p> <pre><code>$ sopa crop [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--sdata-path TEXT</code>: Path to the SpatialData <code>.zarr</code> directory</li> <li><code>--intermediate-image TEXT</code>: Path to the intermediate image, with a <code>.zip</code> extension. Use this only if the interactive mode is not available</li> <li><code>--intermediate-polygon TEXT</code>: Path to the intermediate polygon, with a <code>.zip</code> extension. Use this locally, after downloading the intermediate_image</li> <li><code>--channels TEXT</code>: List of channel names to be displayed. Optional if there are already only 1 or 3 channels</li> <li><code>--scale-factor FLOAT</code>: Resize the image by this value (high value for a lower memory usage)  [default: 10]</li> <li><code>--margin-ratio FLOAT</code>: Ratio of the image margin on the display (compared to the image size)  [default: 0.1]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-explorer","title":"<code>sopa explorer</code>","text":"<p>Convertion to the Xenium Explorer's inputs, and image alignment</p> <p>Usage:</p> <pre><code>$ sopa explorer [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>add-aligned</code>: After alignment on the Xenium Explorer,...</li> <li><code>update-obs</code>: Update the cell categories for the Xenium...</li> <li><code>write</code>: Convert a spatialdata object to Xenium...</li> </ul>"},{"location":"cli/#sopa-explorer-add-aligned","title":"<code>sopa explorer add-aligned</code>","text":"<p>After alignment on the Xenium Explorer, add an image to the SpatialData object</p> <p>Usage:</p> <pre><code>$ sopa explorer add-aligned [OPTIONS] SDATA_PATH IMAGE_PATH TRANSFORMATION_MATRIX_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> <li><code>IMAGE_PATH</code>: Path to the image file to be added (<code>.ome.tif</code> used in the explorer during alignment)  [required]</li> <li><code>TRANSFORMATION_MATRIX_PATH</code>: Path to the <code>matrix.csv</code> file returned by the Explorer after alignment  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--original-image-key TEXT</code>: Optional original-image key (of sdata.images) on which the new image will be aligned. This doesn't need to be provided if there is only one image</li> <li><code>--overwrite / --no-overwrite</code>: Whether to overwrite the image if existing  [default: no-overwrite]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-explorer-update-obs","title":"<code>sopa explorer update-obs</code>","text":"<p>Update the cell categories for the Xenium Explorer's (i.e. what's in <code>adata.obs</code>). This is useful when you perform analysis and update your <code>AnnData</code> object</p> <p>Usage</p> <p>Make sure you have already run <code>sopa explorer write</code> before. This command should only be used if you updated <code>adata.obs</code></p> <p>Usage:</p> <pre><code>$ sopa explorer update-obs [OPTIONS] ADATA_PATH OUTPUT_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>ADATA_PATH</code>: Path to the anndata file (<code>zarr</code> or <code>h5ad</code>) containing the new observations  [required]</li> <li><code>OUTPUT_PATH</code>: Path to the Xenium Explorer directory (it will update <code>analysis.zarr.zip</code>)  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-explorer-write","title":"<code>sopa explorer write</code>","text":"<p>Convert a spatialdata object to Xenium Explorer's inputs</p> <p>Usage:</p> <pre><code>$ sopa explorer write [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--output-path TEXT</code>: Path to a directory where Xenium Explorer's outputs will be saved. By default, writes to the same path as <code>sdata_path</code> but with the <code>.explorer</code> suffix</li> <li><code>--gene-column TEXT</code>: Column name of the points dataframe containing the gene names</li> <li><code>--shapes-key TEXT</code>: Sdata key for the boundaries. By default, uses the baysor boundaires, else the cellpose boundaries</li> <li><code>--pixelsize FLOAT</code>: Number of microns in a pixel. Invalid value can lead to inconsistent scales in the Explorer.  [default: 0.2125]</li> <li><code>--lazy / --no-lazy</code>: If <code>True</code>, will not load the full images in memory (except if the image memory is below <code>ram_threshold_gb</code>)  [default: lazy]</li> <li><code>--ram-threshold-gb INTEGER</code>: Threshold (in gygabytes) from which image can be loaded in memory. If <code>None</code>, the image is never loaded in memory  [default: 4]</li> <li><code>--mode TEXT</code>: String that indicated which files should be created. <code>'-ib'</code> means everything except images and boundaries, while <code>'+tocm'</code> means only transcripts/observations/counts/metadata (each letter corresponds to one explorer file). By default, keeps everything</li> <li><code>--save-h5ad / --no-save-h5ad</code>: Whether to save the adata as h5ad in the explorer directory (for convenience only, since h5ad is faster to open than the original .zarr table)  [default: save-h5ad]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-patchify","title":"<code>sopa patchify</code>","text":"<p>Create patches with overlaps. Afterwards, segmentation will be run on each patch</p> <p>Usage:</p> <pre><code>$ sopa patchify [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>baysor</code>: Prepare the patches for Baysor segmentation</li> <li><code>image</code>: Prepare patches for staining-based...</li> </ul>"},{"location":"cli/#sopa-patchify-baysor","title":"<code>sopa patchify baysor</code>","text":"<p>Prepare the patches for Baysor segmentation</p> <p>Usage:</p> <pre><code>$ sopa patchify baysor [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--patch-width-microns FLOAT</code>: Width (and height) of each patch in microns  [required]</li> <li><code>--patch-overlap-microns FLOAT</code>: Number of overlapping microns between the patches. We advise to choose approximately twice the diameter of a cell  [required]</li> <li><code>--baysor-temp-dir TEXT</code>: Temporary directory where baysor inputs and outputs will be saved. By default, uses <code>.sopa_cache/baysor_boundaries</code></li> <li><code>--config-path TEXT</code>: Path to the baysor config (you can also directly provide the argument via the <code>config</code> option)</li> <li><code>--config TEXT</code>: Dictionnary of baysor parameters  [default: {}]</li> <li><code>--cell-key TEXT</code>: Optional column of the transcripts dataframe that indicates in which cell-id each transcript is, in order to use prior segmentation</li> <li><code>--unassigned-value INTEGER</code>: If --cell-key is provided, this is the value given to transcripts that are not inside any cell (if it's already 0, don't provide this argument)</li> <li><code>--use-prior / --no-use-prior</code>: Whether to use cellpose segmentation as a prior for baysor (if True, make sure to first run Cellpose)  [default: no-use-prior]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-patchify-image","title":"<code>sopa patchify image</code>","text":"<p>Prepare patches for staining-based segmentation (including Cellpose)</p> <p>Usage:</p> <pre><code>$ sopa patchify image [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--patch-width-pixel FLOAT</code>: Width (and height) of each patch in pixels  [default: 5000]</li> <li><code>--patch-overlap-pixel FLOAT</code>: Number of overlapping pixels between the patches. We advise to choose approximately twice the diameter of a cell  [default: 100]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-read","title":"<code>sopa read</code>","text":"<p>Read any technology data, and write a standardized SpatialData object.</p> <p>Either <code>--technology</code> or <code>--config-path</code> has to be provided.</p> <p>Usage:</p> <pre><code>$ sopa read [OPTIONS] DATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>DATA_PATH</code>: Path to one data sample (most of the time, this corresponds to a directory with images files and eventually a transcript file)  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--technology TEXT</code>: Name of the technology used to collected the data (<code>xenium</code>/<code>merfish</code>/<code>cosmx</code>/<code>phenocycler</code>/<code>macsima</code>/<code>hyperion</code>)</li> <li><code>--sdata-path TEXT</code>: Optional path to write the SpatialData object. If not provided, will write to the <code>{data_path}.zarr</code> directory</li> <li><code>--config-path TEXT</code>: Path to the snakemake config. This can be useful in order not to provide the <code>--technology</code> and the <code>--kwargs</code> arguments</li> <li><code>--kwargs TEXT</code>: Dictionary provided to the reader function as kwargs  [default: {}]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-report","title":"<code>sopa report</code>","text":"<p>Create a HTML report of the pipeline run and some quality controls</p> <p>Usage:</p> <pre><code>$ sopa report [OPTIONS] SDATA_PATH PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> <li><code>PATH</code>: Path to the HTML report  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-resolve","title":"<code>sopa resolve</code>","text":"<p>Resolve the segmentation conflicts over patches overlaps</p> <p>Usage:</p> <pre><code>$ sopa resolve [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>baysor</code>: Resolve patches conflicts after baysor...</li> <li><code>cellpose</code>: Resolve patches conflicts after cellpose...</li> <li><code>generic</code>: Resolve patches conflicts after generic...</li> </ul>"},{"location":"cli/#sopa-resolve-baysor","title":"<code>sopa resolve baysor</code>","text":"<p>Resolve patches conflicts after baysor segmentation. Provide either <code>--baysor-temp-dir</code> or <code>--patches-dirs</code></p> <p>Usage:</p> <pre><code>$ sopa resolve baysor [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--gene-column TEXT</code>: Column of the transcripts dataframe containing the genes names  [required]</li> <li><code>--baysor-temp-dir TEXT</code>: Path to the directory containing all the baysor patches (see <code>sopa patchify</code>). By default, uses the <code>.sopa_cache/baysor_boundaries</code> directory</li> <li><code>--min-area FLOAT</code>: Cells with an area less than this value (in microns^2) will be filtered  [default: 0]</li> <li><code>--patches-dirs TEXT</code>: List of patches directories inside <code>baysor_temp_dir</code></li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-resolve-cellpose","title":"<code>sopa resolve cellpose</code>","text":"<p>Resolve patches conflicts after cellpose segmentation</p> <p>Usage:</p> <pre><code>$ sopa resolve cellpose [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--patch-dir TEXT</code>: Directory containing the cellpose segmentation on patches (or multiple directories if using multi-step segmentation). By default, uses the <code>.sopa_cache/cellpose_boundaries</code> directory</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-resolve-generic","title":"<code>sopa resolve generic</code>","text":"<p>Resolve patches conflicts after generic segmentation</p> <p>Usage:</p> <pre><code>$ sopa resolve generic [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--method-name TEXT</code>: Name of the method used during segmentation. This is also the key correspnding to the boundaries in <code>sdata.shapes</code>  [required]</li> <li><code>--patch-dir TEXT</code>: Directory containing the generic segmentation on patches (or multiple directories if using multi-step segmentation). By default, uses the <code>.sopa_cache/&lt;method_name&gt;</code> directory</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-segmentation","title":"<code>sopa segmentation</code>","text":"<p>Perform cell segmentation on patches. NB: for <code>baysor</code>, use directly the <code>baysor</code> command line.</p> <p>Usage:</p> <pre><code>$ sopa segmentation [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>cellpose</code>: Perform cellpose segmentation.</li> <li><code>generic-staining</code>: Perform generic staining-based segmentation.</li> </ul>"},{"location":"cli/#sopa-segmentation-cellpose","title":"<code>sopa segmentation cellpose</code>","text":"<p>Perform cellpose segmentation. This can be done on all patches directly, or on one individual patch.</p> <p>Usage</p> <ul> <li> <p>[On one patch] Use this mode to run patches in parallel. Just provide <code>--patch-index</code> and <code>--patch-dir</code>. Note that <code>--patch-dir</code> will be used during <code>sopa resolve cellpose</code> afterwards.</p> </li> <li> <p>[On all patches at once] For small images, you can run cellpose sequentially (no need to run <code>sopa patchify</code>). You need to provide <code>--patch-width</code> and <code>--patch-overlap</code></p> </li> </ul> <p>Usage:</p> <pre><code>$ sopa segmentation cellpose [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--diameter FLOAT</code>: Cellpose diameter parameter  [required]</li> <li><code>--channels TEXT</code>: Names of the channels used for Cellpose. If one channel, then provide just a nucleus channel. If two channels, this is the nucleus and then the cytoplasm channel  [required]</li> <li><code>--flow-threshold FLOAT</code>: Cellpose <code>flow_threshold</code> parameter  [default: 2]</li> <li><code>--cellprob-threshold FLOAT</code>: Cellpose <code>cellprob_threshold</code> parameter  [default: -6]</li> <li><code>--model-type TEXT</code>: Name of the cellpose model  [default: cyto2]</li> <li><code>--min-area INTEGER</code>: Minimum area (in pixels^2) for a cell to be considered as valid  [default: 0]</li> <li><code>--clip-limit FLOAT</code>: Parameter for skimage.exposure.equalize_adapthist (applied before running cellpose)  [default: 0.2]</li> <li><code>--gaussian-sigma FLOAT</code>: Parameter for scipy gaussian_filter (applied before running cellpose)  [default: 1]</li> <li><code>--patch-index INTEGER</code>: Index of the patch on which cellpose should be run. NB: the number of patches is <code>len(sdata['sopa_patches'])</code></li> <li><code>--patch-dir TEXT</code>: Path to the temporary cellpose directory inside which we will store each individual patch segmentation. By default, saves into the <code>.sopa_cache/cellpose_boundaries</code> directory</li> <li><code>--patch-width INTEGER</code>: Ignore this if you already run <code>sopa patchify</code>. Patch width in pixels</li> <li><code>--patch-overlap INTEGER</code>: Ignore this if you already run <code>sopa patchify</code>. Patches overlaps in pixels</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-segmentation-generic-staining","title":"<code>sopa segmentation generic-staining</code>","text":"<p>Perform generic staining-based segmentation. This can be done on all patches directly, or on one individual patch.</p> <p>Usage</p> <p>First, define a new segmentation method, and write it under <code>sopa.segmentation.methods</code>. It should correspond to a function that is a \"callable builder\", i.e. kwargs will be provided to this function, and it will return a callable that will be applied on patches.</p> <p>As for Cellpose, two modes ara available:</p> <ul> <li> <p>[On one patch] Use this mode to run patches in parallel. Just provide <code>--patch-index</code> and <code>--patch-dir</code>. Note that <code>--patch-dir</code> will be used during <code>sopa resolve cellpose</code> afterwards.</p> </li> <li> <p>[On all patches at once] For small images, you can run the segmentation method sequentially (no need to run <code>sopa patchify</code>). You need to provide <code>--patch-width</code> and <code>--patch-overlap</code></p> </li> </ul> <p>Usage:</p> <pre><code>$ sopa segmentation generic-staining [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--method-name TEXT</code>: Name of the segmentation method builder to use. The corresponding function (<code>sopa.segmentation.methods.&lt;method_name&gt;</code>) will be used, and the kwargs below will be used to instantiate the method.  [required]</li> <li><code>--method-kwargs TEXT</code>: Kwargs for the method. This should be a dictionnary, in inline string format.  [default: {}]</li> <li><code>--channels TEXT</code>: Names of the channels used for segmentation.  [required]</li> <li><code>--min-area INTEGER</code>: Minimum area (in pixels^2) for a cell to be considered as valid  [default: 0]</li> <li><code>--clip-limit FLOAT</code>: Parameter for skimage.exposure.equalize_adapthist (applied before running the segmentation method)  [default: 0.2]</li> <li><code>--gaussian-sigma FLOAT</code>: Parameter for scipy gaussian_filter (applied before running the segmentation method)  [default: 1]</li> <li><code>--patch-index INTEGER</code>: Index of the patch on which the segmentation method should be run. NB: the number of patches is <code>len(sdata['sopa_patches'])</code></li> <li><code>--patch-dir TEXT</code>: Path to the temporary the segmentation method directory inside which we will store each individual patch segmentation. By default, saves into the <code>.sopa_cache/&lt;method_name&gt;</code> directory</li> <li><code>--patch-width INTEGER</code>: Ignore this if you already run <code>sopa patchify</code>. Patch width in pixels</li> <li><code>--patch-overlap INTEGER</code>: Ignore this if you already run <code>sopa patchify</code>. Patches overlaps in pixels</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"faq/","title":"Frequently asked questions","text":""},{"location":"faq/#what-kind-of-inputs-do-i-need-to-run-sopa","title":"What kind of inputs do I need to run Sopa?","text":"<p>You need the raw inputs of your machine, that is:</p> <ul> <li> <p>One or multiple image(s), usually corresponding to one or multiple <code>.tiff</code> file(s)</p> </li> <li> <p>Optionally, a file of transcript location, usually a <code>.csv</code> or <code>.parquet</code> file</p> </li> </ul> <p>In this documentation, <code>data_path</code> denotes the path to your raw data. Select the correct tab below to understand what is the right path to your raw data:</p> XeniumMERSCOPECosMXMACSimaPhenoCyclerHyperion <p><code>data_path</code> is the directory containing the following files: <code>morphology.ome.tif</code> and <code>transcripts.parquet</code></p> <p><code>data_path</code> is the \"region\" directory containing a <code>detected_transcripts.csv</code> file and an <code>image</code> directory. For instance, the directory can be called <code>region_0</code>.</p> <p>(The CosMX data requires stitching the FOVs. It will be added soon, see this issue)</p> <p><code>data_path</code> is the directory containing multiple <code>.ome.tif</code> files (one file per channel)</p> <p><code>data_path</code> corresponds to the path to one <code>.qptiff</code> file, or one <code>.tif</code> file (if exported from QuPath)</p> <p><code>data_path</code> is the directory containing multiple <code>.ome.tiff</code> files (one file per channel)</p>"},{"location":"faq/#cellpose-is-not-segmenting-enough-cells-what-should-i-do","title":"Cellpose is not segmenting enough cells; what should I do?","text":"<ul> <li>The main Cellpose parameter to check is <code>diameter</code>, i.e. a typical cell diameter in pixels. Note that this is highly specific to the technology you're using since the micron-to-pixel ratio can differ. We advise you to start with the default parameter for your technology of interest (see the <code>diameter</code> parameter inside our config files here).</li> <li>Maybe <code>min_area</code> is too high, and all the cells are filtered because they are smaller than this area. Remind that, when using Cellpose, the areas correspond to pixels^2.</li> <li>This can be due to a low image quality. If the image is too pixelated, consider increasing <code>gaussian_sigma</code> (e.g., <code>2</code>) under the cellpose parameters of our config. If the image has a low contrast, consider increasing <code>clip_limit</code> (e.g., <code>0.3</code>). These parameters are detailed in this example config.</li> <li>Consider updating the official Cellpose parameters. In particular, try <code>cellprob_threshold=-6</code> and <code>flow_threshold=2</code>.</li> </ul>"},{"location":"faq/#can-i-use-nextflow-instead-of-snakemake","title":"Can I use Nextflow instead of Snakemake?","text":"<p>Nextflow is not supported yet, but we are working on it. You can also help re-write our Snakemake pipeline for Nextflow (see issue #7).</p>"},{"location":"faq/#i-have-another-issue-how-do-i-fix-it","title":"I have another issue; how do I fix it?","text":"<p>Don't hesitate to open an issue on Sopa's Github repository, and detail your issue with as much precision as possible for the maintainers to be able to reproduce it.</p>"},{"location":"getting_started/","title":"Getting Started","text":""},{"location":"getting_started/#installation","title":"Installation","text":"<p>Sopa can be installed on every OS with <code>pip</code> or <code>poetry</code>.</p> <p>For now, <code>python==3.10</code> is required, but more versions will be supported soon.</p> <p>Advice (optional)</p> <p>We advise creating a new environment via a package manager (except if you use Poetry, which will automatically create the environment).</p> <p>For instance, you can create a new <code>conda</code> environment:</p> <pre><code>conda create --name sopa python=3.10\nconda activate sopa\n</code></pre> <p>Choose one of the following, depending on your needs (it should take at most a few minutes):</p> From PyPILocal install (pip)Poetry (dev mode) <pre><code>pip install sopa\n\n# or to install extras\npip install 'sopa[cellpose,baysor,tangram]'\n</code></pre> <pre><code>git clone https://github.com/gustaveroussy/sopa.git\ncd sopa\n\npip install .\n</code></pre> <pre><code>git clone https://github.com/gustaveroussy/sopa.git\ncd sopa\n\npoetry install --all-extras\n</code></pre> <p>Baysor usage</p> <p>Even though <code>pip install 'sopa[baysor]'</code> will install some dependencies related to baysor, you still have to install the <code>baysor</code> command line (see the official repository) if you want to use it.</p>"},{"location":"getting_started/#snakemake-setup","title":"Snakemake setup","text":"<p>To use the Snakemake pipeline, the installation process is slightly different because you'll need the whole repository.</p> <ol> <li> <p>Clone the <code>sopa</code> repository, and move to the root of the project: <pre><code>git clone https://github.com/gustaveroussy/sopa.git\ncd sopa\n</code></pre></p> </li> <li> <p>Create a <code>conda</code> environment called <code>sopa</code>: <pre><code>conda create --name sopa python=3.10\n</code></pre></p> </li> <li> <p>At the root of the <code>sopa</code> directory, install the package in dev mode, and choose the extras you want (among cellpose/baysor/tangram, depending on your desired usage): <pre><code>conda activate sopa\npip install -e \".[snakemake,cellpose,baysor,tangram]\"\n</code></pre></p> </li> </ol> <p>Now, follow our snakemake tutorial to run your first pipeline.</p> <p>Note</p> <p>You can also use a separate environment for <code>snakemake</code>. In this case, you don't need to install the <code>'snakemake'</code> extra when installing <code>sopa</code>. But you may still need to install other extras, for instance, <code>'cellpose'</code> if you plan to run Cellpose.</p>"},{"location":"getting_started/#usage","title":"Usage","text":"<p>Sopa comes in three different flavours, each corresponding to a different use case:</p> <ul> <li><code>Snakemake pipeline</code>: choose a config, and run our pipeline on your spatial data in a few minutes. See our snakemake tutorial.</li> <li><code>CLI</code>: use our command-line-interface to prototype quickly your own pipeline</li> <li><code>API</code>: use directly <code>sopa</code> as a Python package for full flexibility and customization (see a tutorial here)</li> </ul>"},{"location":"api/_sdata/","title":"sopa._sdata","text":"<p>Note</p> <p>These are convenient tools that operates on <code>SpatialData</code> objects</p>"},{"location":"api/_sdata/#sopa._sdata.get_boundaries","title":"<code>sopa._sdata.get_boundaries(sdata, return_key=False, warn=False)</code>","text":"<p>Gets the baysor boundaries or cellpose boundaries of a SpatialData object after running Sopa</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A SpatialData object</p> required <code>return_key</code> <code>bool</code> <p>Whether to return the key of the shapes or not.</p> <code>False</code> <code>warn</code> <code>bool</code> <p>If <code>True</code>, prints a warning if no boundary is found. Else, raises an error.</p> <code>False</code> <p>Returns:</p> Type Description <code>GeoDataFrame | tuple[str, GeoDataFrame] | None</code> <p>A <code>GeoDataFrame</code> containing the boundaries, or a tuple <code>(shapes_key, geo_df)</code></p> Source code in <code>sopa/_sdata.py</code> <pre><code>def get_boundaries(\n    sdata: SpatialData, return_key: bool = False, warn: bool = False\n) -&gt; gpd.GeoDataFrame | tuple[str, gpd.GeoDataFrame] | None:\n    \"\"\"Gets the baysor boundaries or cellpose boundaries of a SpatialData object after running Sopa\n\n    Args:\n        sdata: A SpatialData object\n        return_key: Whether to return the key of the shapes or not.\n        warn: If `True`, prints a warning if no boundary is found. Else, raises an error.\n\n    Returns:\n        A `GeoDataFrame` containing the boundaries, or a tuple `(shapes_key, geo_df)`\n    \"\"\"\n    for shapes_key in [SopaKeys.BAYSOR_BOUNDARIES, SopaKeys.CELLPOSE_BOUNDARIES]:\n        res = _try_get_boundaries(sdata, shapes_key, return_key)\n        if res is not None:\n            return res\n\n    error_message = \"sdata object has no cellpose boundaries and no baysor boundaries. Consider running segmentation first.\"\n\n    if not warn:\n        raise ValueError(error_message)\n\n    log.warn(error_message)\n    return (None, None) if return_key else None\n</code></pre>"},{"location":"api/_sdata/#sopa._sdata.get_intrinsic_cs","title":"<code>sopa._sdata.get_intrinsic_cs(sdata, element, name=None)</code>","text":"<p>Gets the name of the intrinsic coordinate system of an element</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A SpatialData object</p> required <code>element</code> <code>SpatialElement | str</code> <p><code>SpatialElement</code>, or its key</p> required <code>name</code> <code>str | None</code> <p>Name to provide to the intrinsic coordinate system if not existing. By default, uses the element id.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Name of the intrinsic coordinate system</p> Source code in <code>sopa/_sdata.py</code> <pre><code>def get_intrinsic_cs(\n    sdata: SpatialData, element: SpatialElement | str, name: str | None = None\n) -&gt; str:\n    \"\"\"Gets the name of the intrinsic coordinate system of an element\n\n    Args:\n        sdata: A SpatialData object\n        element: `SpatialElement`, or its key\n        name: Name to provide to the intrinsic coordinate system if not existing. By default, uses the element id.\n\n    Returns:\n        Name of the intrinsic coordinate system\n    \"\"\"\n    if name is None:\n        name = f\"_{element if isinstance(element, str) else id(element)}_intrinsic\"\n\n    if isinstance(element, str):\n        element = sdata[element]\n\n    for cs, transform in get_transformation(element, get_all=True).items():\n        if isinstance(transform, Identity):\n            return cs\n\n    set_transformation(element, Identity(), name)\n    return name\n</code></pre>"},{"location":"api/_sdata/#sopa._sdata.to_intrinsic","title":"<code>sopa._sdata.to_intrinsic(sdata, element, element_cs)</code>","text":"<p>Transforms a <code>SpatialElement</code> into the intrinsic coordinate system of another <code>SpatialElement</code></p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A SpatialData object</p> required <code>element</code> <code>SpatialElement | str</code> <p><code>SpatialElement</code> to transform, or its key</p> required <code>element_cs</code> <code>SpatialElement | str</code> <p><code>SpatialElement</code> of the target coordinate system, or its key</p> required <p>Returns:</p> Type Description <code>SpatialElement</code> <p>The <code>SpatialElement</code> after transformation in the target coordinate system</p> Source code in <code>sopa/_sdata.py</code> <pre><code>def to_intrinsic(\n    sdata: SpatialData, element: SpatialElement | str, element_cs: SpatialElement | str\n) -&gt; SpatialElement:\n    \"\"\"Transforms a `SpatialElement` into the intrinsic coordinate system of another `SpatialElement`\n\n    Args:\n        sdata: A SpatialData object\n        element: `SpatialElement` to transform, or its key\n        element_cs: `SpatialElement` of the target coordinate system, or its key\n\n    Returns:\n        The `SpatialElement` after transformation in the target coordinate system\n    \"\"\"\n    if isinstance(element, str):\n        element = sdata[element]\n    cs = get_intrinsic_cs(sdata, element_cs)\n    return sdata.transform_element_to_coordinate_system(element, cs)\n</code></pre>"},{"location":"api/_sdata/#sopa._sdata.get_intensities","title":"<code>sopa._sdata.get_intensities(sdata)</code>","text":"<p>Gets the intensity dataframe of shape <code>n_obs x n_channels</code></p> Source code in <code>sopa/_sdata.py</code> <pre><code>def get_intensities(sdata: SpatialData) -&gt; pd.DataFrame | None:\n    \"\"\"Gets the intensity dataframe of shape `n_obs x n_channels`\"\"\"\n    if not sdata.table.uns[SopaKeys.UNS_KEY][SopaKeys.UNS_HAS_INTENSITIES]:\n        return None\n\n    if sdata.table.uns[SopaKeys.UNS_KEY][SopaKeys.UNS_HAS_TRANSCRIPTS]:\n        return sdata.table.obsm[SopaKeys.INTENSITIES_OBSM]\n\n    return sdata.table.to_df()\n</code></pre>"},{"location":"api/_sdata/#sopa._sdata.iter_scales","title":"<code>sopa._sdata.iter_scales(image)</code>","text":"<p>Iterates through all the scales of a <code>MultiscaleSpatialImage</code></p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>MultiscaleSpatialImage</code> <p>a <code>MultiscaleSpatialImage</code></p> required <p>Yields:</p> Type Description <code>DataArray</code> <p>Each scale (as a <code>xr.DataArray</code>)</p> Source code in <code>sopa/_sdata.py</code> <pre><code>def iter_scales(image: MultiscaleSpatialImage) -&gt; Iterator[xr.DataArray]:\n    \"\"\"Iterates through all the scales of a `MultiscaleSpatialImage`\n\n    Args:\n        image: a `MultiscaleSpatialImage`\n\n    Yields:\n        Each scale (as a `xr.DataArray`)\n    \"\"\"\n    assert isinstance(\n        image, MultiscaleSpatialImage\n    ), f\"Multiscale iteration is reserved for type MultiscaleSpatialImage. Found {type(image)}\"\n\n    for scale in image:\n        yield next(iter(image[scale].values()))\n</code></pre>"},{"location":"api/_sdata/#sopa._sdata.get_spatial_image","title":"<code>sopa._sdata.get_spatial_image(sdata, key=None, return_key=False)</code>","text":"<p>Gets a SpatialImage from a SpatialData object (if the image has multiple scale, the <code>scale0</code> is returned)</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>SpatialData object.</p> required <code>key</code> <code>str | None</code> <p>Optional image key. If <code>None</code>, returns the only image (if only one), or raises an error.</p> <code>None</code> <code>return_key</code> <code>bool</code> <p>Whether to also return the key of the image.</p> <code>False</code> <p>Returns:</p> Type Description <code>SpatialImage | tuple[str, SpatialImage]</code> <p>If <code>return_key</code> is False, only the image is returned, else a tuple <code>(image_key, image)</code></p> Source code in <code>sopa/_sdata.py</code> <pre><code>def get_spatial_image(\n    sdata: SpatialData, key: str | None = None, return_key: bool = False\n) -&gt; SpatialImage | tuple[str, SpatialImage]:\n    \"\"\"Gets a SpatialImage from a SpatialData object (if the image has multiple scale, the `scale0` is returned)\n\n    Args:\n        sdata: SpatialData object.\n        key: Optional image key. If `None`, returns the only image (if only one), or raises an error.\n        return_key: Whether to also return the key of the image.\n\n    Returns:\n        If `return_key` is False, only the image is returned, else a tuple `(image_key, image)`\n    \"\"\"\n    key = get_key(sdata, \"images\", key)\n\n    assert key is not None, \"One image in `sdata.images` is required\"\n\n    image = sdata.images[key]\n    if isinstance(image, MultiscaleSpatialImage):\n        image = SpatialImage(next(iter(image[\"scale0\"].values())))\n\n    if return_key:\n        return key, image\n    return image\n</code></pre>"},{"location":"api/io.explorer/","title":"sopa.io.explorer","text":""},{"location":"api/io.explorer/#sopa.io.explorer.write","title":"<code>sopa.io.explorer.write(path, sdata, image_key=None, shapes_key=None, points_key=None, gene_column=None, pixelsize=0.2125, layer=None, polygon_max_vertices=13, lazy=True, ram_threshold_gb=4, mode=None, save_h5ad=False)</code>","text":"<p>Transform a SpatialData object into inputs for the Xenium Explorer. After running this function, double-click on the <code>experiment.xenium</code> file to open it.</p> <p>Software download</p> <p>Make sure you have the latest version of the Xenium Explorer</p> Note <p>This function will create up to 7 files, depending on the <code>SpatialData</code> object and the arguments:</p> <ul> <li> <p><code>experiment.xenium</code> contains some experiment metadata. Double-click on this file to open the Xenium Explorer. This file can also be created with <code>write_metadata</code>.</p> </li> <li> <p><code>morphology.ome.tif</code> is the primary image. This file can also be created with <code>write_image</code>. Add more images with <code>align</code>.</p> </li> <li> <p><code>analysis.zarr.zip</code> contains the cells categories (or clusters), i.e. <code>adata.obs</code>. This file can also be created with <code>write_cell_categories</code>.</p> </li> <li> <p><code>cell_feature_matrix.zarr.zip</code> contains the cell-by-gene counts. This file can also be created with <code>write_gene_counts</code>.</p> </li> <li> <p><code>cells.zarr.zip</code> contains the cells polygon boundaries. This file can also be created with <code>write_polygons</code>.</p> </li> <li> <p><code>transcripts.zarr.zip</code> contains transcripts locations. This file can also be created with <code>write_transcripts</code>.</p> </li> <li> <p><code>adata.h5ad</code> is the <code>AnnData</code> object from the <code>SpatialData</code>. This is not used by the Explorer, but only saved for convenience.</p> </li> </ul> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the directory where files will be saved.</p> required <code>sdata</code> <code>SpatialData</code> <p>SpatialData object.</p> required <code>image_key</code> <code>str | None</code> <p>Name of the image of interest (key of <code>sdata.images</code>).</p> <code>None</code> <code>shapes_key</code> <code>str | None</code> <p>Name of the cell shapes (key of <code>sdata.shapes</code>).</p> <code>None</code> <code>points_key</code> <code>str | None</code> <p>Name of the transcripts (key of <code>sdata.points</code>).</p> <code>None</code> <code>gene_column</code> <code>str | None</code> <p>Column name of the points dataframe containing the gene names.</p> <code>None</code> <code>pixelsize</code> <code>float</code> <p>Number of microns in a pixel. Invalid value can lead to inconsistent scales in the Explorer.</p> <code>0.2125</code> <code>layer</code> <code>str | None</code> <p>Layer of <code>sdata.table</code> where the gene counts are saved. If <code>None</code>, uses <code>sdata.table.X</code>.</p> <code>None</code> <code>polygon_max_vertices</code> <code>int</code> <p>Maximum number of vertices for the cell polygons.</p> <code>13</code> <code>lazy</code> <code>bool</code> <p>If <code>True</code>, will not load the full images in memory (except if the image memory is below <code>ram_threshold_gb</code>).</p> <code>True</code> <code>ram_threshold_gb</code> <code>int | None</code> <p>Threshold (in gygabytes) from which image can be loaded in memory. If <code>None</code>, the image is never loaded in memory.</p> <code>4</code> <code>mode</code> <code>str</code> <p>string that indicated which files should be created. \"-ib\" means everything except images and boundaries, while \"+tocm\" means only transcripts/observations/counts/metadata (each letter corresponds to one explorer file). By default, keeps everything.</p> <code>None</code> <code>save_h5ad</code> <code>bool</code> <p>Whether to save the adata as h5ad in the explorer directory (for convenience only, since h5ad is faster to open than the original .zarr table)</p> <code>False</code> Source code in <code>sopa/io/explorer/converter.py</code> <pre><code>def write(\n    path: str,\n    sdata: SpatialData,\n    image_key: str | None = None,\n    shapes_key: str | None = None,\n    points_key: str | None = None,\n    gene_column: str | None = None,\n    pixelsize: float = 0.2125,\n    layer: str | None = None,\n    polygon_max_vertices: int = 13,\n    lazy: bool = True,\n    ram_threshold_gb: int | None = 4,\n    mode: str = None,\n    save_h5ad: bool = False,\n) -&gt; None:\n    \"\"\"\n    Transform a SpatialData object into inputs for the Xenium Explorer.\n    After running this function, double-click on the `experiment.xenium` file to open it.\n\n    !!! note \"Software download\"\n        Make sure you have the latest version of the [Xenium Explorer](https://www.10xgenomics.com/support/software/xenium-explorer)\n\n    Note:\n        This function will create up to 7 files, depending on the `SpatialData` object and the arguments:\n\n        - `experiment.xenium` contains some experiment metadata. Double-click on this file to open the Xenium Explorer. This file can also be created with [`write_metadata`](./#sopa.io.explorer.write_metadata).\n\n        - `morphology.ome.tif` is the primary image. This file can also be created with [`write_image`](./#sopa.io.explorer.write_image). Add more images with `align`.\n\n        - `analysis.zarr.zip` contains the cells categories (or clusters), i.e. `adata.obs`. This file can also be created with [`write_cell_categories`](./#sopa.io.explorer.write_cell_categories).\n\n        - `cell_feature_matrix.zarr.zip` contains the cell-by-gene counts. This file can also be created with [`write_gene_counts`](./#sopa.io.explorer.write_gene_counts).\n\n        - `cells.zarr.zip` contains the cells polygon boundaries. This file can also be created with [`write_polygons`](./#sopa.io.explorer.write_polygons).\n\n        - `transcripts.zarr.zip` contains transcripts locations. This file can also be created with [`write_transcripts`](./#sopa.io.explorer.write_transcripts).\n\n        - `adata.h5ad` is the `AnnData` object from the `SpatialData`. This is **not** used by the Explorer, but only saved for convenience.\n\n    Args:\n        path: Path to the directory where files will be saved.\n        sdata: SpatialData object.\n        image_key: Name of the image of interest (key of `sdata.images`).\n        shapes_key: Name of the cell shapes (key of `sdata.shapes`).\n        points_key: Name of the transcripts (key of `sdata.points`).\n        gene_column: Column name of the points dataframe containing the gene names.\n        pixelsize: Number of microns in a pixel. Invalid value can lead to inconsistent scales in the Explorer.\n        layer: Layer of `sdata.table` where the gene counts are saved. If `None`, uses `sdata.table.X`.\n        polygon_max_vertices: Maximum number of vertices for the cell polygons.\n        lazy: If `True`, will not load the full images in memory (except if the image memory is below `ram_threshold_gb`).\n        ram_threshold_gb: Threshold (in gygabytes) from which image can be loaded in memory. If `None`, the image is never loaded in memory.\n        mode: string that indicated which files should be created. \"-ib\" means everything except images and boundaries, while \"+tocm\" means only transcripts/observations/counts/metadata (each letter corresponds to one explorer file). By default, keeps everything.\n        save_h5ad: Whether to save the adata as h5ad in the explorer directory (for convenience only, since h5ad is faster to open than the original .zarr table)\n    \"\"\"\n    path: Path = Path(path)\n    _check_explorer_directory(path)\n\n    image_key, image = get_spatial_image(sdata, image_key, return_key=True)\n\n    ### Saving cell categories and gene counts\n    if sdata.table is not None:\n        adata = sdata.table\n\n        shapes_key = adata.uns[\"spatialdata_attrs\"][\"region\"]\n        geo_df = sdata[shapes_key]\n\n        if _should_save(mode, \"c\"):\n            write_gene_counts(path, adata, layer=layer)\n        if _should_save(mode, \"o\"):\n            write_cell_categories(path, adata)\n\n    ### Saving cell boundaries\n    if shapes_key is None:\n        shapes_key, geo_df = get_boundaries(sdata, return_key=True, warn=True)\n    else:\n        geo_df = sdata[shapes_key]\n\n    if _should_save(mode, \"b\") and geo_df is not None:\n        geo_df = to_intrinsic(sdata, geo_df, image_key)\n\n        if sdata.table is not None:\n            geo_df = geo_df.loc[adata.obs[adata.uns[\"spatialdata_attrs\"][\"instance_key\"]]]\n\n        write_polygons(path, geo_df.geometry, polygon_max_vertices, pixelsize=pixelsize)\n\n    ### Saving transcripts\n    df = get_element(sdata, \"points\", points_key)\n\n    if _should_save(mode, \"t\") and df is not None:\n        if gene_column is not None:\n            df = to_intrinsic(sdata, df, image_key)\n            write_transcripts(path, df, gene_column, pixelsize=pixelsize)\n        else:\n            log.warn(\"The argument 'gene_column' has to be provided to save the transcripts\")\n\n    ### Saving image\n    if _should_save(mode, \"i\"):\n        write_image(path, image, lazy=lazy, ram_threshold_gb=ram_threshold_gb, pixelsize=pixelsize)\n\n    ### Saving experiment.xenium file\n    if _should_save(mode, \"m\"):\n        write_metadata(path, image_key, shapes_key, _get_n_obs(sdata, geo_df), pixelsize)\n\n    if save_h5ad:\n        sdata.table.write_h5ad(path / FileNames.H5AD)\n\n    log.info(f\"Saved files in the following directory: {path}\")\n    log.info(f\"You can open the experiment with 'open {path / FileNames.METADATA}'\")\n</code></pre>"},{"location":"api/io.explorer/#sopa.io.explorer.write_image","title":"<code>sopa.io.explorer.write_image(path, image, lazy=True, tile_width=1024, n_subscales=5, pixelsize=0.2125, ram_threshold_gb=4, is_dir=True)</code>","text":"<p>Convert an image into a <code>morphology.ome.tif</code> file that can be read by the Xenium Explorer</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the Xenium Explorer directory where the image will be written</p> required <code>image</code> <code>SpatialImage | ndarray</code> <p>Image of shape <code>(C, Y, X)</code></p> required <code>lazy</code> <code>bool</code> <p>If <code>False</code>, the image will not be read in-memory (except if the image size is below <code>ram_threshold_gb</code>). If <code>True</code>, all the images levels are always loaded in-memory.</p> <code>True</code> <code>tile_width</code> <code>int</code> <p>Xenium tile width (do not update).</p> <code>1024</code> <code>n_subscales</code> <code>int</code> <p>Number of sub-scales in the pyramidal image.</p> <code>5</code> <code>pixelsize</code> <code>float</code> <p>Xenium pixel size (do not update).</p> <code>0.2125</code> <code>ram_threshold_gb</code> <code>int | None</code> <p>If an image (of any level of the pyramid) is below this threshold, it will be loaded in-memory.</p> <code>4</code> <code>is_dir</code> <code>bool</code> <p>If <code>False</code>, then <code>path</code> is a path to a single file, not to the Xenium Explorer directory.</p> <code>True</code> Source code in <code>sopa/io/explorer/images.py</code> <pre><code>def write_image(\n    path: str,\n    image: SpatialImage | np.ndarray,\n    lazy: bool = True,\n    tile_width: int = 1024,\n    n_subscales: int = 5,\n    pixelsize: float = 0.2125,\n    ram_threshold_gb: int | None = 4,\n    is_dir: bool = True,\n):\n    \"\"\"Convert an image into a `morphology.ome.tif` file that can be read by the Xenium Explorer\n\n    Args:\n        path: Path to the Xenium Explorer directory where the image will be written\n        image: Image of shape `(C, Y, X)`\n        lazy: If `False`, the image will not be read in-memory (except if the image size is below `ram_threshold_gb`). If `True`, all the images levels are always loaded in-memory.\n        tile_width: Xenium tile width (do not update).\n        n_subscales: Number of sub-scales in the pyramidal image.\n        pixelsize: Xenium pixel size (do not update).\n        ram_threshold_gb: If an image (of any level of the pyramid) is below this threshold, it will be loaded in-memory.\n        is_dir: If `False`, then `path` is a path to a single file, not to the Xenium Explorer directory.\n    \"\"\"\n    path = explorer_file_path(path, FileNames.IMAGE, is_dir)\n\n    if isinstance(image, np.ndarray):\n        assert len(image.shape) == 3, \"Can only write channels with shape (C,Y,X)\"\n        log.info(f\"Converting image of shape {image.shape} into a SpatialImage (with dims: C,Y,X)\")\n        image = SpatialImage(image, dims=[\"c\", \"y\", \"x\"], name=\"image\")\n\n    image: MultiscaleSpatialImage = to_multiscale(image, [2] * n_subscales)\n\n    image_writer = MultiscaleImageWriter(image, pixelsize=pixelsize, tile_width=tile_width)\n    image_writer.write(path, lazy=lazy, ram_threshold_gb=ram_threshold_gb)\n</code></pre>"},{"location":"api/io.explorer/#sopa.io.explorer.write_cell_categories","title":"<code>sopa.io.explorer.write_cell_categories(path, adata, is_dir=True)</code>","text":"<p>Write a <code>analysis.zarr.zip</code> file containing the cell categories/clusters (i.e., from <code>adata.obs</code>)</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the Xenium Explorer directory where the cell-categories file will be written</p> required <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object</p> required <code>is_dir</code> <code>bool</code> <p>If <code>False</code>, then <code>path</code> is a path to a single file, not to the Xenium Explorer directory.</p> <code>True</code> Source code in <code>sopa/io/explorer/table.py</code> <pre><code>def write_cell_categories(path: str, adata: AnnData, is_dir: bool = True) -&gt; None:\n    \"\"\"Write a `analysis.zarr.zip` file containing the cell categories/clusters (i.e., from `adata.obs`)\n\n    Args:\n        path: Path to the Xenium Explorer directory where the cell-categories file will be written\n        adata: An `AnnData` object\n        is_dir: If `False`, then `path` is a path to a single file, not to the Xenium Explorer directory.\n    \"\"\"\n    path = explorer_file_path(path, FileNames.CELL_CATEGORIES, is_dir)\n\n    adata.strings_to_categoricals()\n    cat_columns = [name for name, cat in adata.obs.dtypes.items() if cat == \"category\"]\n\n    log.info(f\"Writing {len(cat_columns)} cell categories: {', '.join(cat_columns)}\")\n\n    ATTRS = cell_categories_attrs()\n    ATTRS[\"number_groupings\"] = len(cat_columns)\n\n    with zarr.ZipStore(path, mode=\"w\") as store:\n        g = zarr.group(store=store)\n        cell_groups = g.create_group(\"cell_groups\")\n\n        for i, name in enumerate(cat_columns):\n            if adata.obs[name].isna().any():\n                NA = \"NA\"\n                log.warn(f\"Column {name} has nan values. They will be displayed as '{NA}'\")\n                adata.obs[name] = adata.obs[name].cat.add_categories(NA).fillna(NA)\n\n            categories = list(adata.obs[name].cat.categories)\n            ATTRS[\"grouping_names\"].append(name)\n            ATTRS[\"group_names\"].append(categories)\n\n            _write_categorical_column(cell_groups, i, adata.obs[name], categories)\n\n        cell_groups.attrs.put(ATTRS)\n</code></pre>"},{"location":"api/io.explorer/#sopa.io.explorer.write_transcripts","title":"<code>sopa.io.explorer.write_transcripts(path, df, gene='gene', max_levels=15, is_dir=True, pixelsize=0.2125)</code>","text":"<p>Write a <code>transcripts.zarr.zip</code> file containing pyramidal transcript locations</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the Xenium Explorer directory where the transcript file will be written</p> required <code>df</code> <code>DataFrame</code> <p>DataFrame representing the transcripts, with <code>\"x\"</code>, <code>\"y\"</code> column required, as well as the <code>gene</code> column (see the corresponding argument)</p> required <code>gene</code> <code>str</code> <p>Column of <code>df</code> containing the genes names.</p> <code>'gene'</code> <code>max_levels</code> <code>int</code> <p>Maximum number of levels in the pyramid.</p> <code>15</code> <code>is_dir</code> <code>bool</code> <p>If <code>False</code>, then <code>path</code> is a path to a single file, not to the Xenium Explorer directory.</p> <code>True</code> <code>pixelsize</code> <code>float</code> <p>Number of microns in a pixel. Invalid value can lead to inconsistent scales in the Explorer.</p> <code>0.2125</code> Source code in <code>sopa/io/explorer/points.py</code> <pre><code>def write_transcripts(\n    path: Path,\n    df: dd.DataFrame,\n    gene: str = \"gene\",\n    max_levels: int = 15,\n    is_dir: bool = True,\n    pixelsize: float = 0.2125,\n):\n    \"\"\"Write a `transcripts.zarr.zip` file containing pyramidal transcript locations\n\n    Args:\n        path: Path to the Xenium Explorer directory where the transcript file will be written\n        df: DataFrame representing the transcripts, with `\"x\"`, `\"y\"` column required, as well as the `gene` column (see the corresponding argument)\n        gene: Column of `df` containing the genes names.\n        max_levels: Maximum number of levels in the pyramid.\n        is_dir: If `False`, then `path` is a path to a single file, not to the Xenium Explorer directory.\n        pixelsize: Number of microns in a pixel. Invalid value can lead to inconsistent scales in the Explorer.\n    \"\"\"\n    path = explorer_file_path(path, FileNames.POINTS, is_dir)\n\n    # TODO: make everything using dask instead of pandas\n    df = df.compute()\n\n    num_transcripts = len(df)\n    grid_size = ExplorerConstants.GRID_SIZE / ExplorerConstants.PIXELS_TO_MICRONS * pixelsize\n    df[gene] = df[gene].astype(\"category\")\n\n    location = df[[\"x\", \"y\"]]\n    location *= pixelsize\n    location = np.concatenate([location, np.zeros((num_transcripts, 1))], axis=1)\n\n    if location.min() &lt; 0:\n        log.warn(\"Some transcripts are located outside of the image (pixels &lt; 0)\")\n    log.info(f\"Writing {len(df)} transcripts\")\n\n    xmax, ymax = location[:, :2].max(axis=0)\n\n    gene_names = list(df[gene].cat.categories)\n    num_genes = len(gene_names)\n\n    codeword_gene_mapping = list(range(num_genes))\n\n    valid = np.ones((num_transcripts, 1))\n    uuid = np.stack([np.arange(num_transcripts), np.full(num_transcripts, 65535)], axis=1)\n    transcript_id = np.stack([np.arange(num_transcripts), np.full(num_transcripts, 65535)], axis=1)\n    gene_identity = df[gene].cat.codes.values[:, None]\n    codeword_identity = np.stack([gene_identity[:, 0], np.full(num_transcripts, 65535)], axis=1)\n    status = np.zeros((num_transcripts, 1))\n    quality_score = np.full((num_transcripts, 1), ExplorerConstants.QUALITY_SCORE)\n\n    ATTRS = {\n        \"codeword_count\": num_genes,\n        \"codeword_gene_mapping\": codeword_gene_mapping,\n        \"codeword_gene_names\": gene_names,\n        \"gene_names\": gene_names,\n        \"gene_index_map\": {name: index for name, index in zip(gene_names, codeword_gene_mapping)},\n        \"number_genes\": num_genes,\n        \"spatial_units\": \"micron\",\n        \"coordinate_space\": \"refined-final_global_micron\",\n        \"major_version\": 4,\n        \"minor_version\": 1,\n        \"name\": \"RnaDataset\",\n        \"number_rnas\": num_transcripts,\n        \"dataset_uuid\": \"unique-id-test\",\n        \"data_format\": 0,\n    }\n\n    GRIDS_ATTRS = {\n        \"grid_key_names\": [\"grid_x_loc\", \"grid_y_loc\"],\n        \"grid_zip\": False,\n        \"grid_size\": [grid_size],\n        \"grid_array_shapes\": [],\n        \"grid_number_objects\": [],\n        \"grid_keys\": [],\n    }\n\n    with zarr.ZipStore(path, mode=\"w\") as store:\n        g = zarr.group(store=store)\n        g.attrs.put(ATTRS)\n\n        grids = g.create_group(\"grids\")\n\n        for level in range(max_levels):\n            log.info(f\"   &gt; Level {level}: {len(location)} transcripts\")\n            level_group = grids.create_group(level)\n\n            tile_size = grid_size * 2**level\n\n            indices = np.floor(location[:, :2] / tile_size).clip(0).astype(int)\n            tiles_str_indices = np.array([f\"{tx},{ty}\" for (tx, ty) in indices])\n\n            GRIDS_ATTRS[\"grid_array_shapes\"].append([])\n            GRIDS_ATTRS[\"grid_number_objects\"].append([])\n            GRIDS_ATTRS[\"grid_keys\"].append([])\n\n            n_tiles_x, n_tiles_y = ceil(xmax / tile_size), ceil(ymax / tile_size)\n\n            for tx in range(n_tiles_x):\n                for ty in range(n_tiles_y):\n                    str_index = f\"{tx},{ty}\"\n                    loc = np.where(tiles_str_indices == str_index)[0]\n\n                    n_points_tile = len(loc)\n                    chunks = (n_points_tile, 1)\n\n                    if n_points_tile == 0:\n                        continue\n\n                    GRIDS_ATTRS[\"grid_array_shapes\"][-1].append({})\n                    GRIDS_ATTRS[\"grid_keys\"][-1].append(str_index)\n                    GRIDS_ATTRS[\"grid_number_objects\"][-1].append(n_points_tile)\n\n                    tile_group = level_group.create_group(str_index)\n                    tile_group.array(\n                        \"valid\",\n                        valid[loc],\n                        dtype=\"uint8\",\n                        chunks=chunks,\n                    )\n                    tile_group.array(\n                        \"status\",\n                        status[loc],\n                        dtype=\"uint8\",\n                        chunks=chunks,\n                    )\n                    tile_group.array(\n                        \"location\",\n                        location[loc],\n                        dtype=\"float32\",\n                        chunks=chunks,\n                    )\n                    tile_group.array(\n                        \"gene_identity\",\n                        gene_identity[loc],\n                        dtype=\"uint16\",\n                        chunks=chunks,\n                    )\n                    tile_group.array(\n                        \"quality_score\",\n                        quality_score[loc],\n                        dtype=\"float32\",\n                        chunks=chunks,\n                    )\n                    tile_group.array(\n                        \"codeword_identity\",\n                        codeword_identity[loc],\n                        dtype=\"uint16\",\n                        chunks=chunks,\n                    )\n                    tile_group.array(\n                        \"uuid\",\n                        uuid[loc],\n                        dtype=\"uint32\",\n                        chunks=chunks,\n                    )\n                    tile_group.array(\n                        \"id\",\n                        transcript_id[loc],\n                        dtype=\"uint32\",\n                        chunks=chunks,\n                    )\n\n            if n_tiles_x * n_tiles_y == 1:\n                GRIDS_ATTRS[\"number_levels\"] = level + 1\n                break\n\n            sub_indices = subsample_indices(len(location))\n\n            location = location[sub_indices]\n            valid = valid[sub_indices]\n            status = status[sub_indices]\n            gene_identity = gene_identity[sub_indices]\n            quality_score = quality_score[sub_indices]\n            codeword_identity = codeword_identity[sub_indices]\n            uuid = uuid[sub_indices]\n            transcript_id = transcript_id[sub_indices]\n\n        grids.attrs.put(GRIDS_ATTRS)\n</code></pre>"},{"location":"api/io.explorer/#sopa.io.explorer.write_gene_counts","title":"<code>sopa.io.explorer.write_gene_counts(path, adata, layer=None, is_dir=True)</code>","text":"<p>Write a <code>cell_feature_matrix.zarr.zip</code> file containing the cell-by-gene transcript counts (i.e., from <code>adata.X</code>)</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the Xenium Explorer directory where the cell-by-gene file will be written</p> required <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object. Note that <code>adata.X</code> has to be a sparse matrix (and contain the raw counts), else use the <code>layer</code> argument.</p> required <code>layer</code> <code>str | None</code> <p>If not <code>None</code>, <code>adata.layers[layer]</code> should be sparse (and contain the raw counts).</p> <code>None</code> <code>is_dir</code> <code>bool</code> <p>If <code>False</code>, then <code>path</code> is a path to a single file, not to the Xenium Explorer directory.</p> <code>True</code> Source code in <code>sopa/io/explorer/table.py</code> <pre><code>def write_gene_counts(\n    path: str, adata: AnnData, layer: str | None = None, is_dir: bool = True\n) -&gt; None:\n    \"\"\"Write a `cell_feature_matrix.zarr.zip` file containing the cell-by-gene transcript counts (i.e., from `adata.X`)\n\n    Args:\n        path: Path to the Xenium Explorer directory where the cell-by-gene file will be written\n        adata: An `AnnData` object. Note that `adata.X` has to be a sparse matrix (and contain the raw counts), else use the `layer` argument.\n        layer: If not `None`, `adata.layers[layer]` should be sparse (and contain the raw counts).\n        is_dir: If `False`, then `path` is a path to a single file, not to the Xenium Explorer directory.\n    \"\"\"\n    path = explorer_file_path(path, FileNames.TABLE, is_dir)\n\n    log.info(f\"Writing table with {adata.n_vars} columns\")\n    counts = adata.X if layer is None else adata.layers[layer]\n    counts = csr_matrix(counts)\n\n    feature_keys = list(adata.var_names) + [\"Total transcripts\"]\n    feature_ids = feature_keys\n    feature_types = [\"gene\"] * len(adata.var_names) + [\"aggregate_gene\"]\n\n    ATTRS = {\n        \"major_version\": 3,\n        \"minor_version\": 0,\n        \"number_cells\": adata.n_obs,\n        \"number_features\": adata.n_vars + 1,\n        \"feature_keys\": feature_keys,\n        \"feature_ids\": feature_ids,\n        \"feature_types\": feature_types,\n    }\n\n    data, indices, indptr = [], [], [0]\n\n    for i in range(adata.n_vars):\n        row_indices = counts[:, i].nonzero()[0]\n        data.append(counts[row_indices, i].data)\n        indices.append(row_indices)\n        indptr.append(indptr[-1] + len(row_indices))\n\n    total_counts = counts.sum(1).A1\n    loc = total_counts &gt; 0\n    data.append(total_counts[loc])\n    indices.append(np.where(loc)[0])\n    indptr.append(indptr[-1] + loc.sum())\n\n    data = np.concatenate(data)\n    indices = np.concatenate(indices)\n    indptr = np.array(indptr)\n\n    cell_id = np.ones((adata.n_obs, 2))\n    cell_id[:, 0] = np.arange(adata.n_obs)\n\n    with zarr.ZipStore(path, mode=\"w\") as store:\n        g = zarr.group(store=store)\n        cells_group = g.create_group(\"cell_features\")\n        cells_group.attrs.put(ATTRS)\n\n        cells_group.array(\"cell_id\", cell_id, dtype=\"uint32\", chunks=cell_id.shape)\n        cells_group.array(\"data\", data, dtype=\"uint32\", chunks=data.shape)\n        cells_group.array(\"indices\", indices, dtype=\"uint32\", chunks=indices.shape)\n        cells_group.array(\"indptr\", indptr, dtype=\"uint32\", chunks=indptr.shape)\n</code></pre>"},{"location":"api/io.explorer/#sopa.io.explorer.write_polygons","title":"<code>sopa.io.explorer.write_polygons(path, polygons, max_vertices, is_dir=True, pixelsize=0.2125)</code>","text":"<p>Write a <code>cells.zarr.zip</code> file containing the cell polygonal boundaries</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the Xenium Explorer directory where the transcript file will be written</p> required <code>polygons</code> <code>Iterable[Polygon]</code> <p>A list of <code>shapely</code> polygons to be written</p> required <code>max_vertices</code> <code>int</code> <p>The number of vertices per polygon (they will be transformed to have the right number of vertices)</p> required <code>is_dir</code> <code>bool</code> <p>If <code>False</code>, then <code>path</code> is a path to a single file, not to the Xenium Explorer directory.</p> <code>True</code> <code>pixelsize</code> <code>float</code> <p>Number of microns in a pixel. Invalid value can lead to inconsistent scales in the Explorer.</p> <code>0.2125</code> Source code in <code>sopa/io/explorer/shapes.py</code> <pre><code>def write_polygons(\n    path: Path,\n    polygons: Iterable[Polygon],\n    max_vertices: int,\n    is_dir: bool = True,\n    pixelsize: float = 0.2125,\n) -&gt; None:\n    \"\"\"Write a `cells.zarr.zip` file containing the cell polygonal boundaries\n\n    Args:\n        path: Path to the Xenium Explorer directory where the transcript file will be written\n        polygons: A list of `shapely` polygons to be written\n        max_vertices: The number of vertices per polygon (they will be transformed to have the right number of vertices)\n        is_dir: If `False`, then `path` is a path to a single file, not to the Xenium Explorer directory.\n        pixelsize: Number of microns in a pixel. Invalid value can lead to inconsistent scales in the Explorer.\n    \"\"\"\n    path = explorer_file_path(path, FileNames.SHAPES, is_dir)\n\n    log.info(f\"Writing {len(polygons)} cell polygons\")\n    coordinates = np.stack([pad_polygon(p, max_vertices) for p in polygons])\n    coordinates *= pixelsize\n\n    num_cells = len(coordinates)\n    cells_fourth = ceil(num_cells / 4)\n    cells_half = ceil(num_cells / 2)\n\n    GROUP_ATTRS = group_attrs()\n    GROUP_ATTRS[\"number_cells\"] = num_cells\n\n    polygon_vertices = np.stack([coordinates, coordinates])\n    num_points = polygon_vertices.shape[2]\n    n_vertices = num_points // 2\n\n    with zarr.ZipStore(path, mode=\"w\") as store:\n        g = zarr.group(store=store)\n        g.attrs.put(GROUP_ATTRS)\n\n        g.array(\n            \"polygon_vertices\",\n            polygon_vertices,\n            dtype=\"float32\",\n            chunks=(1, cells_fourth, ceil(num_points / 4)),\n        )\n\n        cell_id = np.ones((num_cells, 2))\n        cell_id[:, 0] = np.arange(num_cells)\n        g.array(\"cell_id\", cell_id, dtype=\"uint32\", chunks=(cells_half, 1))\n\n        cell_summary = np.zeros((num_cells, 7))\n        cell_summary[:, 2] = [p.area for p in polygons]\n        g.array(\n            \"cell_summary\",\n            cell_summary,\n            dtype=\"float64\",\n            chunks=(num_cells, 1),\n        )\n        g[\"cell_summary\"].attrs.put(cell_summary_attrs())\n\n        g.array(\n            \"polygon_num_vertices\",\n            np.full((2, num_cells), n_vertices),\n            dtype=\"int32\",\n            chunks=(1, cells_half),\n        )\n\n        g.array(\n            \"seg_mask_value\",\n            np.arange(num_cells),\n            dtype=\"uint32\",\n            chunks=(cells_half,),\n        )\n</code></pre>"},{"location":"api/io.explorer/#sopa.io.explorer.write_metadata","title":"<code>sopa.io.explorer.write_metadata(path, image_key='NA', shapes_key='NA', n_obs=0, is_dir=True, pixelsize=0.2125)</code>","text":"<p>Create an <code>experiment.xenium</code> file that can be open by the Xenium Explorer.</p> Note <p>This function alone is not enough to actually open an experiment. You will need at least to wrun <code>write_image</code>, or create all the outputs with <code>write</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the Xenium Explorer directory where the metadata file will be written</p> required <code>image_key</code> <code>str</code> <p>Key of <code>SpatialData</code> object containing the primary image used on the explorer.</p> <code>'NA'</code> <code>shapes_key</code> <code>str</code> <p>Key of <code>SpatialData</code> object containing the boundaries shown on the explorer.</p> <code>'NA'</code> <code>n_obs</code> <code>int</code> <p>Number of cells</p> <code>0</code> <code>is_dir</code> <code>bool</code> <p>If <code>False</code>, then <code>path</code> is a path to a single file, not to the Xenium Explorer directory.</p> <code>True</code> <code>pixelsize</code> <code>float</code> <p>Number of microns in a pixel. Invalid value can lead to inconsistent scales in the Explorer.</p> <code>0.2125</code> Source code in <code>sopa/io/explorer/converter.py</code> <pre><code>def write_metadata(\n    path: str,\n    image_key: str = \"NA\",\n    shapes_key: str = \"NA\",\n    n_obs: int = 0,\n    is_dir: bool = True,\n    pixelsize: float = 0.2125,\n):\n    \"\"\"Create an `experiment.xenium` file that can be open by the Xenium Explorer.\n\n    Note:\n        This function alone is not enough to actually open an experiment. You will need at least to wrun `write_image`, or create all the outputs with `write`.\n\n    Args:\n        path: Path to the Xenium Explorer directory where the metadata file will be written\n        image_key: Key of `SpatialData` object containing the primary image used on the explorer.\n        shapes_key: Key of `SpatialData` object containing the boundaries shown on the explorer.\n        n_obs: Number of cells\n        is_dir: If `False`, then `path` is a path to a single file, not to the Xenium Explorer directory.\n        pixelsize: Number of microns in a pixel. Invalid value can lead to inconsistent scales in the Explorer.\n    \"\"\"\n    path = explorer_file_path(path, FileNames.METADATA, is_dir)\n\n    with open(path, \"w\") as f:\n        metadata = experiment_dict(image_key, shapes_key, n_obs, pixelsize)\n        json.dump(metadata, f, indent=4)\n</code></pre>"},{"location":"api/io.explorer/#sopa.io.explorer.int_cell_id","title":"<code>sopa.io.explorer.int_cell_id(explorer_cell_id)</code>","text":"<p>Transforms an alphabetical cell id from the Xenium Explorer to an integer ID</p> <p>E.g., int_cell_id('aaaachba-1') = 10000</p> Source code in <code>sopa/io/explorer/utils.py</code> <pre><code>def int_cell_id(explorer_cell_id: str) -&gt; int:\n    \"\"\"Transforms an alphabetical cell id from the Xenium Explorer to an integer ID\n\n    E.g., int_cell_id('aaaachba-1') = 10000\"\"\"\n    code = explorer_cell_id[:-2] if explorer_cell_id[-2] == \"-\" else explorer_cell_id\n    coefs = [ord(c) - 97 for c in code][::-1]\n    return sum(value * 16**i for i, value in enumerate(coefs))\n</code></pre>"},{"location":"api/io.explorer/#sopa.io.explorer.str_cell_id","title":"<code>sopa.io.explorer.str_cell_id(cell_id)</code>","text":"<p>Transforms an integer cell ID into an Xenium Explorer alphabetical cell id</p> <p>E.g., str_cell_id(10000) = 'aaaachba-1'</p> Source code in <code>sopa/io/explorer/utils.py</code> <pre><code>def str_cell_id(cell_id: int) -&gt; str:\n    \"\"\"Transforms an integer cell ID into an Xenium Explorer alphabetical cell id\n\n    E.g., str_cell_id(10000) = 'aaaachba-1'\"\"\"\n    coefs = []\n    for _ in range(8):\n        cell_id, coef = divmod(cell_id, 16)\n        coefs.append(coef)\n    return \"\".join([chr(97 + coef) for coef in coefs][::-1]) + \"-1\"\n</code></pre>"},{"location":"api/io.explorer/#sopa.io.explorer.align","title":"<code>sopa.io.explorer.align(sdata, image, transformation_matrix_path, image_key=None, image_models_kwargs=None, overwrite=False)</code>","text":"<p>Add an image to the <code>SpatialData</code> object after alignment with the Xenium Explorer.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>image</code> <code>SpatialImage</code> <p>A <code>SpatialImage</code> object. Note that <code>image.name</code> is used as the key for the aligned image.</p> required <code>transformation_matrix_path</code> <code>str</code> <p>Path to the <code>.csv</code> transformation matrix exported from the Xenium Explorer</p> required <code>image_key</code> <code>str</code> <p>Optional name of the image on which it has been aligned. Required if multiple images in the <code>SpatialData</code> object.</p> <code>None</code> <code>image_models_kwargs</code> <code>dict | None</code> <p>Kwargs to the <code>Image2DModel</code> model.</p> <code>None</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite the image, if already existing.</p> <code>False</code> Source code in <code>sopa/io/explorer/images.py</code> <pre><code>def align(\n    sdata: SpatialData,\n    image: SpatialImage,\n    transformation_matrix_path: str,\n    image_key: str = None,\n    image_models_kwargs: dict | None = None,\n    overwrite: bool = False,\n):\n    \"\"\"Add an image to the `SpatialData` object after alignment with the Xenium Explorer.\n\n    Args:\n        sdata: A `SpatialData` object\n        image: A `SpatialImage` object. Note that `image.name` is used as the key for the aligned image.\n        transformation_matrix_path: Path to the `.csv` transformation matrix exported from the Xenium Explorer\n        image_key: Optional name of the image on which it has been aligned. Required if multiple images in the `SpatialData` object.\n        image_models_kwargs: Kwargs to the `Image2DModel` model.\n        overwrite: Whether to overwrite the image, if already existing.\n    \"\"\"\n    image_models_kwargs = _default_image_models_kwargs(image_models_kwargs)\n\n    to_pixel = Affine(\n        np.genfromtxt(transformation_matrix_path, delimiter=\",\"),\n        input_axes=(\"x\", \"y\"),\n        output_axes=(\"x\", \"y\"),\n    )\n\n    default_image = get_spatial_image(sdata, image_key)\n    pixel_cs = get_intrinsic_cs(sdata, default_image)\n\n    image = Image2DModel.parse(\n        image,\n        dims=(\"c\", \"y\", \"x\"),\n        transformations={pixel_cs: to_pixel},\n        c_coords=image.coords[\"c\"].values,\n        **image_models_kwargs,\n    )\n\n    log.info(f\"Adding image {image.name}:\\n{image}\")\n    sdata.add_image(image.name, image, overwrite=overwrite)\n</code></pre>"},{"location":"api/io.explorer/#sopa.io.explorer.save_column_csv","title":"<code>sopa.io.explorer.save_column_csv(path, adata, key)</code>","text":"<p>Save one column of the AnnData object as a CSV that can be open interactively in the explorer, under the \"cell\" panel.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path where to write the CSV that will be open in the Xenium Explorer</p> required <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object</p> required <code>key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the column to convert</p> required Source code in <code>sopa/io/explorer/table.py</code> <pre><code>def save_column_csv(path: str, adata: AnnData, key: str):\n    \"\"\"Save one column of the AnnData object as a CSV that can be open interactively in the explorer, under the \"cell\" panel.\n\n    Args:\n        path: Path where to write the CSV that will be open in the Xenium Explorer\n        adata: An `AnnData` object\n        key: Key of `adata.obs` containing the column to convert\n    \"\"\"\n    df = pd.DataFrame({\"cell_id\": adata.obs_names, \"group\": adata.obs[key].values})\n    df.to_csv(path, index=None)\n</code></pre>"},{"location":"api/io/","title":"sopa.io","text":"<p>Notes</p> <p>Due to many updates in the data format provided by the different companies, you might have issues loading your data. In this case, consider opening an issue detailing the version of the machine you used and the error log, as well as an example of file names that you are trying to read.</p> <p>Related to <code>spatialdata-io</code></p> <p>A library called <code>spatialdata-io</code> already contains a lot of readers. Here, we updated some readers already existing in <code>spatialdata-io</code>, and added a few others. In the future, we will completely rely on <code>spatialdata-io</code>.</p>"},{"location":"api/io/#sopa.io.xenium","title":"<code>sopa.io.xenium(path, imread_kwargs=MappingProxyType({}), image_models_kwargs=MappingProxyType({}))</code>","text":"<p>Read Xenium data as a <code>SpatialData</code> object. For more information, refer to spatialdata-io.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the Xenium directory containing all the experiment files</p> required <code>imread_kwargs</code> <p>See link above.</p> <code>MappingProxyType({})</code> <code>image_models_kwargs</code> <p>See link above.</p> <code>MappingProxyType({})</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A <code>SpatialData</code> object representing the Xenium experiment</p> Source code in <code>sopa/io/transcriptomics.py</code> <pre><code>def xenium(\n    path: str | Path,\n    imread_kwargs=MappingProxyType({}),\n    image_models_kwargs=MappingProxyType({}),\n) -&gt; SpatialData:\n    \"\"\"Read Xenium data as a `SpatialData` object. For more information, refer to [spatialdata-io](https://spatialdata.scverse.org/projects/io/en/latest/generated/spatialdata_io.xenium.html).\n\n    Args:\n        path: Path to the Xenium directory containing all the experiment files\n        imread_kwargs: See link above.\n        image_models_kwargs:See link above.\n\n    Returns:\n        A `SpatialData` object representing the Xenium experiment\n    \"\"\"\n    if \"chunks\" not in image_models_kwargs:\n        if isinstance(image_models_kwargs, MappingProxyType):\n            image_models_kwargs = {}\n        assert isinstance(image_models_kwargs, dict)\n        image_models_kwargs[\"chunks\"] = (1, 4096, 4096)\n    if \"scale_factors\" not in image_models_kwargs:\n        if isinstance(image_models_kwargs, MappingProxyType):\n            image_models_kwargs = {}\n        assert isinstance(image_models_kwargs, dict)\n        image_models_kwargs[\"scale_factors\"] = [2, 2, 2, 2]\n\n    path = Path(path)\n    with open(path / XeniumKeys.XENIUM_SPECS) as f:\n        specs = json.load(f)\n\n    points = {\"transcripts\": _get_points_xenium(path, specs)}\n\n    images = {\n        \"morphology_mip\": _get_images_xenium(\n            path,\n            XeniumKeys.MORPHOLOGY_MIP_FILE,\n            imread_kwargs,\n            image_models_kwargs,\n        )\n    }\n\n    return SpatialData(images=images, points=points)\n</code></pre>"},{"location":"api/io/#sopa.io.merscope","title":"<code>sopa.io.merscope(path, vpt_outputs=None, z_layers=3, region_name=None, slide_name=None, imread_kwargs=MappingProxyType({}), image_models_kwargs=MappingProxyType({}))</code>","text":"<p>Read MERSCOPE data as a <code>SpatialData</code> object. For more information, refer to spatialdata-io.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the MERSCOPE directory containing all the experiment files</p> required <code>**kwargs</code> <p>See link above.</p> required <p>Returns:</p> Type Description <code>SpatialData</code> <p>A <code>SpatialData</code> object representing the MERSCOPE experiment</p> Source code in <code>sopa/io/transcriptomics.py</code> <pre><code>def merscope(\n    path: str | Path,\n    vpt_outputs: Path | str | dict[str, Any] | None = None,\n    z_layers: int | list[int] | None = 3,\n    region_name: str | None = None,\n    slide_name: str | None = None,\n    imread_kwargs: Mapping[str, Any] = MappingProxyType({}),\n    image_models_kwargs: Mapping[str, Any] = MappingProxyType({}),\n) -&gt; SpatialData:\n    \"\"\"Read MERSCOPE data as a `SpatialData` object. For more information, refer to [spatialdata-io](https://spatialdata.scverse.org/projects/io/en/latest/generated/spatialdata_io.merscope.html).\n\n    Args:\n        path: Path to the MERSCOPE directory containing all the experiment files\n        **kwargs: See link above.\n\n    Returns:\n        A `SpatialData` object representing the MERSCOPE experiment\n    \"\"\"\n    if \"chunks\" not in image_models_kwargs:\n        if isinstance(image_models_kwargs, MappingProxyType):\n            image_models_kwargs = {}\n        assert isinstance(image_models_kwargs, dict)\n        image_models_kwargs[\"chunks\"] = (1, 4096, 4096)\n    if \"scale_factors\" not in image_models_kwargs:\n        if isinstance(image_models_kwargs, MappingProxyType):\n            image_models_kwargs = {}\n        assert isinstance(image_models_kwargs, dict)\n        image_models_kwargs[\"scale_factors\"] = [2, 2, 2, 2]\n\n    path = Path(path).absolute()\n    count_path, obs_path, boundaries_path = _get_file_paths(path, vpt_outputs)\n    images_dir = path / MerscopeKeys.IMAGES_DIR\n\n    microns_to_pixels = Affine(\n        np.genfromtxt(images_dir / MerscopeKeys.TRANSFORMATION_FILE),\n        input_axes=(\"x\", \"y\"),\n        output_axes=(\"x\", \"y\"),\n    )\n\n    vizgen_region = path.name if region_name is None else region_name\n    slide_name = path.parent.name if slide_name is None else slide_name\n    dataset_id = f\"{slide_name}_{vizgen_region}\"\n    region = f\"{dataset_id}_polygons\"\n\n    # Images\n    images = {}\n\n    z_layers = [z_layers] if isinstance(z_layers, int) else z_layers or []\n\n    stainings = _get_channel_names(images_dir)\n    if stainings:\n        for z_layer in z_layers:\n            im = da.stack(\n                [\n                    imread(images_dir / f\"mosaic_{stain}_z{z_layer}.tif\", **imread_kwargs).squeeze()\n                    for stain in stainings\n                ],\n                axis=0,\n            )\n            parsed_im = Image2DModel.parse(\n                im,\n                dims=(\"c\", \"y\", \"x\"),\n                transformations={\"microns\": microns_to_pixels.inverse()},\n                c_coords=stainings,\n                **image_models_kwargs,\n            )\n            images[f\"{dataset_id}_z{z_layer}\"] = parsed_im\n\n    # Transcripts\n    points = {}\n    transcript_path = path / MerscopeKeys.TRANSCRIPTS_FILE\n    if transcript_path.exists():\n        points[f\"{dataset_id}_transcripts\"] = _get_points(transcript_path)\n    else:\n        logger.warning(\n            f\"Transcript file {transcript_path} does not exist. Transcripts are not loaded.\"\n        )\n\n    # Polygons\n    shapes = {}\n    if boundaries_path.exists():\n        shapes[f\"{dataset_id}_polygons\"] = _get_polygons(boundaries_path)\n    else:\n        logger.warning(\n            f\"Boundary file {boundaries_path} does not exist. Cell boundaries are not loaded.\"\n        )\n\n    # Table\n    table = None\n    if count_path.exists() and obs_path.exists():\n        table = _get_table(count_path, obs_path, vizgen_region, slide_name, dataset_id, region)\n    else:\n        logger.warning(\n            f\"At least one of the following files does not exist: {count_path}, {obs_path}. The table is not loaded.\"\n        )\n\n    return SpatialData(shapes=shapes, points=points, images=images, table=table)\n</code></pre>"},{"location":"api/io/#sopa.io.cosmx","title":"<code>sopa.io.cosmx(path, **kwargs)</code>","text":"<p>Alias to the spatialdata-io reader.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the CosMX data directory</p> required <code>**kwargs</code> <code>int</code> <p>See link above.</p> <code>{}</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A <code>SpatialData</code> object representing the CosMX experiment</p> Source code in <code>sopa/io/transcriptomics.py</code> <pre><code>def cosmx(path: str, **kwargs: int) -&gt; SpatialData:\n    \"\"\"Alias to the [spatialdata-io reader](https://spatialdata.scverse.org/projects/io/en/latest/generated/spatialdata_io.cosmx.html).\n\n    Args:\n        path: Path to the CosMX data directory\n        **kwargs: See link above.\n\n    Returns:\n        A `SpatialData` object representing the CosMX experiment\n    \"\"\"\n    return spatialdata_io.cosmx(path, **kwargs)\n</code></pre>"},{"location":"api/io/#sopa.io.macsima","title":"<code>sopa.io.macsima(path, **kwargs)</code>","text":"<p>Read MACSIMA data as a <code>SpatialData</code> object</p> Notes <p>For all dulicated name, their index will be added in brackets after, for instance you will often find <code>DAPI (000)</code> to indicate the DAPI channel of index <code>000</code></p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the directory containing the MACSIMA <code>.tif</code> images</p> required <code>kwargs</code> <code>int</code> <p>Kwargs for <code>_general_tif_directory_reader</code></p> <code>{}</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A <code>SpatialData</code> object with a 2D-image of shape <code>(C, Y, X)</code></p> Source code in <code>sopa/io/imaging.py</code> <pre><code>def macsima(path: Path, **kwargs: int) -&gt; SpatialData:\n    \"\"\"Read MACSIMA data as a `SpatialData` object\n\n    Notes:\n        For all dulicated name, their index will be added in brackets after, for instance you will often find `DAPI (000)` to indicate the DAPI channel of index `000`\n\n    Args:\n        path: Path to the directory containing the MACSIMA `.tif` images\n        kwargs: Kwargs for `_general_tif_directory_reader`\n\n    Returns:\n        A `SpatialData` object with a 2D-image of shape `(C, Y, X)`\n    \"\"\"\n    return _general_tif_directory_reader(\n        path, files_to_channels=_get_channel_names_macsima, **kwargs\n    )\n</code></pre>"},{"location":"api/io/#sopa.io.phenocycler","title":"<code>sopa.io.phenocycler(path, channels_renaming=None, image_models_kwargs=None)</code>","text":"<p>Read Phenocycler data as a <code>SpatialData</code> object</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to a <code>.qptiff</code> file, or a <code>.tif</code> file (if exported from QuPath)</p> required <code>channels_renaming</code> <code>dict | None</code> <p>A dictionnary whose keys correspond to channels and values to their corresponding new name. Not all channels need to be renamed.</p> <code>None</code> <code>image_models_kwargs</code> <code>dict | None</code> <p>Kwargs provided to the <code>Image2DModel</code></p> <code>None</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A <code>SpatialData</code> object with a 2D-image of shape <code>(C, Y, X)</code></p> Source code in <code>sopa/io/imaging.py</code> <pre><code>def phenocycler(\n    path: str | Path, channels_renaming: dict | None = None, image_models_kwargs: dict | None = None\n) -&gt; SpatialData:\n    \"\"\"Read Phenocycler data as a `SpatialData` object\n\n    Args:\n        path: Path to a `.qptiff` file, or a `.tif` file (if exported from QuPath)\n        channels_renaming: A dictionnary whose keys correspond to channels and values to their corresponding new name. Not all channels need to be renamed.\n        image_models_kwargs: Kwargs provided to the `Image2DModel`\n\n    Returns:\n        A `SpatialData` object with a 2D-image of shape `(C, Y, X)`\n    \"\"\"\n    image_models_kwargs = _default_image_models_kwargs(image_models_kwargs)\n\n    path = Path(path)\n    image_name = path.absolute().stem\n\n    if path.suffix == \".qptiff\":\n        with tf.TiffFile(path) as tif:\n            series = tif.series[0]\n            names = _get_channel_names_qptiff(series)\n\n            delayed_image = delayed(lambda series: series.asarray())(tif)\n            image = da.from_delayed(delayed_image, dtype=series.dtype, shape=series.shape)\n    elif path.suffix == \".tif\":\n        image = imread(path)\n        names = _get_IJ_channel_names(path)\n    else:\n        raise ValueError(f\"Unsupported file extension {path.suffix}. Must be '.qptiff' or '.tif'.\")\n\n    names = _rename_channels(names, channels_renaming)\n    image = image.rechunk(chunks=image_models_kwargs[\"chunks\"])\n\n    image = Image2DModel.parse(\n        image,\n        dims=(\"c\", \"y\", \"x\"),\n        transformations={\"pixels\": Identity()},\n        c_coords=names,\n        **image_models_kwargs,\n    )\n\n    return SpatialData(images={image_name: image})\n</code></pre>"},{"location":"api/io/#sopa.io.hyperion","title":"<code>sopa.io.hyperion(path, image_models_kwargs=None, imread_kwargs=None)</code>","text":"<p>Read Hyperion data as a <code>SpatialData</code> object</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the directory containing the Hyperion <code>.tiff</code> images</p> required <code>image_models_kwargs</code> <code>dict | None</code> <p>Kwargs provided to the <code>Image2DModel</code></p> <code>None</code> <code>imread_kwargs</code> <code>dict | None</code> <p>Kwargs provided to <code>dask_image.imread.imread</code></p> <code>None</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A <code>SpatialData</code> object with a 2D-image of shape <code>(C, Y, X)</code></p> Source code in <code>sopa/io/imaging.py</code> <pre><code>def hyperion(\n    path: Path, image_models_kwargs: dict | None = None, imread_kwargs: dict | None = None\n) -&gt; SpatialData:\n    \"\"\"Read Hyperion data as a `SpatialData` object\n\n    Args:\n        path: Path to the directory containing the Hyperion `.tiff` images\n        image_models_kwargs: Kwargs provided to the `Image2DModel`\n        imread_kwargs: Kwargs provided to `dask_image.imread.imread`\n\n    Returns:\n        A `SpatialData` object with a 2D-image of shape `(C, Y, X)`\n    \"\"\"\n    image_models_kwargs = _default_image_models_kwargs(image_models_kwargs)\n    imread_kwargs = {} if imread_kwargs is None else imread_kwargs\n\n    files = [file for file in Path(path).iterdir() if file.suffix == \".tiff\"]\n\n    names = _get_channel_names_hyperion(files)\n    image = da.concatenate(\n        [imread(file, **imread_kwargs) for file in files],\n        axis=0,\n    )\n    image = (image / image.max(axis=(1, 2)).compute()[:, None, None] * 255).astype(np.uint8)\n    image = image.rechunk(chunks=image_models_kwargs[\"chunks\"])\n\n    log.info(f\"Found channel names {names}\")\n\n    image_name = Path(path).absolute().stem\n    image = Image2DModel.parse(\n        image,\n        dims=(\"c\", \"y\", \"x\"),\n        transformations={\"pixels\": Identity()},\n        c_coords=names,\n        **image_models_kwargs,\n    )\n\n    return SpatialData(images={image_name: image})\n</code></pre>"},{"location":"api/io/#sopa.io.ome_tif","title":"<code>sopa.io.ome_tif(path, as_image=False)</code>","text":"<p>Read an <code>.ome.tif</code> image. This image should be a 2D image (with possibly multiple channels). Typically, this function can be used to open Xenium IF images.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the <code>.ome.tif</code> image</p> required <code>as_image</code> <code>bool</code> <p>If <code>True</code>, will return a <code>SpatialImage</code> object</p> <code>False</code> <p>Returns:</p> Type Description <code>SpatialImage | SpatialData</code> <p>A <code>SpatialImage</code> or a <code>SpatialData</code> object</p> Source code in <code>sopa/io/imaging.py</code> <pre><code>def ome_tif(path: Path, as_image: bool = False) -&gt; SpatialImage | SpatialData:\n    \"\"\"Read an `.ome.tif` image. This image should be a 2D image (with possibly multiple channels).\n    Typically, this function can be used to open Xenium IF images.\n\n    Args:\n        path: Path to the `.ome.tif` image\n        as_image: If `True`, will return a `SpatialImage` object\n\n    Returns:\n        A `SpatialImage` or a `SpatialData` object\n    \"\"\"\n    image_models_kwargs = _default_image_models_kwargs(None)\n    image_name = Path(path).absolute().name.split(\".\")[0]\n    image: da.Array = imread(path)\n\n    if image.ndim == 4:\n        assert image.shape[0] == 1, f\"4D images not supported\"\n        image = da.moveaxis(image[0], 2, 0)\n        log.info(f\"Transformed 4D image into a 3D image of shape (c, y, x) = {image.shape}\")\n    elif image.ndim != 3:\n        raise ValueError(f\"Number of dimensions not supported: {image.ndim}\")\n\n    image = image.rechunk(chunks=image_models_kwargs[\"chunks\"])\n\n    channel_names = _ome_channels_names(path)\n    if len(channel_names) != len(image):\n        channel_names = [str(i) for i in range(len(image))]\n        log.warn(f\"Channel names couldn't be read. Using {channel_names} instead.\")\n\n    image = SpatialImage(image, dims=[\"c\", \"y\", \"x\"], name=image_name, coords={\"c\": channel_names})\n\n    if as_image:\n        return image\n\n    image = Image2DModel.parse(\n        image,\n        dims=(\"c\", \"y\", \"x\"),\n        c_coords=channel_names,\n        transformations={\"pixels\": Identity()},\n        **image_models_kwargs,\n    )\n\n    return SpatialData(images={image_name: image})\n</code></pre>"},{"location":"api/io.report/","title":"sopa.io.report","text":""},{"location":"api/io.report/#sopa.io.report.write_report","title":"<code>sopa.io.report.write_report(path, sdata)</code>","text":"<p>Create a HTML report (or web report) after running Sopa.</p> Note <p>This report is automatically generated based on a custom python-to-html engine</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the <code>.html</code> report that has to be created</p> required <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object, after running Sopa</p> required Source code in <code>sopa/io/report/generate.py</code> <pre><code>def write_report(path: str, sdata: SpatialData):\n    \"\"\"Create a HTML report (or web report) after running Sopa.\n\n    Note:\n        This report is automatically generated based on a custom python-to-html engine\n\n    Args:\n        path: Path to the `.html` report that has to be created\n        sdata: A `SpatialData` object, after running Sopa\n    \"\"\"\n    sections = SectionBuilder(sdata).compute_sections()\n\n    log.info(f\"Writing report to {path}\")\n    Root(sections).write(path)\n</code></pre>"},{"location":"api/io.report/#sopa.io.report.engine.Renderable","title":"<code>sopa.io.report.engine.Renderable</code>","text":"<p>Object that can be transformed to string representing HTML</p> Source code in <code>sopa/io/report/engine.py</code> <pre><code>class Renderable:\n    \"\"\"Object that can be transformed to string representing HTML\"\"\"\n\n    @property\n    def children(self) -&gt; list[\"Renderable\"]:\n        if hasattr(self, \"_children\") and self._children is not None:\n            if isinstance(self._children, list):\n                return self._children\n            return [self._children]\n        return []\n\n    @property\n    def children_html(self) -&gt; str:\n        return \"\".join([str(child) for child in self.children])\n\n    def children_rec(self) -&gt; list[\"Renderable\"]:\n        return [self] + [cc for child in self.children for cc in child.children_rec()]\n\n    def __str__(self) -&gt; str:\n        return self.children_html\n</code></pre>"},{"location":"api/io.report/#sopa.io.report.engine.Title","title":"<code>sopa.io.report.engine.Title</code>","text":"<p>             Bases: <code>Renderable</code></p> <p>Report title</p> Source code in <code>sopa/io/report/engine.py</code> <pre><code>class Title(Renderable):\n    \"\"\"Report title\"\"\"\n\n    def __init__(self, text: str, level: int, subtitle: bool = False) -&gt; None:\n        self.text = text\n        self.level = level\n        self.subtitle = subtitle\n\n    def __str__(self) -&gt; str:\n        return f\"\"\"&lt;h1 class=\"{'subtitle' if self.subtitle else 'title'} is-{self.level}\"&gt;{self.text}&lt;/h1&gt;\"\"\"\n</code></pre>"},{"location":"api/io.report/#sopa.io.report.engine.Paragraph","title":"<code>sopa.io.report.engine.Paragraph</code>","text":"<p>             Bases: <code>Renderable</code></p> <p>Report paragraph</p> Source code in <code>sopa/io/report/engine.py</code> <pre><code>class Paragraph(Renderable):\n    \"\"\"Report paragraph\"\"\"\n\n    def __init__(self, text: str) -&gt; None:\n        self.text = text\n\n    def __str__(self) -&gt; str:\n        return f\"\"\"&lt;p&gt;{self.text}&lt;/p&gt;\"\"\"\n</code></pre>"},{"location":"api/io.report/#sopa.io.report.engine.Message","title":"<code>sopa.io.report.engine.Message</code>","text":"<p>             Bases: <code>Renderable</code></p> <p>Colored message</p> Source code in <code>sopa/io/report/engine.py</code> <pre><code>class Message(Renderable):\n    \"\"\"Colored message\"\"\"\n\n    def __init__(self, text: str, is_light: bool = True, color: str = \"primary\") -&gt; None:\n        self.text = text\n        self.color = color\n        self.is_light = is_light\n\n    def __str__(self) -&gt; str:\n        return f\"\"\"\n        &lt;div class='notification is-{self.color} {'is-light' if self.is_light else ''}'&gt;\n            {self.text}\n        &lt;/div&gt;\n        \"\"\"\n</code></pre>"},{"location":"api/io.report/#sopa.io.report.engine.Block","title":"<code>sopa.io.report.engine.Block</code>","text":"<p>             Bases: <code>Renderable</code></p> <p>Block, i.e. padded div</p> Source code in <code>sopa/io/report/engine.py</code> <pre><code>class Block(Renderable):\n    \"\"\"Block, i.e. padded div\"\"\"\n\n    def __init__(self, content: list[Renderable]) -&gt; None:\n        self._children = content\n\n    def __str__(self) -&gt; str:\n        return f\"\"\"&lt;div class=\"block\"&gt;{self.children_html}&lt;/div&gt;\"\"\"\n</code></pre>"},{"location":"api/io.report/#sopa.io.report.engine.CodeBlock","title":"<code>sopa.io.report.engine.CodeBlock</code>","text":"<p>             Bases: <code>Renderable</code></p> <p>Block of code, like in the terminal</p> Source code in <code>sopa/io/report/engine.py</code> <pre><code>class CodeBlock(Renderable):\n    \"\"\"Block of code, like in the terminal\"\"\"\n\n    def __init__(self, text: str) -&gt; None:\n        self.text = text\n\n    def __str__(self) -&gt; str:\n        return f\"\"\"&lt;pre&gt;{self.text}&lt;/pre&gt;\"\"\"\n</code></pre>"},{"location":"api/io.report/#sopa.io.report.engine.ProgressBar","title":"<code>sopa.io.report.engine.ProgressBar</code>","text":"<p>             Bases: <code>Renderable</code></p> <p>Progress bar</p> Source code in <code>sopa/io/report/engine.py</code> <pre><code>class ProgressBar(Renderable):\n    \"\"\"Progress bar\"\"\"\n\n    def __init__(\n        self,\n        value: float,\n        valuemax: int = 1,\n        text: Optional[str] = None,\n        color: str = \"primary\",\n        is_light: bool = False,\n    ) -&gt; None:\n        self.value = value\n        self.valuemax = valuemax\n        self.text = text\n        self.color = color\n        self.is_light = is_light\n\n    def __str__(self) -&gt; str:\n        return f\"\"\"\n        {\"\" if self.text is None else Paragraph(self.text)}\n        &lt;progress class=\"progress is-{self.color} {'is-light' if self.is_light else ''}\"\n            value=\"{self.value}\"\n            max=\"{self.valuemax}\"&gt;{self.value}\n        &lt;/progress&gt;\n    \"\"\"\n</code></pre>"},{"location":"api/io.report/#sopa.io.report.engine.Section","title":"<code>sopa.io.report.engine.Section</code>","text":"<p>             Bases: <code>Renderable</code></p> <p>Section of the report</p> Source code in <code>sopa/io/report/engine.py</code> <pre><code>class Section(Renderable):\n    \"\"\"Section of the report\"\"\"\n\n    def __init__(self, name: str, content: list[\"Section\"] = None) -&gt; None:\n        self.name = name\n        self._children = content\n        self.subtitle = False\n\n    @property\n    def id(self):\n        return self.name.lower().replace(\" \", \"-\")\n\n    def __str__(self) -&gt; str:\n        return f\"\"\"\n        &lt;article class=\"message is-dark\" id=\"{self.id}\"&gt;\n            &lt;div class=\"message-header\"&gt;\n                &lt;p&gt;{self.name}&lt;/p&gt;\n            &lt;/div&gt;\n            &lt;div class=\"message-body\"&gt;\n                {self.children_html}\n            &lt;/div&gt;\n        &lt;/article&gt;\n        \"\"\"\n</code></pre>"},{"location":"api/io.report/#sopa.io.report.engine.SubSection","title":"<code>sopa.io.report.engine.SubSection</code>","text":"<p>             Bases: <code>Section</code></p> <p>Sub-section of the report</p> Source code in <code>sopa/io/report/engine.py</code> <pre><code>class SubSection(Section):\n    \"\"\"Sub-section of the report\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n    def __str__(self) -&gt; str:\n        return f\"\"\"\n        &lt;section id=\"{self.id}\" class=\"py-2\"&gt;\n            {Title(self.name, 4, subtitle=True)}\n            {self.children_html}\n        &lt;/section&gt;\n        \"\"\"\n</code></pre>"},{"location":"api/io.report/#sopa.io.report.engine.NavbarItem","title":"<code>sopa.io.report.engine.NavbarItem</code>","text":"<p>             Bases: <code>Renderable</code></p> <p>One item in the nav bar</p> Source code in <code>sopa/io/report/engine.py</code> <pre><code>class NavbarItem(Renderable):\n    \"\"\"One item in the nav bar\"\"\"\n\n    def __init__(self, section: Section) -&gt; None:\n        self.section = section\n\n    def subsections(self):\n        li = [\n            f\"&lt;li&gt;&lt;a href='#{subsection.id}'&gt;{subsection.name}&lt;/a&gt;&lt;/li&gt;\"\n            for subsection in self.section.children\n        ]\n        return \"\".join(li)\n\n    def __str__(self) -&gt; str:\n        return f\"\"\"\n    &lt;p class=\"menu-label\"&gt;{self.section.name}&lt;/p&gt;\n    &lt;ul class=\"menu-list\"&gt;\n        {self.subsections()}\n    &lt;/ul&gt;\n    \"\"\"\n</code></pre>"},{"location":"api/io.report/#sopa.io.report.engine.Navbar","title":"<code>sopa.io.report.engine.Navbar</code>","text":"<p>             Bases: <code>Renderable</code></p> <p>Left nav bar</p> Source code in <code>sopa/io/report/engine.py</code> <pre><code>class Navbar(Renderable):\n    \"\"\"Left nav bar\"\"\"\n\n    def __init__(self, sections: list[Section]) -&gt; None:\n        self._children = [NavbarItem(section) for section in sections]\n\n    def __str__(self) -&gt; str:\n        return f\"\"\"\n        {Title(\"Sopa report\", 3)}\n        {Message(\"This report was generated &lt;br /&gt;by the &lt;a href='https://github.com/gustaveroussy/sopa'&gt;Sopa&lt;/a&gt; HTML engine.\")}\n        {self.children_html}\n    \"\"\"\n</code></pre>"},{"location":"api/io.report/#sopa.io.report.engine.Columns","title":"<code>sopa.io.report.engine.Columns</code>","text":"<p>             Bases: <code>Renderable</code></p> <p>Flex columns containers</p> Source code in <code>sopa/io/report/engine.py</code> <pre><code>class Columns(Renderable):\n    \"\"\"Flex columns containers\"\"\"\n\n    def __init__(self, content: list[Renderable], is_centered: bool = True) -&gt; None:\n        self._children = content\n        self.is_centered = is_centered\n\n    def __str__(self) -&gt; str:\n        return f\"\"\"\n    &lt;div block style=\"display: flex; {'justify-content: center;' if self.is_centered else ''}\"&gt;\n        {self.children_html}\n    &lt;/div&gt;\n    \"\"\"\n</code></pre>"},{"location":"api/io.report/#sopa.io.report.engine.Image","title":"<code>sopa.io.report.engine.Image</code>","text":"<p>             Bases: <code>Renderable</code></p> <p>Image renderer</p> Source code in <code>sopa/io/report/engine.py</code> <pre><code>class Image(Renderable):\n    \"\"\"Image renderer\"\"\"\n\n    def __init__(\n        self, fig: Figure, width: float = 50, extension: str = \"png\", pretty_legend: bool = True\n    ):\n        self.fig = fig\n        self.width = width\n        self.extension = extension\n        self.pretty_legend = pretty_legend\n\n    def make_figure_pretty(self):\n        if self.pretty_legend and _has_handles(self.fig):\n            self.fig.legend(\n                bbox_to_anchor=(1.04, 0.5), loc=\"center left\", borderaxespad=0, frameon=False\n            )\n        sns.despine(fig=self.fig, offset=10, trim=True)\n\n    def encod(self):\n        self.make_figure_pretty()\n        tmpfile = BytesIO()\n        self.fig.savefig(tmpfile, format=self.extension, transparent=True, bbox_inches=\"tight\")\n        plt.close()\n        return base64.b64encode(tmpfile.getvalue()).decode(\"utf-8\")\n\n    def __str__(self) -&gt; str:\n        return f\"\"\"&lt;img src=\\'data:image/{self.extension};base64,{self.encod()}\\'  width=\"{self.width}%\" height=\"auto\"/&gt;\"\"\"\n</code></pre>"},{"location":"api/io.report/#sopa.io.report.engine.Root","title":"<code>sopa.io.report.engine.Root</code>","text":"<p>             Bases: <code>Renderable</code></p> <p>Whole report generator</p> Source code in <code>sopa/io/report/engine.py</code> <pre><code>class Root(Renderable):\n    \"\"\"Whole report generator\"\"\"\n\n    def __init__(self, sections: list[Section], doc_title: str = \"Sopa report\"):\n        self.doc_title = doc_title\n        self._children = sections\n        self.nav = Navbar(sections)\n\n    def sanity_check(self):\n        section_ids = [section.id for section in self.children]\n        assert len(section_ids) == len(set(section_ids)), \"Sections IDs must be unique\"\n\n        subsections_ids = [sub.id for section in self.children for sub in section.children]\n        assert len(subsections_ids) == len(set(subsections_ids)), \"Subsections IDs must be unique\"\n\n    def write(self, path: str) -&gt; None:\n        self.sanity_check()\n\n        with open(path, \"w\") as f:\n            f.write(str(self))\n\n    def __str__(self) -&gt; str:\n        return f\"\"\"\n    &lt;!DOCTYPE html&gt;\n    &lt;html&gt;\n    &lt;head&gt;\n        &lt;meta charset=\"utf-8\" /&gt;\n        &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" /&gt;\n        &lt;title&gt;{self.doc_title}&lt;/title&gt;\n        &lt;style&gt;\n        {BULMA_CSS}\n        .menu {{\n            position: sticky;\n            flex: 0 0 260px;\n            overflow-y: auto;\n            height: 100vh;\n            top: 0;\n        }}\n        &lt;/style&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;div class=\"is-flex is-flex-direction-row\"&gt;\n            &lt;div class=\"mt-5 ml-5 menu\"&gt;\n                {self.nav}\n            &lt;/div&gt;\n            &lt;div class=\"p-5 block\" style=\"flex: 1; overflow: hidden\"&gt;\n                {self.children_html}\n            &lt;/div&gt;\n        &lt;/div&gt;\n    &lt;/body&gt;\n    &lt;/html&gt;\n    \"\"\"\n</code></pre>"},{"location":"api/spatial/","title":"sopa.spatial","text":""},{"location":"api/spatial/#sopa.spatial.mean_distance","title":"<code>sopa.spatial.mean_distance(adata, group_key, target_group_key=None, ignore_zeros=False)</code>","text":"<p>Mean distance between two groups (typically, between cell-types, or between cell-types and domains)</p> Note <p>The distance is a number of hops, i.e. a distance of 10 between a pDC and a T cell means that there are 10 cells on the closest path from one to the other cell.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object, or a <code>SpatialData object</code></p> required <code>group_key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the groups</p> required <code>target_group_key</code> <code>str | None</code> <p>Key of <code>adata.obs</code> containing the target groups (by default, uses <code>group_key</code>)</p> <code>None</code> <code>ignore_zeros</code> <code>bool</code> <p>If <code>True</code>, a cell distance to its own group is 0.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p><code>DataFrame</code> of shape <code>n_groups * n_groups_target</code> of mean hop-distances</p> Source code in <code>sopa/spatial/distance.py</code> <pre><code>def mean_distance(\n    adata: AnnData, group_key: str, target_group_key: str | None = None, ignore_zeros: bool = False\n) -&gt; pd.DataFrame:\n    \"\"\"Mean distance between two groups (typically, between cell-types, or between cell-types and domains)\n\n    Note:\n        The distance is a number of hops, i.e. a distance of 10 between a pDC and a T cell means that there are 10 cells on the closest path from one to the other cell.\n\n    Args:\n        adata: An `AnnData` object, or a `SpatialData object`\n        group_key: Key of `adata.obs` containing the groups\n        target_group_key: Key of `adata.obs` containing the target groups (by default, uses `group_key`)\n        ignore_zeros: If `True`, a cell distance to its own group is 0.\n\n    Returns:\n        `DataFrame` of shape `n_groups * n_groups_target` of mean hop-distances\n    \"\"\"\n    if isinstance(adata, SpatialData):\n        adata = adata.table\n\n    target_group_key = group_key if target_group_key is None else target_group_key\n\n    df_distances = cells_to_groups(adata, target_group_key, None, ignore_zeros=ignore_zeros)\n\n    if ignore_zeros:\n        df_distances.replace(0, np.nan, inplace=True)\n\n    df_distances[group_key] = adata.obs[group_key]\n    df_distances = df_distances.groupby(group_key, observed=False).mean()\n    df_distances.columns.name = target_group_key\n\n    return df_distances\n</code></pre>"},{"location":"api/spatial/#sopa.spatial.geometrize_niches","title":"<code>sopa.spatial.geometrize_niches(adata, niche_key, buffer='auto', perc_area_th=0.05)</code>","text":"<p>Converts the niches to shapely polygons, and put into a <code>GeoDataFrame</code>. Note that each niche can appear multiple times, as they can be separated by other niches ; in this case, we call them different \"components\" of the same niche ID.</p> Plot components <p>You can show niches components with GeoPandas <pre><code>gdf = geometrize_niches(adata, niche_key)\ngdf.plot(column=niche_key)\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData | SpatialData</code> <p>An <code>AnnData</code> object, or a <code>SpatialData object</code></p> required <code>niche_key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the niches</p> required <code>buffer</code> <code>int | str</code> <p>Expansion radius applied on components. By default, <code>3 * mean_distance_neighbors</code></p> <code>'auto'</code> <code>perc_area_th</code> <code>float</code> <p>For each niche, components whose area is less than <code>perc_area_th * max_component_area</code> will be removed</p> <code>0.05</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>A <code>GeoDataFrame</code> with geometries for each niche component. We also compute the area/perimeter/roundness of each component.</p> Source code in <code>sopa/spatial/morpho.py</code> <pre><code>def geometrize_niches(\n    adata: AnnData | SpatialData,\n    niche_key: str,\n    buffer: int | str = \"auto\",\n    perc_area_th: float = 0.05,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Converts the niches to shapely polygons, and put into a `GeoDataFrame`. Note that each niche can appear multiple times, as they can be separated by other niches ; in this case, we call them different \"components\" of the same niche ID.\n\n    Plot components:\n        You can show niches components with GeoPandas\n        ```py\n        gdf = geometrize_niches(adata, niche_key)\n        gdf.plot(column=niche_key)\n        ```\n\n    Args:\n        adata: An `AnnData` object, or a `SpatialData object`\n        niche_key: Key of `adata.obs` containing the niches\n        buffer: Expansion radius applied on components. By default, `3 * mean_distance_neighbors`\n        perc_area_th: For each niche, components whose area is less than `perc_area_th * max_component_area` will be removed\n\n    Returns:\n        A `GeoDataFrame` with geometries for each niche component. We also compute the area/perimeter/roundness of each component.\n    \"\"\"\n    if isinstance(adata, SpatialData):\n        adata = adata.table\n\n    _check_has_delaunay(adata)\n    data = {\"geometry\": [], niche_key: []}\n\n    delaunay = Delaunay(adata.obsm[\"spatial\"])\n    connectivities = adata.obsp[\"spatial_connectivities\"]\n    values = adata.obs[niche_key].values\n\n    keep = (\n        (connectivities[delaunay.simplices[:, 0], delaunay.simplices[:, 1]].A1 == 1)\n        &amp; (connectivities[delaunay.simplices[:, 0], delaunay.simplices[:, 2]].A1 == 1)\n        &amp; (connectivities[delaunay.simplices[:, 1], delaunay.simplices[:, 2]].A1 == 1)\n        &amp; (values[delaunay.simplices[:, 0]] == values[delaunay.simplices[:, 1]])\n        &amp; (values[delaunay.simplices[:, 0]] == values[delaunay.simplices[:, 2]])\n        &amp; (values[delaunay.simplices[:, 0]] == values[delaunay.simplices[:, 2]])\n    )  # Keep simplices that are in the original Delaunay graph, and which are not in between different value categories\n\n    neighbors = np.where(np.isin(delaunay.neighbors, np.where(~keep)[0]), -1, delaunay.neighbors)\n\n    simplices_to_visit = set(np.where(keep)[0])\n\n    while simplices_to_visit:\n        component = Component(adata, delaunay, neighbors)\n        component.visit(simplices_to_visit)\n\n        data[\"geometry\"].append(component.polygon)\n        data[niche_key].append(values[component.first_vertex_index()])\n\n    gdf = gpd.GeoDataFrame(data)\n\n    if buffer is not None and buffer != 0:\n        gdf = _clean_components(adata, gdf, niche_key, buffer)\n\n    gdf[SopaKeys.GEOMETRY_LENGTH] = gdf.length\n    gdf[SopaKeys.GEOMETRY_AREA] = gdf.area\n    gdf[SopaKeys.GEOMETRY_ROUNDNESS] = (\n        4 * np.pi * gdf[SopaKeys.GEOMETRY_AREA] / gdf[SopaKeys.GEOMETRY_LENGTH] ** 2\n    )\n\n    # Remove minor components (compared to the largest component of its corresponding niche)\n    gdf = gdf[gdf.area &gt;= gdf[niche_key].map(gdf.groupby(niche_key).area.max() * perc_area_th)]\n\n    return gdf\n</code></pre>"},{"location":"api/spatial/#sopa.spatial.niches_geometry_stats","title":"<code>sopa.spatial.niches_geometry_stats(adata, niche_key, aggregation='min', key_added_suffix='_distance_to_niche_', **geometrize_niches_kwargs)</code>","text":"<p>Computes statistics over niches geometries</p> Details <ul> <li><code>n_components</code>: Number of connected component of a niche (a component is a group of neighbor cells with the same niche attribute)</li> <li><code>length</code>: Mean distance of the exterior/boundary of the components of a niche</li> <li><code>area</code>: Mean area of the components of a niche</li> <li><code>roundness</code>: Float value between 0 and 1. The higher the value, the closer to a circle. Computed via <code>4 * pi * area / length**2</code></li> <li><code>mean_distance_to_niche_X</code>: mean distance to the niche (between the two closest points of the niches)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData | SpatialData</code> <p>An <code>AnnData</code> object, or a <code>SpatialData object</code></p> required <code>niche_key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the niches</p> required <code>aggregation</code> <code>str | list[str]</code> <p>Aggregation mode. Either one string such as <code>\"min\"</code>, or a list such as <code>[\"mean\", \"min\"]</code>.</p> <code>'min'</code> <code>key_added_suffix</code> <code>str</code> <p>Suffix added in the DataFrame columns. Defaults to \"distance_to_niche\".</p> <code>'_distance_to_niche_'</code> <code>geometrize_niches_kwargs</code> <code>str</code> <p>Kwargs to the <code>sopa.spatial.geometrize_niches</code> function</p> <code>{}</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>A <code>DataFrame</code> of shape <code>n_niches * n_statistics</code></p> Source code in <code>sopa/spatial/morpho.py</code> <pre><code>def niches_geometry_stats(\n    adata: AnnData | SpatialData,\n    niche_key: str,\n    aggregation: str | list[str] = \"min\",\n    key_added_suffix: str = \"_distance_to_niche_\",\n    **geometrize_niches_kwargs: str,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Computes statistics over niches geometries\n\n    Details:\n        - `n_components`: Number of connected component of a niche (a component is a group of neighbor cells with the same niche attribute)\n        - `length`: Mean distance of the exterior/boundary of the components of a niche\n        - `area`: Mean area of the components of a niche\n        - `roundness`: Float value between 0 and 1. The higher the value, the closer to a circle. Computed via `4 * pi * area / length**2`\n        - `mean_distance_to_niche_X`: mean distance to the niche (between the two closest points of the niches)\n\n    Args:\n        adata: An `AnnData` object, or a `SpatialData object`\n        niche_key: Key of `adata.obs` containing the niches\n        aggregation: Aggregation mode. Either one string such as `\"min\"`, or a list such as `[\"mean\", \"min\"]`.\n        key_added_suffix: Suffix added in the DataFrame columns. Defaults to \"_distance_to_niche_\".\n        geometrize_niches_kwargs: Kwargs to the `sopa.spatial.geometrize_niches` function\n\n    Returns:\n        A `DataFrame` of shape `n_niches * n_statistics`\n    \"\"\"\n    if isinstance(adata, SpatialData):\n        adata = adata.table\n\n    gdf = geometrize_niches(adata, niche_key, **geometrize_niches_kwargs)\n    value_counts = gdf[niche_key].value_counts()\n\n    assert len(gdf), f\"No niche geometry found, stats can't be computed\"\n\n    log.info(f\"Computing pairwise distances between {len(gdf)} components\")\n    pairwise_distances: pd.DataFrame = gdf.geometry.apply(lambda g: gdf.distance(g))\n    pairwise_distances[niche_key] = gdf[niche_key]\n\n    if isinstance(aggregation, str):\n        aggregation = [aggregation]\n\n    for aggr in aggregation:\n        df = pairwise_distances.groupby(niche_key).aggregate(aggr).T\n        df.columns = [f\"{aggr}{key_added_suffix}{c}\" for c in df.columns]\n        gdf[df.columns] = df\n\n    df_stats: pd.DataFrame = gdf.groupby(niche_key)[gdf.columns[2:]].mean()\n    df_stats.insert(0, SopaKeys.GEOMETRY_COUNT, value_counts)\n\n    return df_stats\n</code></pre>"},{"location":"api/spatial/#sopa.spatial.cells_to_groups","title":"<code>sopa.spatial.cells_to_groups(adata, group_key, key_added_prefix=None, ignore_zeros=False)</code>","text":"<p>Compute the hop-distance between each cell and a cell category/group.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object, or a <code>SpatialData object</code></p> required <code>group_key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the groups</p> required <code>key_added_prefix</code> <code>str | None</code> <p>Prefix to the key added in <code>adata.obsm</code>. If <code>None</code>, will return the <code>DataFrame</code> instead of saving it.</p> <code>None</code> <code>ignore_zeros</code> <code>bool</code> <p>If <code>True</code>, a cell distance to its own group is 0.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame | None</code> <p>A <code>Dataframe</code> of shape <code>n_obs * n_groups</code>, or <code>None</code> if <code>key_added_prefix</code> was provided (in this case, the dataframe is saved in <code>\"{key_added_prefix}{group_key}\"</code>)</p> Source code in <code>sopa/spatial/distance.py</code> <pre><code>def cells_to_groups(\n    adata: AnnData,\n    group_key: str,\n    key_added_prefix: str | None = None,\n    ignore_zeros: bool = False,\n) -&gt; pd.DataFrame | None:\n    \"\"\"Compute the hop-distance between each cell and a cell category/group.\n\n    Args:\n        adata: An `AnnData` object, or a `SpatialData object`\n        group_key: Key of `adata.obs` containing the groups\n        key_added_prefix: Prefix to the key added in `adata.obsm`. If `None`, will return the `DataFrame` instead of saving it.\n        ignore_zeros: If `True`, a cell distance to its own group is 0.\n\n    Returns:\n        A `Dataframe` of shape `n_obs * n_groups`, or `None` if `key_added_prefix` was provided (in this case, the dataframe is saved in `\"{key_added_prefix}{group_key}\"`)\n    \"\"\"\n    if isinstance(adata, SpatialData):\n        adata = adata.table\n\n    _check_has_delaunay(adata)\n\n    distances_to_groups = {}\n\n    if not adata.obs[group_key].dtype.name == \"category\":\n        log.info(f\"Converting adata.obs['{group_key}'] to category\")\n        adata.obs[group_key] = adata.obs[group_key].astype(\"category\")\n\n    for group_id in tqdm(adata.obs[group_key].cat.categories):\n        group_nodes = np.where(adata.obs[group_key] == group_id)[0]\n\n        distances = np.full(adata.n_obs, np.nan)\n\n        if not ignore_zeros:\n            distances[group_nodes] = 0\n            visited = set(group_nodes)\n        else:\n            visited = set()\n\n        queue = group_nodes\n        current_distance = 0\n\n        while len(queue):\n            distances[queue] = current_distance\n\n            neighbors = set(adata.obsp[\"spatial_connectivities\"][queue].indices)\n            queue = np.array(list(neighbors - visited))\n            visited |= neighbors\n\n            current_distance += 1\n\n        distances_to_groups[group_id] = distances\n\n    df_distances = pd.DataFrame(distances_to_groups, index=adata.obs_names)\n\n    if key_added_prefix is None:\n        return df_distances\n    adata.obsm[f\"{key_added_prefix}{group_key}\"] = df_distances\n</code></pre>"},{"location":"api/spatial/#sopa.spatial.spatial_neighbors","title":"<code>sopa.spatial.spatial_neighbors(adata, radius, library_key=None, percentile=None, set_diag=False)</code>","text":"<p>Create a Delaunay graph from spatial coordinates. This function comes from squidpy.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData | SpatialData</code> <p>AnnData object</p> required <code>radius</code> <code>tuple[float, float] | None</code> <p>tuple that prunes the final graph to only contain edges in interval <code>[min(radius), max(radius)]</code>. If <code>None</code>, all edges are kept.</p> required <code>library_key</code> <code>str | None</code> <p>Optional batch key in adata.obs</p> <code>None</code> <code>percentile</code> <code>float | None</code> <p>Percentile of the distances to use as threshold.</p> <code>None</code> <code>set_diag</code> <code>bool</code> <p>Whether to set the diagonal of the spatial connectivities to <code>1.0</code>.</p> <code>False</code> Source code in <code>sopa/spatial/_build.py</code> <pre><code>def spatial_neighbors(\n    adata: AnnData | SpatialData,\n    radius: tuple[float, float] | None,\n    library_key: str | None = None,\n    percentile: float | None = None,\n    set_diag: bool = False,\n):\n    \"\"\"Create a Delaunay graph from spatial coordinates. This function comes from [squidpy](https://squidpy.readthedocs.io/en/latest/api/squidpy.gr.spatial_neighbors.html#squidpy.gr.spatial_neighbors).\n\n    Args:\n        adata: AnnData object\n        radius: tuple that prunes the final graph to only contain edges in interval `[min(radius), max(radius)]`. If `None`, all edges are kept.\n        library_key: Optional batch key in adata.obs\n        percentile: Percentile of the distances to use as threshold.\n        set_diag: Whether to set the diagonal of the spatial connectivities to `1.0`.\n    \"\"\"\n    if isinstance(adata, SpatialData):\n        adata = adata.table\n\n    assert (\n        radius is None or len(radius) == 2\n    ), f\"Radius is expected to be a tuple (min_radius, max_radius)\"\n\n    log.info(\"Computing delaunay graph\")\n\n    if library_key is not None:\n        assert adata.obs[library_key].dtype == \"category\"\n        libs = adata.obs[library_key].cat.categories\n        make_index_unique(adata.obs_names)\n    else:\n        libs = [None]\n\n    _build_fun = partial(\n        _spatial_neighbor,\n        set_diag=set_diag,\n        radius=radius,\n        percentile=percentile,\n    )\n\n    if library_key is not None:\n        mats: list[tuple[spmatrix, spmatrix]] = []\n        ixs = []  # type: ignore[var-annotated]\n        for lib in libs:\n            ixs.extend(np.where(adata.obs[library_key] == lib)[0])\n            mats.append(_build_fun(adata[adata.obs[library_key] == lib]))\n        ixs = np.argsort(ixs)  # type: ignore[assignment] # invert\n        Adj = block_diag([m[0] for m in mats], format=\"csr\")[ixs, :][:, ixs]\n        Dst = block_diag([m[1] for m in mats], format=\"csr\")[ixs, :][:, ixs]\n    else:\n        Adj, Dst = _build_fun(adata)\n\n    adata.obsp[\"spatial_connectivities\"] = Adj\n    adata.obsp[\"spatial_distances\"] = Dst\n</code></pre>"},{"location":"api/spatial/#sopa.spatial.prepare_network","title":"<code>sopa.spatial.prepare_network(adata, cell_type_key, niche_key, clip_weight=3, node_colors=('#5c7dc4', '#f05541'), node_sizes=(1.3, 5))</code>","text":"<p>Create a dataframe representing weights between cell-types and/or niches. This can be later use to plot a cell-type/niche represention of a whole slide using the netgraph library.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object</p> required <code>cell_type_key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the cell types</p> required <code>niche_key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the niches</p> required <code>clip_weight</code> <code>float</code> <p>Maximum weight</p> <code>3</code> <code>node_colors</code> <code>tuple[str]</code> <p>Tuple of (cell-type color, niche color)</p> <code>('#5c7dc4', '#f05541')</code> <code>node_sizes</code> <code>float</code> <p>Tuple of (cell-type size, niche size)</p> <code>(1.3, 5)</code> <p>Returns:</p> Type Description <code>tuple[DataFrame, dict, dict, dict]</code> <p>A DataFrame of weights between cell-types and/or niches, and three dict for netgraph display</p> Source code in <code>sopa/spatial/distance.py</code> <pre><code>def prepare_network(\n    adata: AnnData,\n    cell_type_key: str,\n    niche_key: str,\n    clip_weight: float = 3,\n    node_colors: tuple[str] = (\"#5c7dc4\", \"#f05541\"),\n    node_sizes: float = (1.3, 5),\n) -&gt; tuple[pd.DataFrame, dict, dict, dict]:\n    \"\"\"Create a dataframe representing weights between cell-types and/or niches.\n    This can be later use to plot a cell-type/niche represention of a whole slide\n    using the netgraph library.\n\n    Args:\n        adata: An `AnnData` object\n        cell_type_key: Key of `adata.obs` containing the cell types\n        niche_key: Key of `adata.obs` containing the niches\n        clip_weight: Maximum weight\n        node_colors: Tuple of (cell-type color, niche color)\n        node_sizes: Tuple of (cell-type size, niche size)\n\n    Returns:\n        A DataFrame of weights between cell-types and/or niches, and three dict for netgraph display\n    \"\"\"\n    node_color, node_size, node_shape = {}, {}, {}\n\n    log.info(\"Computing all distances for the 4 pairs of categories\")\n    weights = mean_distance(adata, cell_type_key)\n    top_right = mean_distance(adata, cell_type_key, niche_key)\n    bottom_left = mean_distance(adata, niche_key, cell_type_key)\n    bottom_right = mean_distance(adata, niche_key, niche_key)\n\n    for pop in weights.index:\n        node_color[pop] = node_colors[0]\n        node_size[pop] = node_sizes[0]\n        node_shape[pop] = \"o\"\n\n    for niche in bottom_right.index:\n        node_color[niche] = node_colors[1]\n        node_size[niche] = node_sizes[1]\n        node_shape[niche] = \"h\"\n\n    # assemble dataframe per-block\n    bottom_left[bottom_right.columns] = bottom_right\n    weights[top_right.columns] = top_right\n    weights = pd.concat([weights, bottom_left], axis=0).copy()\n\n    # convert distances to symmetric weights\n    weights = 1 / weights\n    np.fill_diagonal(weights.values, 0)\n    weights = weights.clip(0, clip_weight)\n    weights = (weights.T + weights) / 2\n\n    return weights, node_color, node_size, node_shape\n</code></pre>"},{"location":"api/annotation/fluorescence/","title":"sopa.annotation.fluorescence","text":""},{"location":"api/annotation/fluorescence/#sopa.annotation.higher_z_score","title":"<code>sopa.annotation.higher_z_score(adata, marker_cell_dict, cell_type_key='cell_type')</code>","text":"<p>Simple channel-based segmentation using a marker-to-population dictionary</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object</p> required <code>marker_cell_dict</code> <code>dict</code> <p>Dictionary whose keys are channels, and values are the corresponding populations.</p> required <code>cell_type_key</code> <code>str</code> <p>Key of <code>adata.obs</code> where annotations will be stored</p> <code>'cell_type'</code> Source code in <code>sopa/annotation/fluorescence.py</code> <pre><code>def higher_z_score(adata: AnnData, marker_cell_dict: dict, cell_type_key: str = \"cell_type\"):\n    \"\"\"Simple channel-based segmentation using a marker-to-population dictionary\n\n    Args:\n        adata: An `AnnData` object\n        marker_cell_dict: Dictionary whose keys are channels, and values are the corresponding populations.\n        cell_type_key: Key of `adata.obs` where annotations will be stored\n    \"\"\"\n    adata.obsm[SopaKeys.Z_SCORES] = preprocess_fluo(adata)\n\n    markers, cell_types = list(marker_cell_dict.keys()), np.array(list(marker_cell_dict.values()))\n    ct_indices = adata.obsm[SopaKeys.Z_SCORES][markers].values.argmax(1)\n\n    adata.obs[cell_type_key] = cell_types[ct_indices]\n    adata.uns[SopaKeys.UNS_KEY][SopaKeys.UNS_CELL_TYPES] = [cell_type_key]\n\n    log.info(f\"Annotation counts: {adata.obs[cell_type_key].value_counts()}\")\n</code></pre>"},{"location":"api/annotation/fluorescence/#sopa.annotation.preprocess_fluo","title":"<code>sopa.annotation.preprocess_fluo(adata)</code>","text":"<p>Preprocess fluorescence data. For each column \\(X\\), we compute \\(asinh(\\frac{X}{5Q(0.2, X)})\\) and apply standardization</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A dataframe of preprocessed channels intensities</p> Source code in <code>sopa/annotation/fluorescence.py</code> <pre><code>def preprocess_fluo(adata: AnnData) -&gt; pd.DataFrame:\n    \"\"\"Preprocess fluorescence data. For each column $X$, we compute $asinh(\\\\frac{X}{5Q(0.2, X)})$ and apply standardization\n\n    Args:\n        adata: An `AnnData` object\n\n    Returns:\n        A dataframe of preprocessed channels intensities\n    \"\"\"\n    if SopaKeys.INTENSITIES_OBSM in adata.obsm:\n        df = adata.obsm[SopaKeys.INTENSITIES_OBSM]\n    else:\n        df = adata.to_df()\n\n    divider = 5 * np.quantile(df, 0.2, axis=0)\n    divider[divider == 0] = df.max(axis=0)[divider == 0]\n\n    scaled = np.arcsinh(df / divider)\n    return (scaled - scaled.mean(0)) / scaled.std(0)\n</code></pre>"},{"location":"api/annotation/tangram/","title":"sopa.annotation.tangram","text":""},{"location":"api/annotation/tangram/#sopa.annotation.tangram.tangram_annotate","title":"<code>sopa.annotation.tangram.tangram_annotate(sdata, adata_sc, cell_type_key, reference_preprocessing=None, bag_size=10000, max_obs_reference=10000, **kwargs)</code>","text":"<p>Tangram multi-level annotation. Tangram is run on multiple bags of cells to decrease the RAM usage.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>adata_sc</code> <code>AnnData</code> <p>A scRNAseq annotated reference</p> required <code>cell_type_key</code> <code>str</code> <p>Key of <code>adata_sc.obs</code> containing the cell types. For multi-level annotation, provide other levels like such: if <code>cell_type_key = \"ct\"</code>, then <code>\"ct_level1\"</code> and <code>\"ct_level2\"</code> are the two next levels</p> required <code>reference_preprocessing</code> <code>str</code> <p>Preprocessing method used on the reference. Can be <code>\"log1p\"</code> (normalize_total + log1p) or <code>\"normalized\"</code> (just normalize_total). By default, consider that no processing was applied (raw counts)</p> <code>None</code> <code>bag_size</code> <code>int</code> <p>Size of each bag on which tangram will be run. Use smaller bags to lower the RAM usage</p> <code>10000</code> <code>max_obs_reference</code> <code>int</code> <p>Maximum number of cells used in <code>adata_sc</code> at each level. Decrease it to lower the RAM usage.</p> <code>10000</code> Source code in <code>sopa/annotation/tangram/run.py</code> <pre><code>def tangram_annotate(\n    sdata: SpatialData,\n    adata_sc: AnnData,\n    cell_type_key: str,\n    reference_preprocessing: str = None,\n    bag_size: int = 10_000,\n    max_obs_reference: int = 10_000,\n    **kwargs,\n):\n    \"\"\"Tangram multi-level annotation. Tangram is run on multiple bags of cells to decrease the RAM usage.\n\n    Args:\n        sdata: A `SpatialData` object\n        adata_sc: A scRNAseq annotated reference\n        cell_type_key: Key of `adata_sc.obs` containing the cell types. For multi-level annotation, provide other levels like such: if `cell_type_key = \"ct\"`, then `\"ct_level1\"` and `\"ct_level2\"` are the two next levels\n        reference_preprocessing: Preprocessing method used on the reference. Can be `\"log1p\"` (normalize_total + log1p) or `\"normalized\"` (just normalize_total). By default, consider that no processing was applied (raw counts)\n        bag_size: Size of each bag on which tangram will be run. Use smaller bags to lower the RAM usage\n        max_obs_reference: Maximum number of cells used in `adata_sc` at each level. Decrease it to lower the RAM usage.\n    \"\"\"\n    ad_sp = sdata.table\n\n    MultiLevelAnnotation(\n        ad_sp,\n        adata_sc,\n        cell_type_key,\n        reference_preprocessing,\n        bag_size,\n        max_obs_reference,\n        **kwargs,\n    ).run()\n</code></pre>"},{"location":"api/segmentation/aggregate/","title":"sopa.segmentation.aggregate","text":""},{"location":"api/segmentation/aggregate/#sopa.segmentation.aggregate.average_channels","title":"<code>sopa.segmentation.aggregate.average_channels(sdata, image_key=None, shapes_key=None, expand_radius_ratio=0)</code>","text":"<p>Average channel intensities per cell.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>image_key</code> <code>str</code> <p>Key of <code>sdata</code> containing the image. If only one <code>images</code> element, this does not have to be provided.</p> <code>None</code> <code>shapes_key</code> <code>str</code> <p>Key of <code>sdata</code> containing the cell boundaries. If only one <code>shapes</code> element, this does not have to be provided.</p> <code>None</code> <code>expand_radius_ratio</code> <code>float</code> <p>Cells polygons will be expanded by <code>expand_radius_ratio * mean_radius</code>. This help better aggregate boundary stainings.</p> <code>0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A numpy <code>ndarray</code> of shape <code>(n_cells, n_channels)</code></p> Source code in <code>sopa/segmentation/aggregate.py</code> <pre><code>def average_channels(\n    sdata: SpatialData,\n    image_key: str = None,\n    shapes_key: str = None,\n    expand_radius_ratio: float = 0,\n) -&gt; np.ndarray:\n    \"\"\"Average channel intensities per cell.\n\n    Args:\n        sdata: A `SpatialData` object\n        image_key: Key of `sdata` containing the image. If only one `images` element, this does not have to be provided.\n        shapes_key: Key of `sdata` containing the cell boundaries. If only one `shapes` element, this does not have to be provided.\n        expand_radius_ratio: Cells polygons will be expanded by `expand_radius_ratio * mean_radius`. This help better aggregate boundary stainings.\n\n    Returns:\n        A numpy `ndarray` of shape `(n_cells, n_channels)`\n    \"\"\"\n    image = get_spatial_image(sdata, image_key)\n\n    geo_df = get_element(sdata, \"shapes\", shapes_key)\n    geo_df = to_intrinsic(sdata, geo_df, image)\n\n    expand_radius = expand_radius_ratio * np.mean(np.sqrt(geo_df.area / np.pi))\n\n    if expand_radius &gt; 0:\n        geo_df = geo_df.buffer(expand_radius)\n\n    log.info(\n        f\"Averaging channels intensity over {len(geo_df)} cells with expansion {expand_radius}\"\n    )\n    return _average_channels_aligned(image, geo_df)\n</code></pre>"},{"location":"api/segmentation/aggregate/#sopa.segmentation.aggregate._average_channels_aligned","title":"<code>sopa.segmentation.aggregate._average_channels_aligned(image, geo_df)</code>","text":"<p>Average channel intensities per cell. The image and cells have to be aligned, i.e. be on the same coordinate system.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>SpatialImage</code> <p>A <code>SpatialImage</code> of shape <code>(n_channels, y, x)</code></p> required <code>geo_df</code> <code>GeoDataFrame | list[Polygon]</code> <p>A <code>GeoDataFrame</code> whose geometries are cell boundaries (polygons)</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A numpy <code>ndarray</code> of shape <code>(n_cells, n_channels)</code></p> Source code in <code>sopa/segmentation/aggregate.py</code> <pre><code>def _average_channels_aligned(\n    image: SpatialImage, geo_df: gpd.GeoDataFrame | list[Polygon]\n) -&gt; np.ndarray:\n    \"\"\"Average channel intensities per cell. The image and cells have to be aligned, i.e. be on the same coordinate system.\n\n    Args:\n        image: A `SpatialImage` of shape `(n_channels, y, x)`\n        geo_df: A `GeoDataFrame` whose geometries are cell boundaries (polygons)\n\n    Returns:\n        A numpy `ndarray` of shape `(n_cells, n_channels)`\n    \"\"\"\n    cells = geo_df if isinstance(geo_df, list) else list(geo_df.geometry)\n    tree = shapely.STRtree(cells)\n\n    intensities = np.zeros((len(cells), len(image.coords[\"c\"])))\n    areas = np.zeros(len(cells))\n\n    def func(chunk, block_info=None):\n        if block_info is not None:\n            (ymin, ymax), (xmin, xmax) = block_info[0][\"array-location\"][1:]\n            patch = box(xmin, ymin, xmax, ymax)\n            intersections = tree.query(patch, predicate=\"intersects\")\n\n            for index in intersections:\n                cell = cells[index]\n                bounds = shapes.pixel_outer_bounds(cell.bounds)\n\n                sub_image = chunk[\n                    :,\n                    max(bounds[1] - ymin, 0) : bounds[3] - ymin,\n                    max(bounds[0] - xmin, 0) : bounds[2] - xmin,\n                ]\n\n                if sub_image.shape[1] == 0 or sub_image.shape[2] == 0:\n                    continue\n\n                mask = shapes.rasterize(cell, sub_image.shape[1:], bounds)\n\n                intensities[index] += np.sum(sub_image * mask, axis=(1, 2))\n                areas[index] += np.sum(mask)\n        return da.zeros(chunk.shape[1:])\n\n    with ProgressBar():\n        image.data.map_blocks(func, drop_axis=0).compute()\n\n    return intensities / areas[:, None].clip(1)\n</code></pre>"},{"location":"api/segmentation/aggregate/#sopa.segmentation.aggregate.count_transcripts","title":"<code>sopa.segmentation.aggregate.count_transcripts(sdata, gene_column, shapes_key=None, points_key=None, geo_df=None)</code>","text":"<p>Counts transcripts per cell.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>gene_column</code> <code>str</code> <p>Column of the transcript dataframe containing the gene names</p> required <code>shapes_key</code> <code>str</code> <p>Key of <code>sdata</code> containing the cell boundaries. If only one <code>shapes</code> element, this does not have to be provided.</p> <code>None</code> <code>points_key</code> <code>str</code> <p>Key of <code>sdata</code> containing the transcripts. If only one <code>points</code> element, this does not have to be provided.</p> <code>None</code> <code>geo_df</code> <code>GeoDataFrame</code> <p>If the cell boundaries are not yet in <code>sdata</code>, a <code>GeoDataFrame</code> can be directly provided for cell boundaries</p> <code>None</code> <p>Returns:</p> Type Description <code>AnnData</code> <p>An <code>AnnData</code> object of shape <code>(n_cells, n_genes)</code> with the counts per cell</p> Source code in <code>sopa/segmentation/aggregate.py</code> <pre><code>def count_transcripts(\n    sdata: SpatialData,\n    gene_column: str,\n    shapes_key: str = None,\n    points_key: str = None,\n    geo_df: gpd.GeoDataFrame = None,\n) -&gt; AnnData:\n    \"\"\"Counts transcripts per cell.\n\n    Args:\n        sdata: A `SpatialData` object\n        gene_column: Column of the transcript dataframe containing the gene names\n        shapes_key: Key of `sdata` containing the cell boundaries. If only one `shapes` element, this does not have to be provided.\n        points_key: Key of `sdata` containing the transcripts. If only one `points` element, this does not have to be provided.\n        geo_df: If the cell boundaries are not yet in `sdata`, a `GeoDataFrame` can be directly provided for cell boundaries\n\n    Returns:\n        An `AnnData` object of shape `(n_cells, n_genes)` with the counts per cell\n    \"\"\"\n    points_key, points = get_item(sdata, \"points\", points_key)\n\n    if geo_df is None:\n        geo_df = get_element(sdata, \"shapes\", shapes_key)\n        geo_df = to_intrinsic(sdata, geo_df, points_key)\n\n    log.info(f\"Aggregating transcripts over {len(geo_df)} cells\")\n    return _count_transcripts_aligned(geo_df, points, gene_column)\n</code></pre>"},{"location":"api/segmentation/aggregate/#sopa.segmentation.aggregate._count_transcripts_aligned","title":"<code>sopa.segmentation.aggregate._count_transcripts_aligned(geo_df, points, value_key)</code>","text":"<p>Count transcripts per cell. The cells and points have to be aligned (i.e., in the same coordinate system)</p> <p>Parameters:</p> Name Type Description Default <code>geo_df</code> <code>GeoDataFrame</code> <p>Cells geometries</p> required <code>points</code> <code>DataFrame</code> <p>Transcripts dataframe</p> required <code>value_key</code> <code>str</code> <p>Key of <code>points</code> containing the genes names</p> required <p>Returns:</p> Type Description <code>AnnData</code> <p>An <code>AnnData</code> object of shape <code>(n_cells, n_genes)</code> with the counts per cell</p> Source code in <code>sopa/segmentation/aggregate.py</code> <pre><code>def _count_transcripts_aligned(\n    geo_df: gpd.GeoDataFrame, points: dd.DataFrame, value_key: str\n) -&gt; AnnData:\n    \"\"\"Count transcripts per cell. The cells and points have to be aligned (i.e., in the same coordinate system)\n\n    Args:\n        geo_df: Cells geometries\n        points: Transcripts dataframe\n        value_key: Key of `points` containing the genes names\n\n    Returns:\n        An `AnnData` object of shape `(n_cells, n_genes)` with the counts per cell\n    \"\"\"\n    points[value_key] = points[value_key].astype(\"category\").cat.as_known()\n    gene_names = points[value_key].cat.categories.astype(str)\n\n    X = coo_matrix((len(geo_df), len(gene_names)), dtype=int)\n    adata = AnnData(X=X, var=pd.DataFrame(index=gene_names))\n    adata.obs_names = geo_df.index\n\n    geo_df = geo_df.reset_index()\n\n    with ProgressBar():\n        points.map_partitions(\n            partial(_add_coo, adata, geo_df, gene_column=value_key, gene_names=gene_names),\n            meta=(),\n        ).compute()\n\n    adata.X = adata.X.tocsr()\n    return adata\n</code></pre>"},{"location":"api/segmentation/aggregate/#sopa.segmentation.aggregate.Aggregator","title":"<code>sopa.segmentation.aggregate.Aggregator</code>","text":"<p>Perform transcript count and channel averaging over a <code>SpatialData</code> object</p> Source code in <code>sopa/segmentation/aggregate.py</code> <pre><code>class Aggregator:\n    \"\"\"Perform transcript count and channel averaging over a `SpatialData` object\"\"\"\n\n    def __init__(\n        self,\n        sdata: SpatialData,\n        overwrite: bool = True,\n        image_key: str | None = None,\n        shapes_key: str | None = None,\n    ):\n        \"\"\"\n        Args:\n            sdata: A `SpatialData` object\n            overwrite: If `True`, will overwrite `sdata.table` if already existing\n            image_key: Key of `sdata` with the image to be averaged. If only one image, this does not have to be provided.\n            shapes_key: Key of `sdata` with the shapes corresponding to the cells boundaries\n        \"\"\"\n        self.sdata = sdata\n        self.overwrite = overwrite\n\n        self.image_key, self.image = get_spatial_image(sdata, image_key, return_key=True)\n\n        if shapes_key is None:\n            self.shapes_key, self.geo_df = get_boundaries(sdata, return_key=True)\n        else:\n            self.shapes_key = shapes_key\n            self.geo_df = self.sdata[shapes_key]\n\n        if sdata.table is not None and len(self.geo_df) != sdata.table.n_obs:\n            log.warn(\n                f\"Table already existing with {sdata.table.n_obs} obs, but aggregating on {len(self.geo_df)} cells. Deleting table.\"\n            )\n            del sdata.table\n\n        self.table = sdata.table\n\n    def standardize_table(self):\n        self.table.obs_names = list(map(str_cell_id, range(self.table.n_obs)))\n\n        self.table.obsm[\"spatial\"] = np.array(\n            [[centroid.x, centroid.y] for centroid in self.geo_df.centroid]\n        )\n        self.table.obs[SopaKeys.REGION_KEY] = pd.Series(\n            self.shapes_key, index=self.table.obs_names, dtype=\"category\"\n        )\n        self.table.obs[SopaKeys.SLIDE_KEY] = pd.Series(\n            self.image_key, index=self.table.obs_names, dtype=\"category\"\n        )\n        self.table.obs[SopaKeys.INSTANCE_KEY] = self.geo_df.index\n\n        if \"spatialdata_attrs\" in self.table.uns:\n            del self.table.uns[\"spatialdata_attrs\"]\n\n        self.table = TableModel.parse(\n            self.table,\n            region_key=SopaKeys.REGION_KEY,\n            region=self.shapes_key,\n            instance_key=SopaKeys.INSTANCE_KEY,\n        )\n\n    def filter_cells(self, where_filter: np.ndarray):\n        log.info(f\"Filtering {where_filter.sum()} cells\")\n\n        self.geo_df = self.geo_df[~where_filter]\n        self.sdata.add_shapes(self.shapes_key, self.geo_df, overwrite=True)\n\n        if self.table is not None:\n            self.table = self.table[~where_filter]\n\n    def save_table(self):\n        if self.sdata.table is not None and self.overwrite:\n            del self.sdata.table\n        self.sdata.table = self.table\n\n    def update_table(\n        self,\n        gene_column: str | None = None,\n        average_intensities: bool = True,\n        expand_radius_ratio: float = 0,\n        min_transcripts: int = 0,\n        min_intensity_ratio: float = 0,\n    ):\n        \"\"\"Perform aggregation and update the spatialdata table\n\n        Args:\n            gene_column: Column key of the transcript dataframe containing the gene names\n            average_intensities: Whether to average the channels intensities inside cells polygons\n            expand_radius_ratio: Cells polygons will be expanded by `expand_radius_ratio * mean_radius` for channels averaging **only**. This help better aggregate boundary stainings\n            min_transcripts: Minimum amount of transcript to keep a cell\n            min_intensity_ratio: Cells whose mean channel intensity is less than `min_intensity_ratio * quantile_90` will be filtered\n        \"\"\"\n        does_count = (\n            self.table is not None and isinstance(self.table.X, csr_matrix)\n        ) or gene_column is not None\n\n        assert (\n            average_intensities or does_count\n        ), f\"You must choose at least one aggregation: transcripts or fluorescence intensities\"\n\n        if gene_column is not None:\n            if self.table is not None:\n                log.warn(\"sdata.table is already existing. Transcripts are not count again.\")\n            else:\n                self.table = count_transcripts(self.sdata, gene_column, shapes_key=self.shapes_key)\n\n        if does_count and min_transcripts &gt; 0:\n            self.filter_cells(self.table.X.sum(axis=1) &lt; min_transcripts)\n\n        if average_intensities:\n            mean_intensities = average_channels(\n                self.sdata,\n                image_key=self.image_key,\n                shapes_key=self.shapes_key,\n                expand_radius_ratio=expand_radius_ratio,\n            )\n\n            if min_intensity_ratio &gt; 0:\n                means = mean_intensities.mean(axis=1)\n                intensity_threshold = min_intensity_ratio * np.quantile(means, 0.9)\n                where_filter = means &lt; intensity_threshold\n                self.filter_cells(where_filter)\n                mean_intensities = mean_intensities[~where_filter]\n\n            if not does_count:\n                self.table = AnnData(\n                    mean_intensities,\n                    dtype=mean_intensities.dtype,\n                    var=pd.DataFrame(index=self.image.coords[\"c\"].values.astype(str)),\n                    obs=pd.DataFrame(index=self.geo_df.index),\n                )\n            else:\n                self.table.obsm[SopaKeys.INTENSITIES_OBSM] = pd.DataFrame(\n                    mean_intensities,\n                    columns=self.image.coords[\"c\"].values.astype(str),\n                    index=self.table.obs_names,\n                )\n\n        self.table.uns[SopaKeys.UNS_KEY] = {\n            \"version\": sopa.__version__,\n            SopaKeys.UNS_HAS_TRANSCRIPTS: does_count,\n            SopaKeys.UNS_HAS_INTENSITIES: average_intensities,\n        }\n\n        self.standardize_table()\n        self.save_table()\n</code></pre>"},{"location":"api/segmentation/aggregate/#sopa.segmentation.aggregate.Aggregator.__init__","title":"<code>__init__(sdata, overwrite=True, image_key=None, shapes_key=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>overwrite</code> <code>bool</code> <p>If <code>True</code>, will overwrite <code>sdata.table</code> if already existing</p> <code>True</code> <code>image_key</code> <code>str | None</code> <p>Key of <code>sdata</code> with the image to be averaged. If only one image, this does not have to be provided.</p> <code>None</code> <code>shapes_key</code> <code>str | None</code> <p>Key of <code>sdata</code> with the shapes corresponding to the cells boundaries</p> <code>None</code> Source code in <code>sopa/segmentation/aggregate.py</code> <pre><code>def __init__(\n    self,\n    sdata: SpatialData,\n    overwrite: bool = True,\n    image_key: str | None = None,\n    shapes_key: str | None = None,\n):\n    \"\"\"\n    Args:\n        sdata: A `SpatialData` object\n        overwrite: If `True`, will overwrite `sdata.table` if already existing\n        image_key: Key of `sdata` with the image to be averaged. If only one image, this does not have to be provided.\n        shapes_key: Key of `sdata` with the shapes corresponding to the cells boundaries\n    \"\"\"\n    self.sdata = sdata\n    self.overwrite = overwrite\n\n    self.image_key, self.image = get_spatial_image(sdata, image_key, return_key=True)\n\n    if shapes_key is None:\n        self.shapes_key, self.geo_df = get_boundaries(sdata, return_key=True)\n    else:\n        self.shapes_key = shapes_key\n        self.geo_df = self.sdata[shapes_key]\n\n    if sdata.table is not None and len(self.geo_df) != sdata.table.n_obs:\n        log.warn(\n            f\"Table already existing with {sdata.table.n_obs} obs, but aggregating on {len(self.geo_df)} cells. Deleting table.\"\n        )\n        del sdata.table\n\n    self.table = sdata.table\n</code></pre>"},{"location":"api/segmentation/aggregate/#sopa.segmentation.aggregate.Aggregator.update_table","title":"<code>update_table(gene_column=None, average_intensities=True, expand_radius_ratio=0, min_transcripts=0, min_intensity_ratio=0)</code>","text":"<p>Perform aggregation and update the spatialdata table</p> <p>Parameters:</p> Name Type Description Default <code>gene_column</code> <code>str | None</code> <p>Column key of the transcript dataframe containing the gene names</p> <code>None</code> <code>average_intensities</code> <code>bool</code> <p>Whether to average the channels intensities inside cells polygons</p> <code>True</code> <code>expand_radius_ratio</code> <code>float</code> <p>Cells polygons will be expanded by <code>expand_radius_ratio * mean_radius</code> for channels averaging only. This help better aggregate boundary stainings</p> <code>0</code> <code>min_transcripts</code> <code>int</code> <p>Minimum amount of transcript to keep a cell</p> <code>0</code> <code>min_intensity_ratio</code> <code>float</code> <p>Cells whose mean channel intensity is less than <code>min_intensity_ratio * quantile_90</code> will be filtered</p> <code>0</code> Source code in <code>sopa/segmentation/aggregate.py</code> <pre><code>def update_table(\n    self,\n    gene_column: str | None = None,\n    average_intensities: bool = True,\n    expand_radius_ratio: float = 0,\n    min_transcripts: int = 0,\n    min_intensity_ratio: float = 0,\n):\n    \"\"\"Perform aggregation and update the spatialdata table\n\n    Args:\n        gene_column: Column key of the transcript dataframe containing the gene names\n        average_intensities: Whether to average the channels intensities inside cells polygons\n        expand_radius_ratio: Cells polygons will be expanded by `expand_radius_ratio * mean_radius` for channels averaging **only**. This help better aggregate boundary stainings\n        min_transcripts: Minimum amount of transcript to keep a cell\n        min_intensity_ratio: Cells whose mean channel intensity is less than `min_intensity_ratio * quantile_90` will be filtered\n    \"\"\"\n    does_count = (\n        self.table is not None and isinstance(self.table.X, csr_matrix)\n    ) or gene_column is not None\n\n    assert (\n        average_intensities or does_count\n    ), f\"You must choose at least one aggregation: transcripts or fluorescence intensities\"\n\n    if gene_column is not None:\n        if self.table is not None:\n            log.warn(\"sdata.table is already existing. Transcripts are not count again.\")\n        else:\n            self.table = count_transcripts(self.sdata, gene_column, shapes_key=self.shapes_key)\n\n    if does_count and min_transcripts &gt; 0:\n        self.filter_cells(self.table.X.sum(axis=1) &lt; min_transcripts)\n\n    if average_intensities:\n        mean_intensities = average_channels(\n            self.sdata,\n            image_key=self.image_key,\n            shapes_key=self.shapes_key,\n            expand_radius_ratio=expand_radius_ratio,\n        )\n\n        if min_intensity_ratio &gt; 0:\n            means = mean_intensities.mean(axis=1)\n            intensity_threshold = min_intensity_ratio * np.quantile(means, 0.9)\n            where_filter = means &lt; intensity_threshold\n            self.filter_cells(where_filter)\n            mean_intensities = mean_intensities[~where_filter]\n\n        if not does_count:\n            self.table = AnnData(\n                mean_intensities,\n                dtype=mean_intensities.dtype,\n                var=pd.DataFrame(index=self.image.coords[\"c\"].values.astype(str)),\n                obs=pd.DataFrame(index=self.geo_df.index),\n            )\n        else:\n            self.table.obsm[SopaKeys.INTENSITIES_OBSM] = pd.DataFrame(\n                mean_intensities,\n                columns=self.image.coords[\"c\"].values.astype(str),\n                index=self.table.obs_names,\n            )\n\n    self.table.uns[SopaKeys.UNS_KEY] = {\n        \"version\": sopa.__version__,\n        SopaKeys.UNS_HAS_TRANSCRIPTS: does_count,\n        SopaKeys.UNS_HAS_INTENSITIES: average_intensities,\n    }\n\n    self.standardize_table()\n    self.save_table()\n</code></pre>"},{"location":"api/segmentation/baysor/","title":"sopa.segmentation.baysor","text":""},{"location":"api/segmentation/baysor/#sopa.segmentation.baysor.resolve.resolve","title":"<code>sopa.segmentation.baysor.resolve.resolve(sdata, baysor_temp_dir, gene_column, patches_dirs=None, min_area=0)</code>","text":"<p>Concatenate all the per-patch Baysor run and resolve the conflicts. Resulting cells boundaries are saved in the <code>SpatialData</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>baysor_temp_dir</code> <code>str</code> <p>Temporary directory used to store all the baysor subdirectories (one subdirectory for one patch and for one baysor run)</p> required <code>gene_column</code> <code>str</code> <p>Column of the transcript dataframe containing the genes names</p> required <code>patches_dirs</code> <code>list[str] | None</code> <p>Optional list of subdirectories inside <code>baysor_temp_dir</code> to be read. By default, read all.</p> <code>None</code> <code>min_area</code> <code>float</code> <p>Minimum area (in microns^2) for a cell to be kept</p> <code>0</code> Source code in <code>sopa/segmentation/baysor/resolve.py</code> <pre><code>def resolve(\n    sdata: SpatialData,\n    baysor_temp_dir: str,\n    gene_column: str,\n    patches_dirs: list[str] | None = None,\n    min_area: float = 0,\n):\n    \"\"\"Concatenate all the per-patch Baysor run and resolve the conflicts. Resulting cells boundaries are saved in the `SpatialData` object.\n\n    Args:\n        sdata: A `SpatialData` object\n        baysor_temp_dir: Temporary directory used to store all the baysor subdirectories (one subdirectory for one patch and for one baysor run)\n        gene_column: Column of the transcript dataframe containing the genes names\n        patches_dirs: Optional list of subdirectories inside `baysor_temp_dir` to be read. By default, read all.\n        min_area: Minimum area (in microns^2) for a cell to be kept\n    \"\"\"\n    if min_area &gt; 0:\n        log.info(f\"Cells whose area is less than {min_area} microns^2 will be removed\")\n\n    patches_cells, adatas = read_all_baysor_patches(baysor_temp_dir, min_area, patches_dirs)\n    geo_df, cells_indices, new_ids = resolve_patches(patches_cells, adatas)\n\n    image_key = get_key(sdata, \"images\")\n    points = get_element(sdata, \"points\")\n    transformations = get_transformation(points, get_all=True)\n\n    geo_df = ShapesModel.parse(geo_df, transformations=transformations)\n\n    table_conflicts = []\n    if len(new_ids):\n        new_cells = geo_df.geometry[cells_indices == -1]\n        geo_df_new = gpd.GeoDataFrame({\"geometry\": new_cells})\n        geo_df_new = ShapesModel.parse(geo_df_new, transformations=transformations)\n\n        log.info(\"Aggregating transcripts on merged cells\")\n        table_conflicts = aggregate.count_transcripts(sdata, gene_column, geo_df=geo_df_new)\n        table_conflicts.obs_names = new_ids\n        table_conflicts = [table_conflicts]\n\n    valid_ids = set(list(geo_df.index))\n    table = anndata.concat(\n        [adata[list(valid_ids &amp; set(list(adata.obs_names)))] for adata in adatas] + table_conflicts,\n        join=\"outer\",\n    )\n    table.obs.dropna(axis=\"columns\", inplace=True)\n\n    geo_df = geo_df.loc[table.obs_names]\n\n    table.obsm[\"spatial\"] = np.array([[centroid.x, centroid.y] for centroid in geo_df.centroid])\n    table.obs[SopaKeys.REGION_KEY] = pd.Series(\n        SopaKeys.BAYSOR_BOUNDARIES, index=table.obs_names, dtype=\"category\"\n    )\n    table.obs[SopaKeys.SLIDE_KEY] = pd.Series(image_key, index=table.obs_names, dtype=\"category\")\n    table.obs[SopaKeys.INSTANCE_KEY] = geo_df.index\n\n    table = TableModel.parse(\n        table,\n        region_key=SopaKeys.REGION_KEY,\n        region=SopaKeys.BAYSOR_BOUNDARIES,\n        instance_key=SopaKeys.INSTANCE_KEY,\n    )\n\n    sdata.add_shapes(SopaKeys.BAYSOR_BOUNDARIES, geo_df, overwrite=True)\n\n    if sdata.table is not None:\n        del sdata.table\n\n    sdata.table = table\n\n    log.info(\n        f\"Added sdata.table, and {len(geo_df)} cell boundaries to sdata['{SopaKeys.BAYSOR_BOUNDARIES}']\"\n    )\n</code></pre>"},{"location":"api/segmentation/methods/","title":"sopa.segmentation.methods","text":""},{"location":"api/segmentation/methods/#sopa.segmentation.methods.cellpose_patch","title":"<code>sopa.segmentation.methods.cellpose_patch(diameter, channels, model_type='cyto2', **cellpose_kwargs)</code>","text":"<p>Creation of a callable that runs Cellpose segmentation on a patch</p> <p>Parameters:</p> Name Type Description Default <code>diameter</code> <code>float</code> <p>Cellpose diameter parameter</p> required <code>channels</code> <code>list[str]</code> <p>List of channel names</p> required <code>model_type</code> <code>str</code> <p>Cellpose model type</p> <code>'cyto2'</code> <code>**cellpose_kwargs</code> <code>int</code> <p>Kwargs to be provided to <code>model.eval</code> (where <code>model</code> is a <code>cellpose.models.Cellpose</code> object)</p> <code>{}</code> <p>Returns:</p> Type Description <code>Callable</code> <p>A <code>callable</code> whose input is an image of shape <code>(C, Y, X)</code> and output is a cell mask of shape <code>(Y, X)</code>. Each mask value <code>&gt;0</code> represent a unique cell ID</p> Source code in <code>sopa/segmentation/methods.py</code> <pre><code>def cellpose_patch(\n    diameter: float, channels: list[str], model_type: str = \"cyto2\", **cellpose_kwargs: int\n) -&gt; Callable:\n    \"\"\"Creation of a callable that runs Cellpose segmentation on a patch\n\n    Args:\n        diameter: Cellpose diameter parameter\n        channels: List of channel names\n        model_type: Cellpose model type\n        **cellpose_kwargs: Kwargs to be provided to `model.eval` (where `model` is a `cellpose.models.Cellpose` object)\n\n    Returns:\n        A `callable` whose input is an image of shape `(C, Y, X)` and output is a cell mask of shape `(Y, X)`. Each mask value `&gt;0` represent a unique cell ID\n    \"\"\"\n    try:\n        from cellpose import models\n    except ImportError:\n        raise ImportError(\n            \"To use cellpose, you need its corresponding sopa extra: `pip install 'sopa[cellpose]'`\"\n        )\n\n    model = models.Cellpose(model_type=model_type)\n\n    if isinstance(channels, str) or len(channels) == 1:\n        channels = [0, 0]  # gray scale\n    elif len(channels) == 2:\n        channels = [1, 2]\n    else:\n        raise ValueError(f\"Provide 1 or 2 channels. Found {len(channels)}\")\n\n    def _(patch: np.ndarray):\n        mask, *_ = model.eval(patch, diameter=diameter, channels=channels, **cellpose_kwargs)\n        return mask\n\n    return _\n</code></pre>"},{"location":"api/segmentation/patching/","title":"sopa.segmentation.patching","text":""},{"location":"api/segmentation/patching/#sopa.segmentation.patching.Patches2D","title":"<code>sopa.segmentation.patching.Patches2D</code>","text":"<p>Perform patching with overlap</p> Source code in <code>sopa/segmentation/patching.py</code> <pre><code>class Patches2D:\n    \"\"\"Perform patching with overlap\"\"\"\n\n    def __init__(\n        self,\n        sdata: SpatialData,\n        element_name: str,\n        patch_width: float | int,\n        patch_overlap: float | int = 50,\n    ):\n        \"\"\"\n        Args:\n            sdata: A `SpatialData` object\n            element_name: Name of the element on with patches will be made\n            patch_width: Width of the patches (in the unit of the coordinate system of the element)\n            patch_overlap: Overlap width between the patches\n        \"\"\"\n        self.sdata = sdata\n        self.element_name = element_name\n        self.element = sdata[element_name]\n\n        if isinstance(self.element, MultiscaleSpatialImage):\n            self.element = get_spatial_image(sdata, element_name)\n\n        if isinstance(self.element, SpatialImage):\n            xmin, ymin = 0, 0\n            xmax, ymax = len(self.element.coords[\"x\"]), len(self.element.coords[\"y\"])\n            tight, int_coords = False, True\n        elif isinstance(self.element, dd.DataFrame):\n            xmin, ymin = self.element.x.min().compute(), self.element.y.min().compute()\n            xmax, ymax = self.element.x.max().compute(), self.element.y.max().compute()\n            tight, int_coords = True, False\n        else:\n            raise ValueError(f\"Invalid element type: {type(self.element)}\")\n\n        self.patch_x = Patches1D(xmin, xmax, patch_width, patch_overlap, tight, int_coords)\n        self.patch_y = Patches1D(ymin, ymax, patch_width, patch_overlap, tight, int_coords)\n\n        self.roi = sdata.shapes[ROI.KEY] if ROI.KEY in sdata.shapes else None\n        if self.roi is not None:\n            self.roi = to_intrinsic(sdata, self.roi, element_name).geometry[0]\n\n        self._ilocs = []\n\n        for i in range(self.patch_x._count * self.patch_y._count):\n            ix, iy = self.pair_indices(i)\n            bounds = self.iloc(ix, iy)\n            patch = box(*bounds)\n            if self.roi is None or self.roi.intersects(patch):\n                self._ilocs.append((ix, iy))\n\n    def pair_indices(self, i: int) -&gt; tuple[int, int]:\n        \"\"\"Index localization of one patch\n\n        Args:\n            i: The patch index\n\n        Returns:\n            A tuple `(index_x, index_y)` representing the 2D localization of the patch\n        \"\"\"\n        iy, ix = divmod(i, self.patch_x._count)\n        return ix, iy\n\n    def iloc(self, ix: int, iy: int) -&gt; list[int]:\n        \"\"\"Coordinates of the rectangle bounding box of the patch at the given indices\n\n        Args:\n            ix: Patch index in the x-axis\n            iy: Patch indes in the y-axis\n\n        Returns:\n            A list `[xmin, ymin, xmax, ymax]` representing the bounding box of the patch\n        \"\"\"\n        xmin, xmax = self.patch_x[ix]\n        ymin, ymax = self.patch_y[iy]\n        return [xmin, ymin, xmax, ymax]\n\n    def __getitem__(self, i) -&gt; tuple[int, int, int, int]:\n        \"\"\"One patche bounding box: (xmin, ymin, xmax, ymax)\"\"\"\n        if isinstance(i, slice):\n            start, stop, step = i.indices(len(self))\n            return [self[i] for i in range(start, stop, step)]\n\n        return self.iloc(*self._ilocs[i])\n\n    def __len__(self):\n        \"\"\"Number of patches\"\"\"\n        return len(self._ilocs)\n\n    def __iter__(self):\n        \"\"\"Iterate over all patches (see `__getitem__`)\"\"\"\n        for i in range(len(self)):\n            yield self[i]\n\n    def polygon(self, i: int) -&gt; Polygon:\n        \"\"\"One patch as a shapely polygon. The polygon may not be just a square, if a ROI has been previously selected.\n\n        Args:\n            i: Patch index\n\n        Returns:\n            Polygon representing the patch\n        \"\"\"\n        rectangle = box(*self[i])\n        return rectangle if self.roi is None else rectangle.intersection(self.roi)\n\n    @property\n    def polygons(self) -&gt; list[Polygon]:\n        \"\"\"All the patches as polygons\n\n        Returns:\n            List of `shapely` polygons\n        \"\"\"\n        return [self.polygon(i) for i in range(len(self))]\n\n    def write(self, overwrite: bool = True):\n        \"\"\"Save patches in `sdata.shapes[\"sopa_patches\"]`\n\n        Args:\n            overwrite: Whether to overwrite patches if existing\n        \"\"\"\n        geo_df = gpd.GeoDataFrame(\n            {\"geometry\": self.polygons, SopaKeys.BOUNDS: [self[i] for i in range(len(self))]}\n        )\n        geo_df = ShapesModel.parse(\n            geo_df, transformations=get_transformation(self.element, get_all=True)\n        )\n        self.sdata.add_shapes(SopaKeys.PATCHES, geo_df, overwrite=overwrite)\n\n        log.info(f\"{len(geo_df)} patches were saved in sdata['{SopaKeys.PATCHES}']\")\n\n    def patchify_transcripts(\n        self,\n        baysor_temp_dir: str,\n        cell_key: str = None,\n        unassigned_value: int | str = None,\n        use_prior: bool = False,\n        config: dict = {},\n        config_path: str | None = None,\n    ) -&gt; list[int]:\n        \"\"\"Patchification of the transcripts\n\n        Args:\n            baysor_temp_dir: Temporary directory where each patch will be stored. Note that each patch will have its own subdirectory.\n            cell_key: Optional key of the transcript dataframe containing the cell IDs. This is useful if a prior segmentation has been run, assigning each transcript to a cell.\n            unassigned_value: If `cell_key` has been provided, this corresponds to the value given in the 'cell ID' column for transcript that are not inside any cell.\n            use_prior: Whether to use Cellpose as a prior segmentation for Baysor. If `True`, make sure you have already run Cellpose with Sopa, and no need to provide `cell_key` and `unassigned_value`. Note that, if you have MERFISH data, the prior has already been run, so just use `cell_key` and `unassigned_value`.\n            config: Dictionnary of baysor parameters\n            config_path: Path to the baysor config (you can also directly provide the argument via the `config` option)\n\n        Returns:\n            A list of patches indices. Each index correspond to the name of a subdirectory inside `baysor_temp_dir`\n        \"\"\"\n        return BaysorPatches(self, self.element).write(\n            baysor_temp_dir, cell_key, unassigned_value, use_prior, config, config_path\n        )\n</code></pre>"},{"location":"api/segmentation/patching/#sopa.segmentation.patching.Patches2D.polygons","title":"<code>polygons: list[Polygon]</code>  <code>property</code>","text":"<p>All the patches as polygons</p> <p>Returns:</p> Type Description <code>list[Polygon]</code> <p>List of <code>shapely</code> polygons</p>"},{"location":"api/segmentation/patching/#sopa.segmentation.patching.Patches2D.__getitem__","title":"<code>__getitem__(i)</code>","text":"<p>One patche bounding box: (xmin, ymin, xmax, ymax)</p> Source code in <code>sopa/segmentation/patching.py</code> <pre><code>def __getitem__(self, i) -&gt; tuple[int, int, int, int]:\n    \"\"\"One patche bounding box: (xmin, ymin, xmax, ymax)\"\"\"\n    if isinstance(i, slice):\n        start, stop, step = i.indices(len(self))\n        return [self[i] for i in range(start, stop, step)]\n\n    return self.iloc(*self._ilocs[i])\n</code></pre>"},{"location":"api/segmentation/patching/#sopa.segmentation.patching.Patches2D.__init__","title":"<code>__init__(sdata, element_name, patch_width, patch_overlap=50)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>element_name</code> <code>str</code> <p>Name of the element on with patches will be made</p> required <code>patch_width</code> <code>float | int</code> <p>Width of the patches (in the unit of the coordinate system of the element)</p> required <code>patch_overlap</code> <code>float | int</code> <p>Overlap width between the patches</p> <code>50</code> Source code in <code>sopa/segmentation/patching.py</code> <pre><code>def __init__(\n    self,\n    sdata: SpatialData,\n    element_name: str,\n    patch_width: float | int,\n    patch_overlap: float | int = 50,\n):\n    \"\"\"\n    Args:\n        sdata: A `SpatialData` object\n        element_name: Name of the element on with patches will be made\n        patch_width: Width of the patches (in the unit of the coordinate system of the element)\n        patch_overlap: Overlap width between the patches\n    \"\"\"\n    self.sdata = sdata\n    self.element_name = element_name\n    self.element = sdata[element_name]\n\n    if isinstance(self.element, MultiscaleSpatialImage):\n        self.element = get_spatial_image(sdata, element_name)\n\n    if isinstance(self.element, SpatialImage):\n        xmin, ymin = 0, 0\n        xmax, ymax = len(self.element.coords[\"x\"]), len(self.element.coords[\"y\"])\n        tight, int_coords = False, True\n    elif isinstance(self.element, dd.DataFrame):\n        xmin, ymin = self.element.x.min().compute(), self.element.y.min().compute()\n        xmax, ymax = self.element.x.max().compute(), self.element.y.max().compute()\n        tight, int_coords = True, False\n    else:\n        raise ValueError(f\"Invalid element type: {type(self.element)}\")\n\n    self.patch_x = Patches1D(xmin, xmax, patch_width, patch_overlap, tight, int_coords)\n    self.patch_y = Patches1D(ymin, ymax, patch_width, patch_overlap, tight, int_coords)\n\n    self.roi = sdata.shapes[ROI.KEY] if ROI.KEY in sdata.shapes else None\n    if self.roi is not None:\n        self.roi = to_intrinsic(sdata, self.roi, element_name).geometry[0]\n\n    self._ilocs = []\n\n    for i in range(self.patch_x._count * self.patch_y._count):\n        ix, iy = self.pair_indices(i)\n        bounds = self.iloc(ix, iy)\n        patch = box(*bounds)\n        if self.roi is None or self.roi.intersects(patch):\n            self._ilocs.append((ix, iy))\n</code></pre>"},{"location":"api/segmentation/patching/#sopa.segmentation.patching.Patches2D.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over all patches (see <code>__getitem__</code>)</p> Source code in <code>sopa/segmentation/patching.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate over all patches (see `__getitem__`)\"\"\"\n    for i in range(len(self)):\n        yield self[i]\n</code></pre>"},{"location":"api/segmentation/patching/#sopa.segmentation.patching.Patches2D.__len__","title":"<code>__len__()</code>","text":"<p>Number of patches</p> Source code in <code>sopa/segmentation/patching.py</code> <pre><code>def __len__(self):\n    \"\"\"Number of patches\"\"\"\n    return len(self._ilocs)\n</code></pre>"},{"location":"api/segmentation/patching/#sopa.segmentation.patching.Patches2D.iloc","title":"<code>iloc(ix, iy)</code>","text":"<p>Coordinates of the rectangle bounding box of the patch at the given indices</p> <p>Parameters:</p> Name Type Description Default <code>ix</code> <code>int</code> <p>Patch index in the x-axis</p> required <code>iy</code> <code>int</code> <p>Patch indes in the y-axis</p> required <p>Returns:</p> Type Description <code>list[int]</code> <p>A list <code>[xmin, ymin, xmax, ymax]</code> representing the bounding box of the patch</p> Source code in <code>sopa/segmentation/patching.py</code> <pre><code>def iloc(self, ix: int, iy: int) -&gt; list[int]:\n    \"\"\"Coordinates of the rectangle bounding box of the patch at the given indices\n\n    Args:\n        ix: Patch index in the x-axis\n        iy: Patch indes in the y-axis\n\n    Returns:\n        A list `[xmin, ymin, xmax, ymax]` representing the bounding box of the patch\n    \"\"\"\n    xmin, xmax = self.patch_x[ix]\n    ymin, ymax = self.patch_y[iy]\n    return [xmin, ymin, xmax, ymax]\n</code></pre>"},{"location":"api/segmentation/patching/#sopa.segmentation.patching.Patches2D.pair_indices","title":"<code>pair_indices(i)</code>","text":"<p>Index localization of one patch</p> <p>Parameters:</p> Name Type Description Default <code>i</code> <code>int</code> <p>The patch index</p> required <p>Returns:</p> Type Description <code>tuple[int, int]</code> <p>A tuple <code>(index_x, index_y)</code> representing the 2D localization of the patch</p> Source code in <code>sopa/segmentation/patching.py</code> <pre><code>def pair_indices(self, i: int) -&gt; tuple[int, int]:\n    \"\"\"Index localization of one patch\n\n    Args:\n        i: The patch index\n\n    Returns:\n        A tuple `(index_x, index_y)` representing the 2D localization of the patch\n    \"\"\"\n    iy, ix = divmod(i, self.patch_x._count)\n    return ix, iy\n</code></pre>"},{"location":"api/segmentation/patching/#sopa.segmentation.patching.Patches2D.patchify_transcripts","title":"<code>patchify_transcripts(baysor_temp_dir, cell_key=None, unassigned_value=None, use_prior=False, config={}, config_path=None)</code>","text":"<p>Patchification of the transcripts</p> <p>Parameters:</p> Name Type Description Default <code>baysor_temp_dir</code> <code>str</code> <p>Temporary directory where each patch will be stored. Note that each patch will have its own subdirectory.</p> required <code>cell_key</code> <code>str</code> <p>Optional key of the transcript dataframe containing the cell IDs. This is useful if a prior segmentation has been run, assigning each transcript to a cell.</p> <code>None</code> <code>unassigned_value</code> <code>int | str</code> <p>If <code>cell_key</code> has been provided, this corresponds to the value given in the 'cell ID' column for transcript that are not inside any cell.</p> <code>None</code> <code>use_prior</code> <code>bool</code> <p>Whether to use Cellpose as a prior segmentation for Baysor. If <code>True</code>, make sure you have already run Cellpose with Sopa, and no need to provide <code>cell_key</code> and <code>unassigned_value</code>. Note that, if you have MERFISH data, the prior has already been run, so just use <code>cell_key</code> and <code>unassigned_value</code>.</p> <code>False</code> <code>config</code> <code>dict</code> <p>Dictionnary of baysor parameters</p> <code>{}</code> <code>config_path</code> <code>str | None</code> <p>Path to the baysor config (you can also directly provide the argument via the <code>config</code> option)</p> <code>None</code> <p>Returns:</p> Type Description <code>list[int]</code> <p>A list of patches indices. Each index correspond to the name of a subdirectory inside <code>baysor_temp_dir</code></p> Source code in <code>sopa/segmentation/patching.py</code> <pre><code>def patchify_transcripts(\n    self,\n    baysor_temp_dir: str,\n    cell_key: str = None,\n    unassigned_value: int | str = None,\n    use_prior: bool = False,\n    config: dict = {},\n    config_path: str | None = None,\n) -&gt; list[int]:\n    \"\"\"Patchification of the transcripts\n\n    Args:\n        baysor_temp_dir: Temporary directory where each patch will be stored. Note that each patch will have its own subdirectory.\n        cell_key: Optional key of the transcript dataframe containing the cell IDs. This is useful if a prior segmentation has been run, assigning each transcript to a cell.\n        unassigned_value: If `cell_key` has been provided, this corresponds to the value given in the 'cell ID' column for transcript that are not inside any cell.\n        use_prior: Whether to use Cellpose as a prior segmentation for Baysor. If `True`, make sure you have already run Cellpose with Sopa, and no need to provide `cell_key` and `unassigned_value`. Note that, if you have MERFISH data, the prior has already been run, so just use `cell_key` and `unassigned_value`.\n        config: Dictionnary of baysor parameters\n        config_path: Path to the baysor config (you can also directly provide the argument via the `config` option)\n\n    Returns:\n        A list of patches indices. Each index correspond to the name of a subdirectory inside `baysor_temp_dir`\n    \"\"\"\n    return BaysorPatches(self, self.element).write(\n        baysor_temp_dir, cell_key, unassigned_value, use_prior, config, config_path\n    )\n</code></pre>"},{"location":"api/segmentation/patching/#sopa.segmentation.patching.Patches2D.polygon","title":"<code>polygon(i)</code>","text":"<p>One patch as a shapely polygon. The polygon may not be just a square, if a ROI has been previously selected.</p> <p>Parameters:</p> Name Type Description Default <code>i</code> <code>int</code> <p>Patch index</p> required <p>Returns:</p> Type Description <code>Polygon</code> <p>Polygon representing the patch</p> Source code in <code>sopa/segmentation/patching.py</code> <pre><code>def polygon(self, i: int) -&gt; Polygon:\n    \"\"\"One patch as a shapely polygon. The polygon may not be just a square, if a ROI has been previously selected.\n\n    Args:\n        i: Patch index\n\n    Returns:\n        Polygon representing the patch\n    \"\"\"\n    rectangle = box(*self[i])\n    return rectangle if self.roi is None else rectangle.intersection(self.roi)\n</code></pre>"},{"location":"api/segmentation/patching/#sopa.segmentation.patching.Patches2D.write","title":"<code>write(overwrite=True)</code>","text":"<p>Save patches in <code>sdata.shapes[\"sopa_patches\"]</code></p> <p>Parameters:</p> Name Type Description Default <code>overwrite</code> <code>bool</code> <p>Whether to overwrite patches if existing</p> <code>True</code> Source code in <code>sopa/segmentation/patching.py</code> <pre><code>def write(self, overwrite: bool = True):\n    \"\"\"Save patches in `sdata.shapes[\"sopa_patches\"]`\n\n    Args:\n        overwrite: Whether to overwrite patches if existing\n    \"\"\"\n    geo_df = gpd.GeoDataFrame(\n        {\"geometry\": self.polygons, SopaKeys.BOUNDS: [self[i] for i in range(len(self))]}\n    )\n    geo_df = ShapesModel.parse(\n        geo_df, transformations=get_transformation(self.element, get_all=True)\n    )\n    self.sdata.add_shapes(SopaKeys.PATCHES, geo_df, overwrite=overwrite)\n\n    log.info(f\"{len(geo_df)} patches were saved in sdata['{SopaKeys.PATCHES}']\")\n</code></pre>"},{"location":"api/segmentation/shapes/","title":"sopa.segmentation.shapes","text":""},{"location":"api/segmentation/shapes/#sopa.segmentation.shapes.solve_conflicts","title":"<code>sopa.segmentation.shapes.solve_conflicts(cells, threshold=0.5, patch_indices=None, return_indices=False)</code>","text":"<p>Resolve segmentation conflicts (i.e. overlap) after running segmentation on patches</p> <p>Parameters:</p> Name Type Description Default <code>cells</code> <code>list[Polygon]</code> <p>List of cell polygons</p> required <code>threshold</code> <code>float</code> <p>When two cells are overlapping, we look at the area of intersection over the area of the smallest cell. If this value is higher than the <code>threshold</code>, the cells are merged</p> <code>0.5</code> <code>patch_indices</code> <code>ndarray | None</code> <p>Patch from which each cell belongs.</p> <code>None</code> <code>return_indices</code> <code>bool</code> <p>If <code>True</code>, returns also the cells indices.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray[Polygon]</code> <p>Array of resolved cells polygons</p> Source code in <code>sopa/segmentation/shapes.py</code> <pre><code>def solve_conflicts(\n    cells: list[Polygon],\n    threshold: float = 0.5,\n    patch_indices: np.ndarray | None = None,\n    return_indices: bool = False,\n) -&gt; np.ndarray[Polygon]:\n    \"\"\"Resolve segmentation conflicts (i.e. overlap) after running segmentation on patches\n\n    Args:\n        cells: List of cell polygons\n        threshold: When two cells are overlapping, we look at the area of intersection over the area of the smallest cell. If this value is higher than the `threshold`, the cells are merged\n        patch_indices: Patch from which each cell belongs.\n        return_indices: If `True`, returns also the cells indices.\n\n    Returns:\n        Array of resolved cells polygons\n    \"\"\"\n    cells = list(cells)\n    n_cells = len(cells)\n    resolved_indices = np.arange(n_cells)\n\n    assert n_cells &gt; 0, f\"No cells was segmented, cannot continue\"\n\n    tree = shapely.STRtree(cells)\n    conflicts = tree.query(cells, predicate=\"intersects\")\n\n    if patch_indices is not None:\n        conflicts = conflicts[:, patch_indices[conflicts[0]] != patch_indices[conflicts[1]]].T\n    else:\n        conflicts = conflicts[:, conflicts[0] != conflicts[1]].T\n\n    for i1, i2 in tqdm(conflicts, desc=\"Resolving conflicts\"):\n        resolved_i1: int = resolved_indices[i1]\n        resolved_i2: int = resolved_indices[i2]\n        cell1, cell2 = cells[resolved_i1], cells[resolved_i2]\n\n        intersection = cell1.intersection(cell2).area\n        if intersection &gt;= threshold * min(cell1.area, cell2.area):\n            cell = _ensure_polygon(cell1.union(cell2))\n\n            resolved_indices[np.isin(resolved_indices, [resolved_i1, resolved_i2])] = len(cells)\n            cells.append(cell)\n\n    unique_indices = np.unique(resolved_indices)\n    unique_cells = np.array(cells)[unique_indices]\n\n    if return_indices:\n        return unique_cells, np.where(unique_indices &lt; n_cells, unique_indices, -1)\n\n    return unique_cells\n</code></pre>"},{"location":"api/segmentation/shapes/#sopa.segmentation.shapes.geometrize","title":"<code>sopa.segmentation.shapes.geometrize(mask, tolerance=None, smooth_radius_ratio=0.1)</code>","text":"<p>Convert a cells mask to multiple <code>shapely</code> geometries. Inspired from https://github.com/Vizgen/vizgen-postprocessing</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>ndarray</code> <p>A cell mask. Non-null values correspond to cell ids</p> required <code>tolerance</code> <code>float | None</code> <p>Tolerance parameter used by <code>shapely</code> during simplification. By default, define the tolerance automatically.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Polygon]</code> <p>List of <code>shapely</code> polygons representing each cell ID of the mask</p> Source code in <code>sopa/segmentation/shapes.py</code> <pre><code>def geometrize(\n    mask: np.ndarray, tolerance: float | None = None, smooth_radius_ratio: float = 0.1\n) -&gt; list[Polygon]:\n    \"\"\"Convert a cells mask to multiple `shapely` geometries. Inspired from https://github.com/Vizgen/vizgen-postprocessing\n\n    Args:\n        mask: A cell mask. Non-null values correspond to cell ids\n        tolerance: Tolerance parameter used by `shapely` during simplification. By default, define the tolerance automatically.\n\n    Returns:\n        List of `shapely` polygons representing each cell ID of the mask\n    \"\"\"\n    max_cells = mask.max()\n\n    if max_cells == 0:\n        log.warn(\"No cell was returned by the segmentation\")\n        return []\n\n    cells = [_contours((mask == cell_id).astype(\"uint8\")) for cell_id in range(1, max_cells + 1)]\n\n    mean_radius = np.sqrt(np.array([cell.area for cell in cells]) / np.pi).mean()\n    smooth_radius = mean_radius * smooth_radius_ratio\n\n    if tolerance is None:\n        tolerance = _default_tolerance(mean_radius)\n\n    cells = [_smoothen_cell(cell, smooth_radius, tolerance) for cell in cells]\n    cells = [cell for cell in cells if cell is not None]\n\n    log.info(\n        f\"Percentage of non-geometrized cells: {(max_cells - len(cells)) / max_cells:.2%} (usually due to segmentation artefacts)\"\n    )\n\n    return cells\n</code></pre>"},{"location":"api/segmentation/shapes/#sopa.segmentation.shapes.rasterize","title":"<code>sopa.segmentation.shapes.rasterize(cell, shape, xy_min=[0, 0])</code>","text":"<p>Transform a cell polygon into a numpy array with value 1 where the polygon touches a pixel, else 0.</p> <p>Parameters:</p> Name Type Description Default <code>cell</code> <code>Polygon</code> <p>Cell polygon to rasterize.</p> required <code>shape</code> <code>tuple[int, int]</code> <p>Image shape as a tuple (y, x).</p> required <code>xy_min</code> <code>tuple[int, int]</code> <p>Tuple containing the origin of the image [x0, y0].</p> <code>[0, 0]</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The mask array.</p> Source code in <code>sopa/segmentation/shapes.py</code> <pre><code>def rasterize(\n    cell: Polygon, shape: tuple[int, int], xy_min: tuple[int, int] = [0, 0]\n) -&gt; np.ndarray:\n    \"\"\"Transform a cell polygon into a numpy array with value 1 where the polygon touches a pixel, else 0.\n\n    Args:\n        cell: Cell polygon to rasterize.\n        shape: Image shape as a tuple (y, x).\n        xy_min: Tuple containing the origin of the image [x0, y0].\n\n    Returns:\n        The mask array.\n    \"\"\"\n    import cv2\n\n    xmin, ymin, xmax, ymax = [xy_min[0], xy_min[1], xy_min[0] + shape[1], xy_min[1] + shape[0]]\n\n    cell_translated = shapely.affinity.translate(cell, -xmin, -ymin)\n\n    coords = np.array(cell_translated.exterior.coords)[None, :].astype(np.int32)\n    return cv2.fillPoly(np.zeros((ymax - ymin, xmax - xmin), dtype=np.int8), coords, color=1)\n</code></pre>"},{"location":"api/segmentation/stainings/","title":"sopa.segmentation.stainings","text":""},{"location":"api/segmentation/stainings/#sopa.segmentation.stainings.StainingSegmentation","title":"<code>sopa.segmentation.stainings.StainingSegmentation</code>","text":"Source code in <code>sopa/segmentation/stainings.py</code> <pre><code>class StainingSegmentation:\n    def __init__(\n        self,\n        sdata: SpatialData,\n        method: Callable,\n        channels: list[str] | str,\n        min_area: float = 0,\n        clip_limit: float = 0.2,\n        gaussian_sigma: float = 1,\n    ):\n        \"\"\"Generalized staining-based segmentation\n\n        !!! note \"Sequential segmentation (slower)\"\n            ```python\n            from sopa.segmentation.stainings import StainingSegmentation\n\n            method = ... # custom callable that runs segmentation on each patch\n\n            segmentation = StainingSegmentation(sdata, method, \"DAPI\")\n            cells = segmentation.run_patches(2000, 100)\n            StainingSegmentation.add_shapes(sdata, cells, image_key, \"method_name\")\n            ```\n\n        !!! note \"Parallel segmentation (faster)\"\n            ```python\n            from sopa.segmentation.stainings import StainingSegmentation\n\n            method = ... # custom callable that runs segmentation on each patch\n\n            segmentation = StainingSegmentation(sdata, method, \"DAPI\")\n\n            # Run all this in a parallel manner, e.g. on different jobs\n            for i in range(len(sdata['sopa_patches'])):\n                segmentation.write_patch_cells(\"./temp_dir\", i)\n\n            cells = StainingSegmentation.read_patches_cells(\"./temp_dir\")\n            StainingSegmentation.add_shapes(sdata, cells, image_key, \"method_name\")\n            ```\n\n        Args:\n            sdata: A `SpatialData` object\n            method: A segmentation `callable` whose input is an image of shape `(C, Y, X)` and output is a cell mask of shape `(Y, X)`. Each mask value `&gt;0` represent a unique cell ID. Such callables can be found in `sopa.segmentation.methods`.\n            channels: One or a list of channel names used for segmentation. If only one channel is provided, the image given to the `method` will be of shape `(1, Y, X)`.\n            min_area: Minimum area (in pixels^2) for a cell to be kept\n            clip_limit: Parameter for skimage.exposure.equalize_adapthist (applied before running cellpose)\n            gaussian_sigma: Parameter for scipy gaussian_filter (applied before running cellpose)\n        \"\"\"\n        self.sdata = sdata\n        self.method = method\n        self.channels = [channels] if isinstance(channels, str) else channels\n\n        self.min_area = min_area\n        self.clip_limit = clip_limit\n        self.gaussian_sigma = gaussian_sigma\n\n        self.image_key, self.image = get_spatial_image(sdata, return_key=True)\n\n        image_channels = self.image.coords[\"c\"].values\n        assert np.isin(\n            channels, image_channels\n        ).all(), f\"Channel names must be a subset of: {', '.join(image_channels)}\"\n\n    def _run_patch(self, patch: Polygon) -&gt; list[Polygon]:\n        \"\"\"Run segmentation on one patch\n\n        Args:\n            patch: Patch, represented as a `shapely` polygon\n\n        Returns:\n            A list of cells, represented as polygons\n        \"\"\"\n        bounds = [int(x) for x in patch.bounds]\n\n        image = self.image.sel(\n            c=self.channels,\n            x=slice(bounds[0], bounds[2]),\n            y=slice(bounds[1], bounds[3]),\n        ).values\n\n        image = gaussian_filter(image, sigma=self.gaussian_sigma)\n        image = exposure.equalize_adapthist(image, clip_limit=self.clip_limit)\n\n        if patch.area &lt; box(*bounds).area:\n            image = image * shapes.rasterize(patch, image.shape[1:], bounds)\n\n        cells = shapes.geometrize(self.method(image))\n\n        if self.min_area &gt; 0:\n            cells = [cell for cell in cells if cell.area &gt;= self.min_area]\n\n        return [affinity.translate(cell, *bounds[:2]) for cell in cells]\n\n    def write_patch_cells(self, patch_dir: str, patch_index: int):\n        \"\"\"Run segmentation on one patch, and save the result in a dedicated directory\n\n        Args:\n            patch_dir: Directory inside which segmentation results will be saved\n            patch_index: Index of the patch on which to run segmentation. NB: the number of patches is `len(sdata['sopa_patches'])`\n        \"\"\"\n        patch = self.sdata[SopaKeys.PATCHES].geometry[patch_index]\n\n        cells = self._run_patch(patch)\n        gdf = gpd.GeoDataFrame(geometry=cells)\n\n        patch_dir: Path = Path(patch_dir)\n        patch_dir.mkdir(parents=True, exist_ok=True)\n        patch_file = patch_dir / f\"{patch_index}.parquet\"\n\n        gdf.to_parquet(patch_file)\n\n    def run_patches(\n        self,\n        patch_width: int,\n        patch_overlap: int,\n    ) -&gt; list[Polygon]:\n        \"\"\"Run segmentation over all patches, in a sequential manner (this is slower than running all patches in parallel)\n\n        Args:\n            patch_width: Width of the patches\n            patch_overlap: Number of pixels of overlap between patches\n\n        Returns:\n            A list of cells represented as `shapely` polygons\n        \"\"\"\n        self.patches = Patches2D(self.sdata, self.image_key, patch_width, patch_overlap)\n\n        cells = [\n            cell\n            for patch in tqdm(self.patches.polygons, desc=\"Run on patches\")\n            for cell in self._run_patch(patch)\n        ]\n        cells = shapes.solve_conflicts(cells)\n        return cells\n\n    @classmethod\n    def read_patches_cells(cls, patch_dir: str | list[str]) -&gt; list[Polygon]:\n        \"\"\"Read all patch segmentation results after running `write_patch_cells` on all patches\n\n        Args:\n            patch_dir: Directory provided when running `write_patch_cells` containing the `.parquet` files. For multi-step segmentation, provide a list of directories (one per step).\n\n        Returns:\n            A list of cells represented as `shapely` polygons\n        \"\"\"\n        cells = []\n\n        files = [f for f in Path(patch_dir).iterdir() if f.suffix == \".parquet\"]\n        for file in tqdm(files, desc=\"Reading patches\"):\n            cells += list(gpd.read_parquet(file).geometry)\n\n        log.info(f\"Found {len(cells)} total cells\")\n        return cells\n\n    @classmethod\n    def add_shapes(cls, sdata: SpatialData, cells: list[Polygon], image_key: str, shapes_key: str):\n        \"\"\"Adding `shapely` polygon to the `SpatialData` object\n\n        Args:\n            sdata: A `SpatialData` object\n            cells: List of polygons after segmentation\n            image_key: Key of the image on which segmentation has been run\n            shapes_key: Name to provide to the geodataframe to be created\n        \"\"\"\n        image = get_spatial_image(sdata, image_key)\n\n        geo_df = gpd.GeoDataFrame({\"geometry\": cells})\n        geo_df.index = image_key + geo_df.index.astype(str)\n\n        geo_df = ShapesModel.parse(geo_df, transformations=get_transformation(image, get_all=True))\n        sdata.add_shapes(shapes_key, geo_df, overwrite=True)\n\n        log.info(f\"Added {len(geo_df)} cell boundaries in sdata['{shapes_key}']\")\n</code></pre>"},{"location":"api/segmentation/stainings/#sopa.segmentation.stainings.StainingSegmentation.__init__","title":"<code>__init__(sdata, method, channels, min_area=0, clip_limit=0.2, gaussian_sigma=1)</code>","text":"<p>Generalized staining-based segmentation</p> <p>Sequential segmentation (slower)</p> <pre><code>from sopa.segmentation.stainings import StainingSegmentation\n\nmethod = ... # custom callable that runs segmentation on each patch\n\nsegmentation = StainingSegmentation(sdata, method, \"DAPI\")\ncells = segmentation.run_patches(2000, 100)\nStainingSegmentation.add_shapes(sdata, cells, image_key, \"method_name\")\n</code></pre> <p>Parallel segmentation (faster)</p> <pre><code>from sopa.segmentation.stainings import StainingSegmentation\n\nmethod = ... # custom callable that runs segmentation on each patch\n\nsegmentation = StainingSegmentation(sdata, method, \"DAPI\")\n\n# Run all this in a parallel manner, e.g. on different jobs\nfor i in range(len(sdata['sopa_patches'])):\n    segmentation.write_patch_cells(\"./temp_dir\", i)\n\ncells = StainingSegmentation.read_patches_cells(\"./temp_dir\")\nStainingSegmentation.add_shapes(sdata, cells, image_key, \"method_name\")\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>method</code> <code>Callable</code> <p>A segmentation <code>callable</code> whose input is an image of shape <code>(C, Y, X)</code> and output is a cell mask of shape <code>(Y, X)</code>. Each mask value <code>&gt;0</code> represent a unique cell ID. Such callables can be found in <code>sopa.segmentation.methods</code>.</p> required <code>channels</code> <code>list[str] | str</code> <p>One or a list of channel names used for segmentation. If only one channel is provided, the image given to the <code>method</code> will be of shape <code>(1, Y, X)</code>.</p> required <code>min_area</code> <code>float</code> <p>Minimum area (in pixels^2) for a cell to be kept</p> <code>0</code> <code>clip_limit</code> <code>float</code> <p>Parameter for skimage.exposure.equalize_adapthist (applied before running cellpose)</p> <code>0.2</code> <code>gaussian_sigma</code> <code>float</code> <p>Parameter for scipy gaussian_filter (applied before running cellpose)</p> <code>1</code> Source code in <code>sopa/segmentation/stainings.py</code> <pre><code>def __init__(\n    self,\n    sdata: SpatialData,\n    method: Callable,\n    channels: list[str] | str,\n    min_area: float = 0,\n    clip_limit: float = 0.2,\n    gaussian_sigma: float = 1,\n):\n    \"\"\"Generalized staining-based segmentation\n\n    !!! note \"Sequential segmentation (slower)\"\n        ```python\n        from sopa.segmentation.stainings import StainingSegmentation\n\n        method = ... # custom callable that runs segmentation on each patch\n\n        segmentation = StainingSegmentation(sdata, method, \"DAPI\")\n        cells = segmentation.run_patches(2000, 100)\n        StainingSegmentation.add_shapes(sdata, cells, image_key, \"method_name\")\n        ```\n\n    !!! note \"Parallel segmentation (faster)\"\n        ```python\n        from sopa.segmentation.stainings import StainingSegmentation\n\n        method = ... # custom callable that runs segmentation on each patch\n\n        segmentation = StainingSegmentation(sdata, method, \"DAPI\")\n\n        # Run all this in a parallel manner, e.g. on different jobs\n        for i in range(len(sdata['sopa_patches'])):\n            segmentation.write_patch_cells(\"./temp_dir\", i)\n\n        cells = StainingSegmentation.read_patches_cells(\"./temp_dir\")\n        StainingSegmentation.add_shapes(sdata, cells, image_key, \"method_name\")\n        ```\n\n    Args:\n        sdata: A `SpatialData` object\n        method: A segmentation `callable` whose input is an image of shape `(C, Y, X)` and output is a cell mask of shape `(Y, X)`. Each mask value `&gt;0` represent a unique cell ID. Such callables can be found in `sopa.segmentation.methods`.\n        channels: One or a list of channel names used for segmentation. If only one channel is provided, the image given to the `method` will be of shape `(1, Y, X)`.\n        min_area: Minimum area (in pixels^2) for a cell to be kept\n        clip_limit: Parameter for skimage.exposure.equalize_adapthist (applied before running cellpose)\n        gaussian_sigma: Parameter for scipy gaussian_filter (applied before running cellpose)\n    \"\"\"\n    self.sdata = sdata\n    self.method = method\n    self.channels = [channels] if isinstance(channels, str) else channels\n\n    self.min_area = min_area\n    self.clip_limit = clip_limit\n    self.gaussian_sigma = gaussian_sigma\n\n    self.image_key, self.image = get_spatial_image(sdata, return_key=True)\n\n    image_channels = self.image.coords[\"c\"].values\n    assert np.isin(\n        channels, image_channels\n    ).all(), f\"Channel names must be a subset of: {', '.join(image_channels)}\"\n</code></pre>"},{"location":"api/segmentation/stainings/#sopa.segmentation.stainings.StainingSegmentation.add_shapes","title":"<code>add_shapes(sdata, cells, image_key, shapes_key)</code>  <code>classmethod</code>","text":"<p>Adding <code>shapely</code> polygon to the <code>SpatialData</code> object</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>cells</code> <code>list[Polygon]</code> <p>List of polygons after segmentation</p> required <code>image_key</code> <code>str</code> <p>Key of the image on which segmentation has been run</p> required <code>shapes_key</code> <code>str</code> <p>Name to provide to the geodataframe to be created</p> required Source code in <code>sopa/segmentation/stainings.py</code> <pre><code>@classmethod\ndef add_shapes(cls, sdata: SpatialData, cells: list[Polygon], image_key: str, shapes_key: str):\n    \"\"\"Adding `shapely` polygon to the `SpatialData` object\n\n    Args:\n        sdata: A `SpatialData` object\n        cells: List of polygons after segmentation\n        image_key: Key of the image on which segmentation has been run\n        shapes_key: Name to provide to the geodataframe to be created\n    \"\"\"\n    image = get_spatial_image(sdata, image_key)\n\n    geo_df = gpd.GeoDataFrame({\"geometry\": cells})\n    geo_df.index = image_key + geo_df.index.astype(str)\n\n    geo_df = ShapesModel.parse(geo_df, transformations=get_transformation(image, get_all=True))\n    sdata.add_shapes(shapes_key, geo_df, overwrite=True)\n\n    log.info(f\"Added {len(geo_df)} cell boundaries in sdata['{shapes_key}']\")\n</code></pre>"},{"location":"api/segmentation/stainings/#sopa.segmentation.stainings.StainingSegmentation.read_patches_cells","title":"<code>read_patches_cells(patch_dir)</code>  <code>classmethod</code>","text":"<p>Read all patch segmentation results after running <code>write_patch_cells</code> on all patches</p> <p>Parameters:</p> Name Type Description Default <code>patch_dir</code> <code>str | list[str]</code> <p>Directory provided when running <code>write_patch_cells</code> containing the <code>.parquet</code> files. For multi-step segmentation, provide a list of directories (one per step).</p> required <p>Returns:</p> Type Description <code>list[Polygon]</code> <p>A list of cells represented as <code>shapely</code> polygons</p> Source code in <code>sopa/segmentation/stainings.py</code> <pre><code>@classmethod\ndef read_patches_cells(cls, patch_dir: str | list[str]) -&gt; list[Polygon]:\n    \"\"\"Read all patch segmentation results after running `write_patch_cells` on all patches\n\n    Args:\n        patch_dir: Directory provided when running `write_patch_cells` containing the `.parquet` files. For multi-step segmentation, provide a list of directories (one per step).\n\n    Returns:\n        A list of cells represented as `shapely` polygons\n    \"\"\"\n    cells = []\n\n    files = [f for f in Path(patch_dir).iterdir() if f.suffix == \".parquet\"]\n    for file in tqdm(files, desc=\"Reading patches\"):\n        cells += list(gpd.read_parquet(file).geometry)\n\n    log.info(f\"Found {len(cells)} total cells\")\n    return cells\n</code></pre>"},{"location":"api/segmentation/stainings/#sopa.segmentation.stainings.StainingSegmentation.run_patches","title":"<code>run_patches(patch_width, patch_overlap)</code>","text":"<p>Run segmentation over all patches, in a sequential manner (this is slower than running all patches in parallel)</p> <p>Parameters:</p> Name Type Description Default <code>patch_width</code> <code>int</code> <p>Width of the patches</p> required <code>patch_overlap</code> <code>int</code> <p>Number of pixels of overlap between patches</p> required <p>Returns:</p> Type Description <code>list[Polygon]</code> <p>A list of cells represented as <code>shapely</code> polygons</p> Source code in <code>sopa/segmentation/stainings.py</code> <pre><code>def run_patches(\n    self,\n    patch_width: int,\n    patch_overlap: int,\n) -&gt; list[Polygon]:\n    \"\"\"Run segmentation over all patches, in a sequential manner (this is slower than running all patches in parallel)\n\n    Args:\n        patch_width: Width of the patches\n        patch_overlap: Number of pixels of overlap between patches\n\n    Returns:\n        A list of cells represented as `shapely` polygons\n    \"\"\"\n    self.patches = Patches2D(self.sdata, self.image_key, patch_width, patch_overlap)\n\n    cells = [\n        cell\n        for patch in tqdm(self.patches.polygons, desc=\"Run on patches\")\n        for cell in self._run_patch(patch)\n    ]\n    cells = shapes.solve_conflicts(cells)\n    return cells\n</code></pre>"},{"location":"api/segmentation/stainings/#sopa.segmentation.stainings.StainingSegmentation.write_patch_cells","title":"<code>write_patch_cells(patch_dir, patch_index)</code>","text":"<p>Run segmentation on one patch, and save the result in a dedicated directory</p> <p>Parameters:</p> Name Type Description Default <code>patch_dir</code> <code>str</code> <p>Directory inside which segmentation results will be saved</p> required <code>patch_index</code> <code>int</code> <p>Index of the patch on which to run segmentation. NB: the number of patches is <code>len(sdata['sopa_patches'])</code></p> required Source code in <code>sopa/segmentation/stainings.py</code> <pre><code>def write_patch_cells(self, patch_dir: str, patch_index: int):\n    \"\"\"Run segmentation on one patch, and save the result in a dedicated directory\n\n    Args:\n        patch_dir: Directory inside which segmentation results will be saved\n        patch_index: Index of the patch on which to run segmentation. NB: the number of patches is `len(sdata['sopa_patches'])`\n    \"\"\"\n    patch = self.sdata[SopaKeys.PATCHES].geometry[patch_index]\n\n    cells = self._run_patch(patch)\n    gdf = gpd.GeoDataFrame(geometry=cells)\n\n    patch_dir: Path = Path(patch_dir)\n    patch_dir.mkdir(parents=True, exist_ok=True)\n    patch_file = patch_dir / f\"{patch_index}.parquet\"\n\n    gdf.to_parquet(patch_file)\n</code></pre>"},{"location":"api/utils/data/","title":"sopa.utils.data","text":""},{"location":"api/utils/data/#sopa.utils.data.uniform","title":"<code>sopa.utils.data.uniform(*_, length=2048, cell_density=0.0001, n_points_per_cell=50, c_coords=['DAPI', 'CK', 'CD3', 'CD20'], genes=['EPCAM', 'CD3E', 'CD20', 'CXCL4', 'CXCL10'], sigma_factor=0.1, seed=0, include_vertices=False, include_image=True, apply_blur=True)</code>","text":"<p>Generate a dummy dataset composed of cells generated uniformly in a square. It also has transcripts.</p> <p>Parameters:</p> Name Type Description Default <code>length</code> <code>int</code> <p>Size of the square, in pixels</p> <code>2048</code> <code>cell_density</code> <code>float</code> <p>Density of cells per pixel^2</p> <code>0.0001</code> <code>n_points_per_cell</code> <code>int</code> <p>Mean number of transcripts per cell</p> <code>50</code> <code>c_coords</code> <code>list[str]</code> <p>Channel names</p> <code>['DAPI', 'CK', 'CD3', 'CD20']</code> <code>genes</code> <code>int | list[str]</code> <p>Number of different genes, or list of gene names</p> <code>['EPCAM', 'CD3E', 'CD20', 'CXCL4', 'CXCL10']</code> <code>sigma_factor</code> <code>float</code> <p>Factor used to determine <code>sigma</code> for the gaussian blur.</p> <code>0.1</code> <code>seed</code> <code>int</code> <p>Numpy random seed</p> <code>0</code> <code>include_vertices</code> <code>bool</code> <p>Whether to include the vertices of the cells (as points) in the spatialdata object</p> <code>False</code> <code>include_image</code> <code>bool</code> <p>Whether to include the image in the spatialdata object</p> <code>True</code> <code>apply_blur</code> <code>bool</code> <p>Whether to apply gaussian blur on the image (without blur, cells are just one pixel)</p> <code>True</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A SpatialData object with a 2D image (<code>sdata[\"image\"]</code>), the cells polygon boundaries (<code>sdata[\"cells\"]</code>), the transcripts (<code>sdata[\"transcripts\"]</code>), and optional cell vertices (<code>sdata[\"vertices\"]</code>) if <code>include_vertices</code> is <code>True</code>.</p> Source code in <code>sopa/utils/data.py</code> <pre><code>def uniform(\n    *_,\n    length: int = 2_048,\n    cell_density: float = 1e-4,\n    n_points_per_cell: int = 50,\n    c_coords: list[str] = [\"DAPI\", \"CK\", \"CD3\", \"CD20\"],\n    genes: int | list[str] = [\"EPCAM\", \"CD3E\", \"CD20\", \"CXCL4\", \"CXCL10\"],\n    sigma_factor: float = 0.1,\n    seed: int = 0,\n    include_vertices: bool = False,\n    include_image: bool = True,\n    apply_blur: bool = True,\n) -&gt; SpatialData:\n    \"\"\"Generate a dummy dataset composed of cells generated uniformly in a square. It also has transcripts.\n\n    Args:\n        length: Size of the square, in pixels\n        cell_density: Density of cells per pixel^2\n        n_points_per_cell: Mean number of transcripts per cell\n        c_coords: Channel names\n        genes: Number of different genes, or list of gene names\n        sigma_factor: Factor used to determine `sigma` for the gaussian blur.\n        seed: Numpy random seed\n        include_vertices: Whether to include the vertices of the cells (as points) in the spatialdata object\n        include_image: Whether to include the image in the spatialdata object\n        apply_blur: Whether to apply gaussian blur on the image (without blur, cells are just one pixel)\n\n    Returns:\n        A SpatialData object with a 2D image (`sdata[\"image\"]`), the cells polygon boundaries (`sdata[\"cells\"]`), the transcripts (`sdata[\"transcripts\"]`), and optional cell vertices (`sdata[\"vertices\"]`) if `include_vertices` is `True`.\n    \"\"\"\n    np.random.seed(seed)\n\n    grid_width = max(1, int(length * np.sqrt(cell_density)))\n    dx = length / grid_width\n    sigma = dx * sigma_factor\n    n_cells = grid_width**2\n    radius = int(dx) // 4\n    cell_types_index = np.random.randint(0, max(1, len(c_coords) - 1), n_cells)\n\n    log.info(\n        f\"Image of size ({len(c_coords), length, length}) with {n_cells} cells and {n_points_per_cell} transcripts per cell\"\n    )\n\n    # Compute cell vertices (xy array)\n    vertices_x = dx / 2 + np.arange(grid_width) * dx\n    x, y = np.meshgrid(vertices_x, vertices_x)\n    xy = np.stack([x.ravel(), y.ravel()], axis=1)\n    xy += np.random.uniform(-dx / 2, dx / 2, size=xy.shape)\n    xy = xy.clip(0, length - 1).astype(int)\n\n    vertices = pd.DataFrame(xy, columns=[\"x\", \"y\"])\n\n    # Create image\n    images = {}\n\n    if include_image:\n        x_circle, y_circle = circle_coords(radius)\n\n        image = np.zeros((len(c_coords), length, length))\n        for i, (x, y) in enumerate(xy):\n            y_coords = (y + y_circle).clip(0, image.shape[1] - 1)\n            x_coords = (x + x_circle).clip(0, image.shape[2] - 1)\n            image[0, y_coords, x_coords] = 1\n            if len(c_coords) &gt; 1:\n                image[cell_types_index[i] + 1, y_coords, x_coords] = 1\n        if apply_blur:\n            image = gaussian_filter(image, sigma=sigma, axes=(1, 2))\n        image = (image / image.max() * 255).astype(np.uint8)\n        image = da.from_array(image, chunks=(1, 4096, 4096))\n        images[\"image\"] = Image2DModel.parse(image, c_coords=c_coords, dims=[\"c\", \"y\", \"x\"])\n\n    # Create cell boundaries\n    cells = [Point(vertex).buffer(radius).simplify(tolerance=1) for vertex in xy]\n    bbox = box(0, 0, length - 1, length - 1)\n    cells = [cell.intersection(bbox) for cell in cells]\n    gdf = gpd.GeoDataFrame(geometry=cells)\n    shapes = {\"cells\": ShapesModel.parse(gdf)}\n\n    # Create transcripts\n    n_genes = n_cells * n_points_per_cell\n    point_cell_index = np.arange(n_cells).repeat(n_points_per_cell)\n    points_coords = radius / 2 * np.random.randn(n_genes, 2) + xy[point_cell_index]\n    points_coords = points_coords.clip(0, length - 1)\n\n    if isinstance(genes, int):\n        gene_names = np.random.choice([chr(97 + i) for i in range(n_genes)], size=n_genes)\n    elif len(genes) and len(genes) &gt;= len(c_coords) - 1:\n        gene_names = np.full(n_genes, \"\", dtype=\"&lt;U5\")\n        for i in range(len(genes)):\n            where_cell_type = np.where(cell_types_index[point_cell_index] == i)[0]\n            probabilities = np.full(len(genes), 0.2 / (len(genes) - 1))\n            probabilities[i] = 0.8\n            gene_names[where_cell_type] = np.random.choice(\n                genes, len(where_cell_type), p=probabilities\n            )\n    else:\n        gene_names = np.random.choice(genes, size=n_genes)\n\n    df = pd.DataFrame(\n        {\n            \"x\": points_coords[:, 0],\n            \"y\": points_coords[:, 1],\n            \"genes\": gene_names,\n        }\n    )\n    df = dd.from_pandas(df, chunksize=2_000_000)\n\n    points = {\"transcripts\": PointsModel.parse(df)}\n    if include_vertices:\n        points[\"vertices\"] = PointsModel.parse(vertices)\n\n    return SpatialData(images=images, points=points, shapes=shapes)\n</code></pre>"},{"location":"api/utils/data/#sopa.utils.data.blobs","title":"<code>sopa.utils.data.blobs(*_, length=1024, n_points=10000, c_coords=['DAPI', 'CK', 'CD3', 'CD20'], **kwargs)</code>","text":"<p>Adapts the blobs dataset from SpatialData for sopa. Please refer to the SpatialData documentation</p> Source code in <code>sopa/utils/data.py</code> <pre><code>def blobs(\n    *_,\n    length: int = 1_024,\n    n_points: int = 10_000,\n    c_coords=[\"DAPI\", \"CK\", \"CD3\", \"CD20\"],\n    **kwargs,\n) -&gt; SpatialData:\n    \"\"\"Adapts the blobs dataset from SpatialData for sopa. Please refer to the SpatialData documentation\"\"\"\n    _blobs = BlobsDataset(\n        length=length, n_points=n_points, c_coords=c_coords, n_channels=len(c_coords), **kwargs\n    )\n\n    image = _blobs._image_blobs(\n        _blobs.transformations,\n        _blobs.length,\n        _blobs.n_channels,\n        _blobs.c_coords,\n    )\n    image.data = (image.data * 255).astype(np.uint8)\n\n    points = _blobs._points_blobs(_blobs.transformations, _blobs.length, _blobs.n_points)\n    genes = pd.Series(np.random.choice(list(\"abcdef\"), size=len(points))).astype(\"category\")\n    points[\"genes\"] = dd.from_pandas(genes, npartitions=points.npartitions)\n\n    return SpatialData(images={\"blob_image\": image}, points={\"blob_transcripts\": points})\n</code></pre>"},{"location":"api/utils/image/","title":"sopa.utils.image","text":""},{"location":"api/utils/image/#sopa.utils.image.scale_dtype","title":"<code>sopa.utils.image.scale_dtype(arr, dtype)</code>","text":"<p>Change the dtype of an array but keep the scale compared to the type maximum value.</p> <p>Example</p> <p>For an array of dtype <code>uint8</code> being transformed to <code>np.uint16</code>, the value <code>255</code> will become <code>65535</code></p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>ndarray</code> <p>A <code>numpy</code> array</p> required <code>dtype</code> <code>dtype</code> <p>Target <code>numpy</code> data type</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A scaled <code>numpy</code> array with the dtype provided.</p> Source code in <code>sopa/utils/image.py</code> <pre><code>def scale_dtype(arr: np.ndarray, dtype: np.dtype) -&gt; np.ndarray:\n    \"\"\"Change the dtype of an array but keep the scale compared to the type maximum value.\n\n    !!! note \"Example\"\n        For an array of dtype `uint8` being transformed to `np.uint16`, the value `255` will become `65535`\n\n    Args:\n        arr: A `numpy` array\n        dtype: Target `numpy` data type\n\n    Returns:\n        A scaled `numpy` array with the dtype provided.\n    \"\"\"\n    _check_integer_dtype(arr.dtype)\n    _check_integer_dtype(dtype)\n\n    if arr.dtype == dtype:\n        return arr\n\n    factor = np.iinfo(dtype).max / np.iinfo(arr.dtype).max\n    return (arr * factor).astype(dtype)\n</code></pre>"},{"location":"api/utils/image/#sopa.utils.image.resize","title":"<code>sopa.utils.image.resize(xarr, scale_factor)</code>","text":"<p>Resize a xarray image</p> <p>Parameters:</p> Name Type Description Default <code>xarr</code> <code>DataArray</code> <p>A <code>xarray</code> array</p> required <code>scale_factor</code> <code>float</code> <p>Scale factor of resizing, e.g. <code>2</code> will decrease the width by 2</p> required <p>Returns:</p> Type Description <code>Array</code> <p>Resized dask array</p> Source code in <code>sopa/utils/image.py</code> <pre><code>def resize(xarr: xr.DataArray, scale_factor: float) -&gt; da.Array:\n    \"\"\"Resize a xarray image\n\n    Args:\n        xarr: A `xarray` array\n        scale_factor: Scale factor of resizing, e.g. `2` will decrease the width by 2\n\n    Returns:\n        Resized dask array\n    \"\"\"\n    resize_dims = [dim in [\"x\", \"y\"] for dim in xarr.dims]\n    transform = np.diag([scale_factor if resize_dim else 1 for resize_dim in resize_dims])\n    output_shape = [\n        size // scale_factor if resize_dim else size\n        for size, resize_dim in zip(xarr.shape, resize_dims)\n    ]\n\n    return dask_image.ndinterp.affine_transform(\n        xarr.data, matrix=transform, output_shape=output_shape\n    )\n</code></pre>"},{"location":"api/utils/image/#sopa.utils.image.resize_numpy","title":"<code>sopa.utils.image.resize_numpy(arr, scale_factor, dims, output_shape)</code>","text":"<p>Resize a numpy image</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>ndarray</code> <p>a <code>numpy</code> array</p> required <code>scale_factor</code> <code>float</code> <p>Scale factor of resizing, e.g. <code>2</code> will decrease the width by 2</p> required <code>dims</code> <code>list[str]</code> <p>List of dimension names. Only <code>\"x\"</code> and <code>\"y\"</code> are resized.</p> required <code>output_shape</code> <code>list[int]</code> <p>Size of the output array</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Resized array</p> Source code in <code>sopa/utils/image.py</code> <pre><code>def resize_numpy(\n    arr: np.ndarray, scale_factor: float, dims: list[str], output_shape: list[int]\n) -&gt; np.ndarray:\n    \"\"\"Resize a numpy image\n\n    Args:\n        arr: a `numpy` array\n        scale_factor: Scale factor of resizing, e.g. `2` will decrease the width by 2\n        dims: List of dimension names. Only `\"x\"` and `\"y\"` are resized.\n        output_shape: Size of the output array\n\n    Returns:\n        Resized array\n    \"\"\"\n    resize_dims = [dim in [\"x\", \"y\"] for dim in dims]\n    transform = np.diag([scale_factor if resize_dim else 1 for resize_dim in resize_dims])\n\n    return dask_image.ndinterp.affine_transform(\n        arr, matrix=transform, output_shape=output_shape\n    ).compute()\n</code></pre>"},{"location":"api/utils/polygon_crop/","title":"sopa.utils.polygon_crop","text":""},{"location":"api/utils/polygon_crop/#sopa.utils.polygon_crop.polygon_selection","title":"<code>sopa.utils.polygon_crop.polygon_selection(sdata, intermediate_image=None, intermediate_polygon=None, channels=None, scale_factor=10, margin_ratio=0.1)</code>","text":"<p>Crop an image based on a user-defined polygon (interactive mode).</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>intermediate_image</code> <code>str | None</code> <p>Path to the intermediate image, with a <code>.zip</code> extension. Use this only if the interactive mode is not available</p> <code>None</code> <code>intermediate_polygon</code> <code>str | None</code> <p>Path to the intermediate polygon, with a <code>.zip</code> extension. Use this locally, after downloading the <code>intermediate_image</code></p> <code>None</code> <code>channels</code> <code>list[str] | None</code> <p>List of channel names to be displayed. Optional if there are already only 1 or 3 channels.</p> <code>None</code> <code>scale_factor</code> <code>float</code> <p>Resize the image by this value (high value for a lower memory usage)</p> <code>10</code> <code>margin_ratio</code> <code>float</code> <p>Ratio of the image margin on the display (compared to the image size)</p> <code>0.1</code> Source code in <code>sopa/utils/polygon_crop.py</code> <pre><code>def polygon_selection(\n    sdata: SpatialData,\n    intermediate_image: str | None = None,\n    intermediate_polygon: str | None = None,\n    channels: list[str] | None = None,\n    scale_factor: float = 10,\n    margin_ratio: float = 0.1,\n):\n    \"\"\"Crop an image based on a user-defined polygon (interactive mode).\n\n    Args:\n        sdata: A `SpatialData` object\n        intermediate_image: Path to the intermediate image, with a `.zip` extension. Use this only if the interactive mode is not available\n        intermediate_polygon: Path to the intermediate polygon, with a `.zip` extension. Use this locally, after downloading the `intermediate_image`\n        channels: List of channel names to be displayed. Optional if there are already only 1 or 3 channels.\n        scale_factor: Resize the image by this value (high value for a lower memory usage)\n        margin_ratio: Ratio of the image margin on the display (compared to the image size)\n    \"\"\"\n    if intermediate_polygon is None:\n        image_key, image = _prepare(sdata, channels, scale_factor)\n\n        if intermediate_image is not None:\n            log.info(f\"Resized image will be saved to {intermediate_image}\")\n            with zarr.ZipStore(intermediate_image, mode=\"w\") as store:\n                g = zarr.group(store=store)\n                g.attrs.put({ROI.SCALE_FACTOR: scale_factor, ROI.IMAGE_KEY: image_key})\n                g.array(ROI.IMAGE_ARRAY_KEY, image, dtype=image.dtype, chunks=image.shape)\n            return\n\n        polygon = _draw_polygon(image, scale_factor, margin_ratio)\n    else:\n        log.info(f\"Reading polygon at path {intermediate_polygon}\")\n        z = zarr.open(intermediate_polygon, mode=\"r\")\n        polygon = Polygon(z[ROI.POLYGON_ARRAY_KEY][:])\n        image_key = z.attrs[ROI.IMAGE_KEY]\n\n        image = get_spatial_image(sdata, image_key)\n\n    geo_df = gpd.GeoDataFrame(geometry=[polygon])\n\n    geo_df = ShapesModel.parse(\n        geo_df, transformations=get_transformation(sdata[image_key], get_all=True)\n    )\n    sdata.add_shapes(ROI.KEY, geo_df)\n\n    log.info(f\"Polygon saved in sdata['{ROI.KEY}']\")\n</code></pre>"},{"location":"tutorials/advanced_segmentation/","title":"Advanced segmentation","text":"<p>The Sopa CLI and pipeline are based on Cellpose for staining-based segmentation. Yet, if desired, one can implement another staining-based segmentation algorithm or use a multi-step segmentation process on multiple channels.</p>"},{"location":"tutorials/advanced_segmentation/#multi-step-segmentation","title":"Multi-step segmentation","text":"<p>Multi-step segmentation consists of running multiple times Cellpose over the whole slides with different parameters. For instance, we can first run a nucleus segmentation using DAPI, then another round using DAPI and a membrane staining, and finally, DAPI and cell boundary staining. This can make the segmentation more robust. Note that the results of the multiple steps are combined into one final segmentation.</p> <p>Warning</p> <p>Here, we only detail the multi-step segmentation. For the rest of the CLI usage, refer to our CLI usage tutorial, and only replace the \"Run segmentation\" section with the instructions below.</p> <p>First, generate the bounding boxes of the patches on which Cellpose will be run. Here, the patches have a width and height of 1500 pixels, and an overlap of 50 pixels. We advise bigger sizes for real datasets (see our default parameters in one of our config files). On the toy dataset, this will generate 4 patches.</p> <pre><code>sopa patchify image tuto.zarr --patch-width-pixel 1500 --patch-overlap-pixel 50\n</code></pre> <p>Now, we can run Cellpose on each of the four patches and for each \"segmentation step\" we want. In this toy example, we run 3 steps with (i) DAPI + CK, (ii) DAPI + CD3, and (iii) DAPI + CD20.</p> <p>Tip</p> <p>Manually running the commands below can involve using many consecutive commands, so we recommend automatizing it. For instance, this can be done using Snakemake or Nextflow. Mainly, this will help you parallelize it since you can run each task on separate jobs or using multithreading. You can also see how we do it in the Sopa Snakemake pipeline.</p> <p>To automatically get the number of patches, you can either open the <code>tuto.zarr/.sopa_cache/patches_file_image</code> file or compute <code>len(sdata['sopa_patches'])</code> in Python.</p> Patch 0Patch 1Patch 2Patch 3 <pre><code>sopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CK \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CK \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 0\n\nsopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CD3 \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CD3 \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 0\n\nsopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CD20 \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CD20 \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 0\n</code></pre> <pre><code>sopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CK \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CK \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 1\n\nsopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CD3 \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CD3 \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 1\n\nsopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CD20 \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CD20 \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 1\n</code></pre> <pre><code>sopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CK \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CK \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 2\n\nsopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CD3 \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CD3 \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 2\n\nsopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CD20 \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CD20 \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 2\n</code></pre> <pre><code>sopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CK \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CK \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 3\n\nsopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CD3 \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CD3 \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 3\n\nsopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CD20 \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CD20 \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 3\n</code></pre> <p>Note</p> <p>In the above commands, the <code>--diameter</code> and <code>--min-area</code> parameters are specific to the data type we work on. For your own data, consider using the default parameters from one of our config files. Here, <code>min-area</code> is in pixels^2.</p> <p>At this stage, you executed 12 times Cellpose (3 steps on each of the 4 patches). Now, we need to resolve the conflict, i.e., merge the three segmentations into one. Note that we gave the paths to the temporary boundaries we made above. <pre><code>sopa resolve cellpose tuto.zarr \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CK \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CD3 \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CD20\n</code></pre></p> <p>Congrats, you have now merged the results of a three-step segmentation! You can now refer to our normal CLI usage tutorial for all the other tasks.</p>"},{"location":"tutorials/advanced_segmentation/#custom-staining-based-segmentation","title":"Custom staining-based segmentation","text":"<p>You can plug your segmentation model into Sopa to benefit from all the other functionalities. In particular, it will scale the segmentation since Sopa will run on small patches.</p>"},{"location":"tutorials/advanced_segmentation/#1-define-your-segmentation-function","title":"1. Define your segmentation function","text":"<p>You need a Python function as described below:</p> <ul> <li> <p>The function input is an image of shape <code>(C, Y, X)</code> (<code>C</code> is the number of desired channels; it can be one if you want DAPI only)</p> </li> <li> <p>The function output is a mask of shape <code>(Y, X)</code>. This mask should contain positive values representing the segmented cells, and contain <code>0</code> outside of the cells. For instance, if 4 cells are segmented, the mask should contain the values 1, 2, 3, and eventually 0 (where there is no cell).</p> </li> </ul> <p>If you want to use our API, you can find a detailed example of custom segmentation here. Else, if you want to use the CLI, continue below.</p> <p>This function should be wrapped into a \"method builder\". The purpose is that you can provide arguments to the method builder that your desired function can then use. For instance, this is a dummy method builder whose segmentation function only creates one cell:</p> <pre><code>def dummy_method(**method_kwargs):\n    \"\"\"A method builder (i.e. it returns a segmentation function).\n    Kwargs can be provided and used in the below function\"\"\"\n\n    def segmentation_function(image: np.ndarray) -&gt; np.ndarray:\n        \"\"\"A dummy example of a custom segmentation method\n        that creates one cell (with a padding of 10 pixels).\n\n        Args:\n            image: An image of shape `(C, Y, X)`\n\n        Returns:\n            A mask of shape `(Y, X)` containing one cell\n        \"\"\"\n        mask = np.zeros(image.shape[1:], dtype=int)\n\n        # one cell, corresponding to value 1\n        mask[10:-10, 10:-10] = 1  # squared shaped\n\n        return mask\n\n    return segmentation_function\n</code></pre>"},{"location":"tutorials/advanced_segmentation/#2-setup","title":"2. Setup","text":"<p>To use the CLI, you'll need to clone the repository. Also, we recommend installing Sopa in dev mode, allowing you to update your segmentation function without re-installing everything. For instance: </p> <pre><code>git clone https://github.com/gustaveroussy/sopa.git\ncd sopa\n\n# create an empty conda env\nconda create --name sopa python=3.10\nconda activate sopa\n\n# install the extras you want\npip install -e \".[cellpose,baysor,tangram]\"\n</code></pre>"},{"location":"tutorials/advanced_segmentation/#3-run-your-custom-segmentation","title":"3. Run your custom segmentation","text":"<p>Warning</p> <p>Here, we only detail the multi-step segmentation. For the rest of the CLI usage, refer to our CLI usage tutorial, and only replace the \"Run segmentation\" section with the instructions below.</p> <p>Similarly to the tutorial for Cellpose, first start by generating patches:</p> <pre><code>sopa patchify image tuto.zarr --patch-width-pixel 1500 --patch-overlap-pixel 50\n</code></pre> <p>Then, call the CLI by providing the name of your method builder, i.e. replace <code>&lt;BUILDER_NAME&gt;</code> in the following commands:</p> <p>Note</p> <p>The process below is similar to the one of the Cellpose tutorial in the CLI usage tutorial.</p> Patch 0Patch 1Patch 2Patch 3 <pre><code>sopa segmentation generic-staining tuto.zarr \\\n    --method-name &lt;BUILDER_NAME&gt; \\\n    --channels DAPI \\\n    --patch-index 0\n</code></pre> <pre><code>sopa segmentation generic-staining tuto.zarr \\\n    --method-name &lt;BUILDER_NAME&gt; \\\n    --channels DAPI \\\n    --patch-index 1\n</code></pre> <pre><code>sopa segmentation generic-staining tuto.zarr \\\n    --method-name &lt;BUILDER_NAME&gt; \\\n    --channels DAPI \\\n    --patch-index 2\n</code></pre> <pre><code>sopa segmentation generic-staining tuto.zarr \\\n    --method-name &lt;BUILDER_NAME&gt; \\\n    --channels DAPI \\\n    --patch-index 3\n</code></pre> <p>And, to resolve the conflicts:</p> <pre><code>sopa resolve generic tuto.zarr --method-name &lt;BUILDER_NAME&gt;\n</code></pre> <p>Finally, aggregate the results:</p> <pre><code>sopa aggregate tuto.zarr --method-name &lt;BUILDER_NAME&gt; --gene-column genes --average-intensities\n</code></pre> <p>Congrats, you have now run your custom segmentation method! You can now refer to our normal CLI usage tutorial for all the other tasks.</p>"},{"location":"tutorials/align/","title":"Align images (e.g. H&E)","text":"<p>If you have an H&amp;E image or immunofluorescence data that you want to align on the main image, this can be done with the Xenium Explorer, even if you don't work on Xenium data.</p>"},{"location":"tutorials/align/#image-conversion","title":"Image conversion","text":"<p>Convert your image with QuPath as written in this 10x genomics webpage.</p> <p>If you are not familiar with QuPath, you can also use our API to write the image: <pre><code>from sopa import io\nfrom sopa.io.explorer import write_image\n\nimage = io.ome_tif(\"path/to/your/image.tif\") # or use a different reader\nwrite_image(\"where/to/save/image.ome.tif\", image, is_dir=False)\n</code></pre></p> <p>Xenium users</p> <p>If using the Xenium machine, then you don't need conversion; the images provided by the Xenium machine already have the correct format.</p>"},{"location":"tutorials/align/#open-your-data-in-the-xenium-explorer","title":"Open your data in the Xenium Explorer","text":"<p>If not done yet, convert your <code>SpatialData</code> object to the Xenium Explorer's inputs. This can be done as detailed in this tutorial.</p> <p>Double-click on the <code>experiment.xenium</code> file, or select it from the Xenium Explorer interface. It will display the data in the explorer.</p>"},{"location":"tutorials/align/#keypoint-placement","title":"Keypoint placement","text":"<p>Warning</p> <p>Make sure your Xenium Explorer version is at least <code>1.3.0</code></p> <p>On the Xenium Explorer, under the \"Images\" panel, click \"Add image\" and follow the instructions on the screen.</p> <p> </p> <p>Afterwards, the explorer will automatically align the images based on the key points you selected on both images.</p>"},{"location":"tutorials/align/#optional-update-the-spatialdata-object","title":"(Optional) Update the <code>SpatialData</code> object","text":"<p>After alignment, export the transformation matrix as a <code>.csv</code> file. For that, select your aligned image under the \"Images\" panel and click on \"Download Alignment File\":</p> <p> </p> <p>Then, select only the \"Transformation Matrix\" box and download it:</p> <p> </p> <p>Then, use the CLI to update your <code>SpatialData</code> object. You'll need the path to the <code>.zarr</code> directory corresponding to your <code>SpatialData</code> object (<code>SDATA_PATH</code>), the path to the <code>.ome.tif</code> image that you converted above (<code>IMAGE_PATH</code>), and the <code>.csv</code> transformation matrix that you exported from the Xenium Explorer (<code>TRANSFORMATION_MATRIX_PATH</code>):</p> <pre><code>sopa explorer add-aligned &lt;SDATA_PATH&gt; &lt;IMAGE_PATH&gt; &lt;TRANSFORMATION_MATRIX_PATH&gt;\n</code></pre>"},{"location":"tutorials/api_usage/","title":"API usage","text":"In\u00a0[1]: Copied! <pre>from sopa.utils.data import uniform\nimport sopa.segmentation\nimport sopa.io\n</pre> from sopa.utils.data import uniform import sopa.segmentation import sopa.io In\u00a0[2]: Copied! <pre># The line below creates a toy dataset for this tutorial\n# Instead, use sopa.io to read your own data as a SpatialData object: see https://gustaveroussy.github.io/sopa/api/io/\n# For instance, if you have MERSCOPE data, you can do `sdata = sopa.io.merscope(\"/path/to/region_0\")`\nsdata = uniform()\n\nsdata.write(\"tuto.zarr\", overwrite=True)\nsdata\n</pre> # The line below creates a toy dataset for this tutorial # Instead, use sopa.io to read your own data as a SpatialData object: see https://gustaveroussy.github.io/sopa/api/io/ # For instance, if you have MERSCOPE data, you can do `sdata = sopa.io.merscope(\"/path/to/region_0\")` sdata = uniform()  sdata.write(\"tuto.zarr\", overwrite=True) sdata <pre>[INFO] (sopa.utils.data) Image of size ((4, 2048, 2048)) with 400 cells and 50 transcripts per cell\n</pre> Out[2]: <pre>SpatialData object with:\n\u251c\u2500\u2500 Images\n\u2502     \u2514\u2500\u2500 'image': SpatialImage[cyx] (4, 2048, 2048)\n\u251c\u2500\u2500 Points\n\u2502     \u2514\u2500\u2500 'transcripts': DataFrame with shape: (20000, 3) (2D points)\n\u2514\u2500\u2500 Shapes\n      \u2514\u2500\u2500 'cells': GeoDataFrame shape: (400, 1) (2D shapes)\nwith coordinate systems:\n\u25b8 'global', with elements:\n        image (Images), transcripts (Points), cells (Shapes)</pre> <p>Before starting, we create the variables below that denotes the names of the image and transcripts that we want to use, as displayed in the <code>SpatialData</code> object above:</p> In\u00a0[3]: Copied! <pre>image_key = \"image\"\npoints_key = \"transcripts\" # (ignore this for multiplex imaging)\ngene_column = \"genes\" # (optional) column of sdata[points_key] containing the gene names\n</pre> image_key = \"image\" points_key = \"transcripts\" # (ignore this for multiplex imaging) gene_column = \"genes\" # (optional) column of sdata[points_key] containing the gene names In\u00a0[4]: Copied! <pre>shapes_key = \"cellpose_boundaries\" # the name that we will give to the cellpose \"shapes\"\n</pre> shapes_key = \"cellpose_boundaries\" # the name that we will give to the cellpose \"shapes\" <p>The following channels are available for segmentation. Choose one or two channels used by Cellpose.</p> In\u00a0[5]: Copied! <pre>print(sdata[image_key].c.values)\n</pre> print(sdata[image_key].c.values) <pre>['DAPI' 'CK' 'CD3' 'CD20']\n</pre> <p>Then, we initialize the Cellpose model. Here, we run segmentation using DAPI only, and we set the cell diameter to be about <code>35</code> pixels:</p> In\u00a0[6]: Copied! <pre>channels = [\"DAPI\"]\n\nmethod = sopa.segmentation.methods.cellpose_patch(diameter=35, channels=channels, flow_threshold=2, cellprob_threshold=-6)\nsegmentation = sopa.segmentation.StainingSegmentation(sdata, method, channels, min_area=2500)\n</pre> channels = [\"DAPI\"]  method = sopa.segmentation.methods.cellpose_patch(diameter=35, channels=channels, flow_threshold=2, cellprob_threshold=-6) segmentation = sopa.segmentation.StainingSegmentation(sdata, method, channels, min_area=2500) In\u00a0[24]: Copied! <pre>cells = segmentation.run_patches(patch_width=1200, patch_overlap=50)\n\nsopa.segmentation.StainingSegmentation.add_shapes(sdata, cells, image_key, shapes_key)\n</pre> cells = segmentation.run_patches(patch_width=1200, patch_overlap=50)  sopa.segmentation.StainingSegmentation.add_shapes(sdata, cells, image_key, shapes_key) <pre>[INFO] (sopa.segmentation.shapes) Percentage of non-geometrized cells: 12.44% (usually due to segmentation artefacts)\n[INFO] (sopa.segmentation.shapes) Percentage of non-geometrized cells: 13.68% (usually due to segmentation artefacts)\n[INFO] (sopa.segmentation.shapes) Percentage of non-geometrized cells: 15.69% (usually due to segmentation artefacts)\n[INFO] (sopa.segmentation.shapes) Percentage of non-geometrized cells: 10.71% (usually due to segmentation artefacts)\nRun on patches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:54&lt;00:00, 13.67s/it]\nResolving conflicts: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 210/210 [00:00&lt;00:00, 15649.55it/s]\n[INFO] (sopa.segmentation.stainings) Added 321 cell boundaries in sdata['cellpose_boundaries']\n</pre> In\u00a0[7]: Copied! <pre>patches = sopa.segmentation.Patches2D(sdata, image_key, patch_width=1200, patch_overlap=50)\npatches.write()\n</pre> patches = sopa.segmentation.Patches2D(sdata, image_key, patch_width=1200, patch_overlap=50) patches.write() <pre>[INFO] (sopa.segmentation.patching) 4 patches were saved in sdata['sopa_patches']\n</pre> <p>Then, we run segmentation on each patch, and save the results in a temporary directory (here, <code>tuto.zarr/.sopa_cache</code>).</p> <p>On this example, we performed a \"for-loop\" here, so you should paralellize this using multiple jobs or multi-threading.</p> In\u00a0[8]: Copied! <pre>cellpose_temp_dir = \"tuto.zarr/.sopa_cache/cellpose\"\n\nfor patch_index in range(len(sdata['sopa_patches'])):\n    segmentation.write_patch_cells(cellpose_temp_dir, patch_index)\n</pre> cellpose_temp_dir = \"tuto.zarr/.sopa_cache/cellpose\"  for patch_index in range(len(sdata['sopa_patches'])):     segmentation.write_patch_cells(cellpose_temp_dir, patch_index) <pre>[INFO] (sopa.segmentation.shapes) Percentage of non-geometrized cells: 12.44% (usually due to segmentation artefacts)\n[INFO] (sopa.segmentation.shapes) Percentage of non-geometrized cells: 13.68% (usually due to segmentation artefacts)\n[INFO] (sopa.segmentation.shapes) Percentage of non-geometrized cells: 15.69% (usually due to segmentation artefacts)\n[INFO] (sopa.segmentation.shapes) Percentage of non-geometrized cells: 10.71% (usually due to segmentation artefacts)\n</pre> <p>At this stage, you executed 4 times Cellpose (once per patch). Now, we need to resolve the conflict, i.e. where boundaries are overlapping due to segmentation on multiple patches:</p> In\u00a0[9]: Copied! <pre>cells = sopa.segmentation.StainingSegmentation.read_patches_cells(cellpose_temp_dir)\ncells = sopa.segmentation.shapes.solve_conflicts(cells)\n\nshapes_key = \"cellpose_boundaries\"\n\nsopa.segmentation.StainingSegmentation.add_shapes(sdata, cells, image_key, shapes_key)\n</pre> cells = sopa.segmentation.StainingSegmentation.read_patches_cells(cellpose_temp_dir) cells = sopa.segmentation.shapes.solve_conflicts(cells)  shapes_key = \"cellpose_boundaries\"  sopa.segmentation.StainingSegmentation.add_shapes(sdata, cells, image_key, shapes_key) <pre>Reading patches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 222.94it/s]\n[INFO] (sopa.segmentation.stainings) Found 346 total cells\nResolving conflicts: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 210/210 [00:00&lt;00:00, 16158.57it/s]\n[INFO] (sopa.segmentation.stainings) Added 321 cell boundaries in sdata['cellpose_boundaries']\n</pre> In\u00a0[4]: Copied! <pre>shapes_key = \"baysor_boundaries\" # the name that we will give to the baysor \"shapes\"\n</pre> shapes_key = \"baysor_boundaries\" # the name that we will give to the baysor \"shapes\" <p>Baysor needs a config to be executed. You can find official config examples here.</p> <p>You can also reuse the Baysor parameter we have defined for each machine, as in our Snakemake config files. Note that, our Snakemake config is a <code>.yaml</code> file, but the Baysor config should still be a <code>.toml</code> file.</p> <p>For this tutorial, we will use the config below. Instead of a dictionnary, you can also have a <code>.toml</code> file and provide <code>config_path</code> to the <code>patchify_transcripts</code> function.</p> In\u00a0[5]: Copied! <pre>config = {\n    \"data\": {\n        \"force_2d\": True,\n        \"min_molecules_per_cell\": 10,\n        \"x\": \"x\",\n        \"y\": \"y\",\n        \"z\": \"z\",\n        \"gene\": \"genes\",\n        \"min_molecules_per_gene\": 0,\n        \"min_molecules_per_segment\": 3,\n        \"confidence_nn_id\": 6\n    },\n    \"segmentation\": {\n        \"scale\": 30,  # Important parameter: typical cell diameter, in microns (see our configs)\n        \"scale_std\": \"25%\",\n        \"prior_segmentation_confidence\": 0,\n        \"estimate_scale_from_centers\": False,\n        \"n_clusters\": 4,\n        \"iters\": 500,\n        \"n_cells_init\": 0,\n        \"nuclei_genes\": \"\",\n        \"cyto_genes\": \"\",\n        \"new_component_weight\": 0.2,\n        \"new_component_fraction\": 0.3\n    }\n}\n</pre> config = {     \"data\": {         \"force_2d\": True,         \"min_molecules_per_cell\": 10,         \"x\": \"x\",         \"y\": \"y\",         \"z\": \"z\",         \"gene\": \"genes\",         \"min_molecules_per_gene\": 0,         \"min_molecules_per_segment\": 3,         \"confidence_nn_id\": 6     },     \"segmentation\": {         \"scale\": 30,  # Important parameter: typical cell diameter, in microns (see our configs)         \"scale_std\": \"25%\",         \"prior_segmentation_confidence\": 0,         \"estimate_scale_from_centers\": False,         \"n_clusters\": 4,         \"iters\": 500,         \"n_cells_init\": 0,         \"nuclei_genes\": \"\",         \"cyto_genes\": \"\",         \"new_component_weight\": 0.2,         \"new_component_fraction\": 0.3     } } <p>Then, we generate the bounding boxes of the patches on which Baysor will be run. Here, the patches have a width and height of 3000 microns and an overlap of 50 microns. We advise bigger sizes for real datasets (see our default parameters in one of our config files). On the toy dataset, this will generate 1 patch.</p> In\u00a0[6]: Copied! <pre>baysor_temp_dir = \"tuto.zarr/.sopa_cache/baysor\"\n\npatches = sopa.segmentation.Patches2D(sdata, points_key, patch_width=3000, patch_overlap=50)\nvalid_indices = patches.patchify_transcripts(baysor_temp_dir, config=config)\n</pre> baysor_temp_dir = \"tuto.zarr/.sopa_cache/baysor\"  patches = sopa.segmentation.Patches2D(sdata, points_key, patch_width=3000, patch_overlap=50) valid_indices = patches.patchify_transcripts(baysor_temp_dir, config=config) <pre>[INFO] (sopa.segmentation.patching) Writing sub-CSV for baysor\n</pre> <pre>[########################################] | 100% Completed | 208.89 ms\n</pre> <pre>[INFO] (sopa.segmentation.patching) Patches saved in directory tuto.zarr/.sopa_cache/baysor\n</pre> <p>Now, we can run Baysor on each individual patch.</p> <p>NB: depending on you Baysor installation, you may need to update the <code>baysor_executable_path</code> variable to locate the Baysor binary executable</p> In\u00a0[7]: Copied! <pre>import subprocess\n\nbaysor_executable_path = \"~/.julia/bin/baysor\"\n</pre> import subprocess  baysor_executable_path = \"~/.julia/bin/baysor\" In\u00a0[\u00a0]: Copied! <pre>for patch_index in valid_indices:\n    command = f\"\"\"\n    cd {baysor_temp_dir}/{patch_index}\n    {baysor_executable_path} run --save-polygons GeoJSON -c config.toml transcripts.csv\n    \"\"\"\n    subprocess.run(command, shell=True)\n</pre> for patch_index in valid_indices:     command = f\"\"\"     cd {baysor_temp_dir}/{patch_index}     {baysor_executable_path} run --save-polygons GeoJSON -c config.toml transcripts.csv     \"\"\"     subprocess.run(command, shell=True) <p>At this stage, you executed 4 times Baysor (once per patch). Now, we need to resolve the conflict, i.e. where boundaries are overlapping due to segmentation on multiple patches:</p> In\u00a0[\u00a0]: Copied! <pre>from sopa.segmentation.baysor.resolve import resolve\n\nresolve(sdata, baysor_temp_dir, gene_column, min_area=500)\n</pre> from sopa.segmentation.baysor.resolve import resolve  resolve(sdata, baysor_temp_dir, gene_column, min_area=500) In\u00a0[10]: Copied! <pre>aggregator = sopa.segmentation.Aggregator(sdata, image_key=image_key, shapes_key=shapes_key)\n\naggregator.update_table(gene_column=gene_column, average_intensities=True)\n</pre> aggregator = sopa.segmentation.Aggregator(sdata, image_key=image_key, shapes_key=shapes_key)  aggregator.update_table(gene_column=gene_column, average_intensities=True) <pre>[INFO] (sopa.segmentation.aggregate) Aggregating transcripts over 321 cells\n</pre> <pre>[########################################] | 100% Completed | 106.10 ms\n</pre> <pre>[INFO] (sopa.segmentation.aggregate) Averaging channels intensity over 321 cells with expansion 0.0\n</pre> <pre>[########################################] | 100% Completed | 105.83 ms\n</pre> In\u00a0[11]: Copied! <pre>sdata\n</pre> sdata Out[11]: <pre>SpatialData object with:\n\u251c\u2500\u2500 Images\n\u2502     \u2514\u2500\u2500 'image': SpatialImage[cyx] (4, 2048, 2048)\n\u251c\u2500\u2500 Points\n\u2502     \u2514\u2500\u2500 'transcripts': DataFrame with shape: (&lt;Delayed&gt;, 3) (2D points)\n\u251c\u2500\u2500 Shapes\n\u2502     \u251c\u2500\u2500 'cellpose_boundaries': GeoDataFrame shape: (321, 1) (2D shapes)\n\u2502     \u251c\u2500\u2500 'cells': GeoDataFrame shape: (400, 1) (2D shapes)\n\u2502     \u2514\u2500\u2500 'sopa_patches': GeoDataFrame shape: (4, 2) (2D shapes)\n\u2514\u2500\u2500 Table\n      \u2514\u2500\u2500 AnnData object with n_obs \u00d7 n_vars = 321 \u00d7 5\n    obs: 'region', 'slide', 'cell_id'\n    uns: 'sopa_attrs', 'spatialdata_attrs'\n    obsm: 'intensities', 'spatial': AnnData (321, 5)\nwith coordinate systems:\n\u25b8 'global', with elements:\n        image (Images), transcripts (Points), cellpose_boundaries (Shapes), cells (Shapes), sopa_patches (Shapes)</pre> <p>Now, <code>sdata.table</code> is an <code>AnnData</code> object.</p> <ul> <li>If you count the transcripts, then <code>adata.X</code> are the raw counts</li> <li>If you average the channel intensities, then <code>adata.X</code> are the channels intensities</li> <li>If you both count the transcript and average the intensities, then <code>adata.X</code> are the raw counts, and <code>adata.obsm[\"intensities\"]</code> are the channels intensities</li> </ul> In\u00a0[6]: Copied! <pre>from sopa.annotation.tangram import tangram_annotate\nimport anndata\n</pre> from sopa.annotation.tangram import tangram_annotate import anndata In\u00a0[\u00a0]: Copied! <pre>adata_reference = anndata.read_h5ad(\"adata_reference.h5ad\")\n\ntangram_annotate(sdata, adata_reference, \"cell_type\")\n</pre> adata_reference = anndata.read_h5ad(\"adata_reference.h5ad\")  tangram_annotate(sdata, adata_reference, \"cell_type\") In\u00a0[12]: Copied! <pre>from sopa.annotation import higher_z_score\n\nmarker_cell_dict = {\n    \"CK\": \"Tumoral cell\",\n    \"CD20\": \"B cell\",\n    \"CD3\": \"T cell\"\n}\n\nhigher_z_score(sdata.table, marker_cell_dict)\n</pre> from sopa.annotation import higher_z_score  marker_cell_dict = {     \"CK\": \"Tumoral cell\",     \"CD20\": \"B cell\",     \"CD3\": \"T cell\" }  higher_z_score(sdata.table, marker_cell_dict) <pre>[INFO] (sopa.annotation.fluorescence) Annotation counts: cell_type\nB cell          110\nT cell          106\nTumoral cell    105\nName: count, dtype: int64\n</pre> In\u00a0[13]: Copied! <pre>sopa.io.write_report(\"report.html\", sdata)\n</pre> sopa.io.write_report(\"report.html\", sdata) <pre>[INFO] (sopa.io.report.generate) Writing general section\n[INFO] (sopa.io.report.generate) Writing cell section\n[INFO] (sopa.io.report.generate) Writing channel section\n[INFO] (sopa.io.report.generate) Writing transcript section\n[INFO] (sopa.io.report.generate) Writing representation section\n[INFO] (sopa.io.report.generate) Computing UMAP on 321 cells\n/Users/quentinblampey/Library/Caches/pypoetry/virtualenvs/sopa-hDHgkEug-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n/Users/quentinblampey/Library/Caches/pypoetry/virtualenvs/sopa-hDHgkEug-py3.10/lib/python3.10/site-packages/scanpy/plotting/_tools/scatterplots.py:394: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n  cax = scatter(\n[INFO] (sopa.io.report.generate) Writing report to report.html\n</pre> In\u00a0[14]: Copied! <pre>sopa.io.explorer.write(\"tuto.explorer\", sdata, image_key, points_key=points_key, gene_column=gene_column)\n</pre> sopa.io.explorer.write(\"tuto.explorer\", sdata, image_key, points_key=points_key, gene_column=gene_column) <pre>[INFO] (sopa.io.explorer.table) Writing table with 5 columns\n[INFO] (sopa.io.explorer.table) Writing 3 cell categories: region, slide, cell_type\n[INFO] (sopa.io.explorer.shapes) Writing 321 cell polygons\n[INFO] (sopa.io.explorer.points) Writing 20000 transcripts\n[INFO] (sopa.io.explorer.points)    &gt; Level 0: 20000 transcripts\n[INFO] (sopa.io.explorer.points)    &gt; Level 1: 5000 transcripts\n[INFO] (sopa.io.explorer.images) Writing multiscale image with procedure=semi-lazy (load in memory when possible)\n[INFO] (sopa.io.explorer.images)    (Loading image of shape (4, 2048, 2048)) in memory\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 2048, 2048)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 1024, 1024)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 512, 512)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 256, 256)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 128, 128)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 64, 64)\n[INFO] (sopa.io.explorer.converter) Saved files in the following directory: tuto.explorer\n[INFO] (sopa.io.explorer.converter) You can open the experiment with 'open tuto.explorer/experiment.xenium'\n</pre> <p>If you have downloaded the Xenium Explorer, you can now open the results in the explorer: <code>open tuto.explorer/experiment.xenium</code> (if using a Unix operating system), or double-click on the latter file.</p> In\u00a0[15]: Copied! <pre>import spatialdata_plot\n</pre> import spatialdata_plot In\u00a0[16]: Copied! <pre>sdata\\\n    .pl.render_points(size=0.01)\\\n    .pl.render_images(channel=[\"CD20\", \"CK\", \"CD3\"])\\\n    .pl.show()\n</pre> sdata\\     .pl.render_points(size=0.01)\\     .pl.render_images(channel=[\"CD20\", \"CK\", \"CD3\"])\\     .pl.show() <pre>/Users/quentinblampey/Library/Caches/pypoetry/virtualenvs/sopa-hDHgkEug-py3.10/lib/python3.10/site-packages/anndata/_core/anndata.py:183: ImplicitModificationWarning: Transforming to str index.\n  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n/Users/quentinblampey/Library/Caches/pypoetry/virtualenvs/sopa-hDHgkEug-py3.10/lib/python3.10/site-packages/spatialdata_plot/pl/render.py:263: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n  _cax = ax.scatter(\n</pre>"},{"location":"tutorials/api_usage/#save-the-spatialdata-object","title":"Save the <code>SpatialData</code> object\u00b6","text":"<p>For this tutorial, we use a generated dataset. The command below will generate and save it on disk (you can change the path <code>tuto.zarr</code> to save it somewhere else).</p> <p>See the commented lines below to load your own data, or see the <code>sopa.io</code> API.</p>"},{"location":"tutorials/api_usage/#segmentation","title":"Segmentation\u00b6","text":""},{"location":"tutorials/api_usage/#option-1-cellpose","title":"Option 1: Cellpose\u00b6","text":""},{"location":"tutorials/api_usage/#sequential-running","title":"Sequential running\u00b6","text":"<p>If desired, you can run Cellpose sequentially, as in the lines below, but this is slower than the \"Parallel running\" section below.</p>"},{"location":"tutorials/api_usage/#parallel-running","title":"Parallel running\u00b6","text":"<p>Here, we show how to run Cellpose in parallel for all the patches. It's up to you to choose the way to parallelize it: for instance, if you have a Slurm cluster, you can run one job per patch.</p> <p>First, we generate the bounding boxes of the patches on which Cellpose will be run. Here, the patches have a width and height of 1500 pixels and an overlap of 50 pixels. We advise bigger sizes for real datasets (see our default parameters in one of our config files). On the toy dataset, this will generate 4 patches.</p>"},{"location":"tutorials/api_usage/#option-2-baysor","title":"Option 2: Baysor\u00b6","text":""},{"location":"tutorials/api_usage/#aggregate","title":"Aggregate\u00b6","text":"<p>This mandatory step turns the data into an <code>AnnData</code> object. We can count the transcript inside each cell, and/or average each channel intensity inside each cell boundary.</p> <p>NB: Baysor already counts the transcripts inside each cell to create a cell-by-gene table, so you don't need to provide <code>gene_column</code></p>"},{"location":"tutorials/api_usage/#annotation","title":"Annotation\u00b6","text":""},{"location":"tutorials/api_usage/#option-1-transcript-based-tangram","title":"Option 1: Transcript-based (Tangram)\u00b6","text":"<p>Tangram is a transcript-based annotation that uses an annotated single-cell reference. Let's suppose your reference <code>AnnData</code> object is stored in a file called <code>adata_reference.h5ad</code> (preferably, keep raw counts), and the cell type is in <code>adata.obs[\"cell_type\"]</code>. Then, you can annotate your spatial data as follows:</p>"},{"location":"tutorials/api_usage/#option-2-staining-based","title":"Option 2: Staining-based\u00b6","text":"<p>For now, our fluorescence-based annotation is very simple. We provide a dictionary where a channel is associated with a population. Then, each cell is associated with the cell type whose corresponding channel is the brightest (according to a certain Z-score). In this tutorial example, we can annotate Tumoral cells, T cells, and B cells:</p>"},{"location":"tutorials/api_usage/#pipeline-report","title":"Pipeline report\u00b6","text":"<p>You can optionally create an HTML report of the pipeline run (in the example below, we save it under <code>report.html</code>). It contains some quality controls for your data.</p>"},{"location":"tutorials/api_usage/#visualization","title":"Visualization\u00b6","text":""},{"location":"tutorials/api_usage/#with-the-xenium-explorer","title":"With the Xenium Explorer\u00b6","text":"<p>The Xenium Explorer is a software developed by 10X Genomics for visualizing spatial data, and it can be downloaded freely here. Sopa allows the conversion to the Xenium Explorer, whatever the type of spatial data you worked on. It will create some files under a new <code>tuto.explorer</code> directory:</p>"},{"location":"tutorials/api_usage/#with-spatialdata-plot","title":"With <code>spatialdata-plot</code>\u00b6","text":"<p><code>spatialdata-plot</code> library is a static plotting library for <code>SpatialData</code> objects</p>"},{"location":"tutorials/api_usage/#further-analyses","title":"Further analyses\u00b6","text":"<ul> <li>You can read this tutorial on spatial statistic and geometric analysis.</li> <li>You can use Squidpy which operates on both the <code>SpatialData</code> object or the <code>AnnData</code> object, or use other tools of the <code>scverse</code> ecosystem such as <code>Scanpy</code>.</li> <li>You can also try the CLI or the Snakemake pipeline of Sopa.</li> </ul>"},{"location":"tutorials/cli_usage/","title":"CLI usage","text":"<p>Here, we provide a minimal example of command line usage. For more details and to learn about other optional arguments, refer to the full CLI documentation.</p>"},{"location":"tutorials/cli_usage/#save-the-spatialdata-object","title":"Save the <code>SpatialData</code> object","text":"<p>For this tutorial, we use a generated dataset. The command below will generate and save it on disk (you can change the path <code>tuto.zarr</code> to save it somewhere else). If you want to load your own data: choose the right panel below, or see the <code>sopa read</code> CLI documentation.</p> TutorialXeniumMERSCOPECosMXPhenoCyclerMACSimaHyperion <pre><code># it will generate a 'tuto.zarr' directory\nsopa read . --sdata-path tuto.zarr --technology uniform\n</code></pre> <pre><code># it will generate a '/path/to/sample/directory.zarr' directory\nsopa read /path/to/sample/directory --technology xenium\n</code></pre> <pre><code># it will generate a '/path/to/sample/directory.zarr' directory\nsopa read /path/to/sample/directory --technology merscope\n</code></pre> <pre><code># it will generate a '/path/to/sample/directory.zarr' directory\nsopa read /path/to/sample/directory --technology cosmx\n</code></pre> <p>Warning</p> <p>The CosMX data requires stitching the FOVs. It will be added soon, see this issue.</p> <pre><code># it will generate a '/path/to/sample.zarr' directory\nsopa read /path/to/sample.qptiff --technology phenocycler\n</code></pre> <pre><code># it will generate a '/path/to/sample/directory.zarr' directory\nsopa read /path/to/sample/directory --technology macsima\n</code></pre> <pre><code># it will generate a '/path/to/sample/directory.zarr' directory\nsopa read /path/to/sample/directory --technology hyperion\n</code></pre> <p>Info</p> <p>It has created a <code>.zarr</code> directory which stores a <code>SpatialData</code> object corresponding to your data sample. You can choose the location of the <code>.zarr</code> directory using the <code>--sdata-path</code> command line argument.</p>"},{"location":"tutorials/cli_usage/#optional-roi-selection","title":"(Optional) ROI selection","text":"<p>Sometimes, your slide may contain a region with low-quality data, and we want to run the analysis only on the good-quality region. For this, we can interactively select a region of interest (ROI), and Sopa will only run on the selected ROI.</p> If working locallyIf working on a machine without interactive mode <p>Run the following command line and follow the instructions displayed in the console: <pre><code>sopa crop --sdata-path tuto.zarr --channels DAPI\n</code></pre></p> <p>When interactive mode is unavailable, the ROI selection will be performed in three steps.</p> <ol> <li> <p>On the machine where the data is stored, save a light view of the original image (here, it will create a file called <code>image.zarr.zip</code>): <pre><code>sopa crop --sdata-path tuto.zarr --channels DAPI --intermediate-image image.zarr.zip\n</code></pre></p> </li> <li> <p>Download the <code>image.zip</code> file locally (or on a machine with interactive mode), and select the ROI. Here, it will create a file called <code>roi.zarr.zip</code>: <pre><code>sopa crop --intermediate-image image.zarr.zip --intermediate-polygon roi.zarr.zip\n</code></pre></p> </li> <li> <p>Upload the <code>roi.zarr.zip</code> file, and save it inside the <code>SpatialData</code> object: <pre><code>sopa crop --sdata-path tuto.zarr --intermediate-polygon roi.zarr.zip\n</code></pre></p> </li> </ol>"},{"location":"tutorials/cli_usage/#run-segmentation","title":"Run segmentation","text":""},{"location":"tutorials/cli_usage/#option-1-cellpose","title":"Option 1: Cellpose","text":"<p>First, generate the bounding boxes of the patches on which Cellpose will be run. Here, the patches have a width and height of 1500 pixels and an overlap of 50 pixels. We advise bigger sizes for real datasets (see our default parameters in one of our config files). On the toy dataset, this will generate 4 patches.</p> <pre><code>sopa patchify image tuto.zarr --patch-width-pixel 1500 --patch-overlap-pixel 50\n</code></pre> <p>Now, we can run Cellpose on each individual patch. Execute the following command line on all <code>patch-index</code> (i.e., <code>0</code>, <code>1</code>, <code>2</code>, and <code>3</code>) to run Cellpose using DAPI only (you can add an additional channel, for instance, <code>--channels DAPI --channels PolyT</code>):</p> <p>Tip</p> <p>Manually running the commands below can involve using many consecutive commands, so we recommend automatizing it. For instance, this can be done using Snakemake or Nextflow. This will help you parallelize it since you can run each task on separate jobs or using multithreading. You can also see how we do it in the Sopa Snakemake pipeline.</p> <p>To automatically get the number of patches, you can either open the <code>tuto.zarr/.sopa_cache/patches_file_image</code> file, or compute <code>len(sdata['sopa_patches'])</code> in Python.</p> Patch 0Patch 1Patch 2Patch 3 <pre><code>sopa segmentation cellpose tuto.zarr \\\n    --channels DAPI \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 0\n</code></pre> <pre><code>sopa segmentation cellpose tuto.zarr \\\n    --channels DAPI \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 1\n</code></pre> <pre><code>sopa segmentation cellpose tuto.zarr \\\n    --channels DAPI \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 2\n</code></pre> <pre><code>sopa segmentation cellpose tuto.zarr \\\n    --channels DAPI \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 3\n</code></pre> <p>Note</p> <p>In the above commands, the <code>--diameter</code> and <code>--min-area</code> parameters are specific to the data type we work on. For your own data, consider using the default parameters from one of our config files. Here, <code>min-area</code> is in pixels^2.</p> <p>At this stage, you executed 4 times Cellpose (once per patch). Now, we need to resolve the conflict, i.e. where boundaries are overlapping due to segmentation on multiple patches: <pre><code>sopa resolve cellpose tuto.zarr\n</code></pre></p>"},{"location":"tutorials/cli_usage/#option-2-baysor","title":"Option 2: Baysor","text":"<p>Baysor needs a config to be executed. You can find official config examples here.</p> <p>Note</p> <p>You can also reuse the Baysor parameter we have defined for each machine, as in our Snakemake config files. Note that, our Snakemake config is a <code>.yaml</code> file, but the Baysor config should still be a <code>.toml</code> file.</p> <p>For this tutorial, we will use the config below. Save this in a <code>config.toml</code> file. <pre><code>[data]\nforce_2d = true\nmin_molecules_per_cell = 10   # min number of transcripts per cell\nx = \"x\"\ny = \"y\"\nz = \"z\"\ngene = \"genes\"\nmin_molecules_per_gene = 0\nmin_molecules_per_segment = 3\nconfidence_nn_id = 6\n\n[segmentation]\nscale = 30                          # typical cell radius\nscale_std = \"25%\"                   # cell radius standard deviation\nprior_segmentation_confidence = 0\nestimate_scale_from_centers = false\nn_clusters = 4\niters = 500\nn_cells_init = 0\nnuclei_genes = \"\"\ncyto_genes = \"\"\nnew_component_weight = 0.2\nnew_component_fraction = 0.3\n</code></pre></p> <p>Then, we generate the bounding boxes of the patches on which Baysor will be run. Here, the patches have a width and height of 1200 microns and an overlap of 50 microns. We advise bigger sizes for real datasets (see our default parameters in one of our config files). On the toy dataset, this will generate 4 patches.</p> <pre><code># config.toml is the Baysor config file you generated above\nsopa patchify baysor tuto.zarr --config-path config.toml --patch-width-microns 1200 --patch-overlap-microns 50\n</code></pre> <p>Now, we can run Baysor on each individual patch. Execute the following command lines to run Baysor on each patch (i.e., <code>0</code>, <code>1</code>, <code>2</code>, and <code>3</code>).</p> <p>Tip</p> <p>Manually running the commands below can involve using many consecutive commands, so we recommend automatizing it. For instance, this can be done using Snakemake or Nextflow. This will help you parallelize it since you can run each task on separate jobs or using multithreading. You can also see how we do it in the Sopa Snakemake pipeline.</p> <p>To automatically get the number of patches, you can open the <code>tuto.zarr/.sopa_cache/patches_file_baysor</code> file. This lists the names of the directories inside <code>tuto.zarr/.sopa_cache/baysor</code> related to each patch. If you selected an ROI, the excluded patches are effectively not in the <code>patches_file_baysor</code> file.</p> Patch 0Patch 1Patch 2Patch 3 <pre><code>cd tuto.zarr/.sopa_cache/baysor_boundaries/0\n\n# 'baysor' is the official baysor executable. If unavailable, replace it with your path to the executable\nbaysor run --save-polygons GeoJSON -c config.toml transcripts.csv\n</code></pre> <pre><code>cd tuto.zarr/.sopa_cache/baysor_boundaries/1\n\n# 'baysor' is the official baysor executable. If unavailable, replace it with your path to the executable\nbaysor run --save-polygons GeoJSON -c config.toml transcripts.csv\n</code></pre> <pre><code>cd tuto.zarr/.sopa_cache/baysor_boundaries/2\n\n# 'baysor' is the official baysor executable. If unavailable, replace it with your path to the executable\nbaysor run --save-polygons GeoJSON -c config.toml transcripts.csv\n</code></pre> <pre><code>cd tuto.zarr/.sopa_cache/baysor_boundaries/3\n\n# 'baysor' is the official baysor executable. If unavailable, replace it with your path to the executable\nbaysor run --save-polygons GeoJSON -c config.toml transcripts.csv\n</code></pre> <p>At this stage, you executed 4 times Baysor (once per patch). Now, we need to resolve the conflict, i.e. where boundaries are overlapping due to segmentation on multiple patches: <pre><code>sopa resolve baysor tuto.zarr --gene-column genes\n</code></pre></p>"},{"location":"tutorials/cli_usage/#aggregation","title":"Aggregation","text":"<p>This mandatory step turns the data into an <code>AnnData</code> object. We can count the transcript inside each cell, and/or average each channel intensity inside each cell boundary.</p> <p>Info</p> <p>The <code>--gene-column</code> option below tells which column contains the gene names inside the transcript dataframe. If you don't know it, you can look to our configs to find the right <code>gene-column</code> corresponding to your machine.</p> Count transcripts + average intensitiesCount transcriptsAverage intensities <pre><code>sopa aggregate tuto.zarr --gene-column genes --average-intensities\n</code></pre> <pre><code>sopa aggregate tuto.zarr --gene-column genes\n</code></pre> <pre><code>sopa aggregate tuto.zarr --average-intensities\n</code></pre> <p>If using Baysor</p> <p>Baysor already counts the transcripts inside each cell to create a cell-by-gene table. So you'll always have this table, and there is no need to use the <code>--gene-column</code> argument. If you don't want to average the intensities, you will still need to run <code>sopa aggregate tuto.zarr</code> before continuing.</p>"},{"location":"tutorials/cli_usage/#annotation","title":"Annotation","text":"<p>If desired, cell-type annotation can be run. Currently, we support Tangram for transcript-based annotation and a simple scoring approach for channel-based annotation (called channel z-score).</p> Tangram annotationChannel Z-score annotation <p>Tangram is a transcript-based annotation that uses an annotated single-cell reference. Let's suppose your reference <code>AnnData</code> object is stored in a file called <code>adata_reference.h5ad</code> (preferably, keep raw counts), and the cell type is in <code>adata.obs[\"cell_type\"]</code>. Then, you can annotate your spatial data as follows: <pre><code>sopa annotate tangram tuto.zarr --sc-reference-path adata_reference.h5ad --cell-type-key cell_type\n</code></pre></p> <p>For now, our fluorescence-based annotation is very simple. We provide a dictionary where a channel is associated with a population. Then, each cell is associated with the cell type whose corresponding channel is the brightest (according to a certain Z-score). In this tutorial example, we can annotate Tumoral cells, T cells, and B cells: <pre><code>sopa annotate fluorescence tuto.zarr --marker-cell-dict '{\"CK\": \"Tumoral cell\", \"CD3\": \"T cell\", \"CD20\": \"B cell\"}'\n</code></pre></p> <p>More complex annotation</p> <p>If you have a large number of channels, it may be preferable to run clustering on your data, for instance, using `Leiden clustering. Then, you can annotate each cluster manually by plotting a heatmap of all channels expressions per cluster.</p>"},{"location":"tutorials/cli_usage/#pipeline-report","title":"Pipeline report","text":"<p>You can optionally create an HTML report of the pipeline run (in the example below, we save it under <code>report.html</code>). It contains some quality controls for your data.</p> <pre><code>sopa report tuto.zarr report.html\n</code></pre>"},{"location":"tutorials/cli_usage/#visualization-xenium-explorer","title":"Visualization (Xenium Explorer)","text":"<p>The Xenium Explorer is a software developed by 10X Genomics for visualizing spatial data, and it can be downloaded freely here. Sopa allows the conversion to the Xenium Explorer, whatever the type of spatial data you worked on. It will create some files under a new <code>tuto.explorer</code> directory:</p> <pre><code>sopa explorer write tuto.zarr --gene-column genes\n</code></pre> <p>If you have downloaded the Xenium Explorer, you can now open the results in the explorer: <code>open tuto.explorer/experiment.xenium</code> (if using a Unix operating system), or double-click on the latter file.</p> <p>Time efficiency</p> <p>Creating the image needed by the Xenium Explorer can be time-consuming. Therefore, we recommend performing one run for the image generation (below) and another to save the transcripts/boundaries/observations. <pre><code># this can be done directly after saving the raw data in a .zarr directory\nsopa explorer write tuto.zarr --mode '+i' --no-save-h5ad\n</code></pre></p> <p>After running everything with Sopa, you can finally save all the other Xenium Explorer input (e.g. boundaries and cell categories): <pre><code># this should be done after aggregation and an eventual annotation\nsopa explorer write tuto.zarr --mode '-i' --gene-column genes\n</code></pre> For more details and customization, refer to the command line helper.</p>"},{"location":"tutorials/cli_usage/#geometric-and-spatial-statistics","title":"Geometric and spatial statistics","text":"<p>All functions to compute geometric and spatial statistics are detailed in the <code>sopa.spatial</code> API. You can also read this tutorial.</p>"},{"location":"tutorials/cli_usage/#further-analyses","title":"Further analyses","text":"<ul> <li>If you are familiar with the <code>spatialdata</code> library, you can directly use the <code>tuto.zarr</code> directory, corresponding to a <code>SpatialData</code> object: <pre><code>import spatialdata\n\nsdata = spatialdata.read_zarr(\"tuto.zarr\")\n</code></pre></li> <li>You can use Squidpy which operates on both the <code>SpatialData</code> object or the <code>AnnData</code> object, or use other tools of the <code>scverse</code> ecosystem such as <code>Scanpy</code>.</li> <li>You can also use the file <code>tuto.explorer/adata.h5ad</code> if you prefer the <code>AnnData</code> object instead of the full <code>SpatialData</code> object.</li> </ul>"},{"location":"tutorials/snakemake/","title":"Snakemake pipeline","text":"<p>Sopa comes with an existing Snakemake pipeline to get started quickly. This will not involve any coding but requires some setup specific to <code>snakemake</code>.</p>"},{"location":"tutorials/snakemake/#install-sopa","title":"Install <code>sopa</code>","text":"<p>Follow the \"Snakemake setup\" instructions of our installation page.</p> <p>Baysor usage</p> <p>Even though <code>pip install -e '.[baysor]'</code> will install some dependencies related to baysor, you still have to install the <code>baysor</code> command line (see the official repository) if you want to use it.</p> <p>If your path to the baysor executable is not the default one (i.e. <code>~/.julia/bin/baysor</code>), update the config described below to provide the right path to the executable.</p>"},{"location":"tutorials/snakemake/#choose-a-config","title":"Choose a config","text":"<p>Our pipeline config is a YAML file that describes all the steps desired for the pipeline. It is flexible; for instance, if you remove the <code>baysor</code> arguments from the config, then it will not run baysor. Similarly, if you remove the <code>\"annotation\"</code> section, it will not run annotation.</p> <p>You can choose a config among the existing ones here or create your own.</p> <p>Note the relative path of your config since you'll need it later, e.g. <code>config/merscope/base.yaml</code>.</p>"},{"location":"tutorials/snakemake/#run-the-pipeline","title":"Run the pipeline","text":"<ol> <li> <p>First, locate the path to one sample's raw experiment file(s). This is usually a directory containing one or many image(s) and, eventually, a transcript file. If you don't know what data you need, see our FAQ.</p> </li> <li> <p>Then, activate your environment that has the snakemake command, and go to the <code>workflow</code> directory inside the <code>sopa</code> directory that you cloned earlier: <pre><code>conda activate sopa    # or an environment that has `snakemake`\ncd workflow            # run this at the root of the 'sopa' directory\n</code></pre></p> </li> <li> <p>You can either execute the pipeline locally or on a high-performance-cluster (choose the right option below)</p> </li> </ol> Local execution (e.g., personal laptop)High-performance-cluster (e.g., Slurm cluster) <p>Most of the time, when executing locally, you'll run the pipeline sequentially, i.e. with one core:</p> <pre><code># replace the configfile with yours\n# replace data_path with the path to your data directory\n\nsnakemake --config data_path=/path/to/directory --configfile=config/merscope/base.yaml --cores 1 --use-conda\n</code></pre> <p>You'll need a cluster profile. For instance, if on a Slurm cluster, it can look like this file. You can create your own in <code>sopa/workflow/&lt;hpc-name&gt;/config.yaml</code>, or simply re-use this file (as in the command below). For more details, see the snakemake documentation on profiles.</p> <pre><code># replace the configfile with yours\n# replace data_path with the path to your data directory\n# replace profile with &lt;hpc-name&gt; as above, or keep 'slurm'\n\nsnakemake --profile slurm --config data_path=/path/to/directory --configfile=config/merscope/base.yaml\n</code></pre> <p>Note</p> <p>You may need to update the params under <code>resources</code> inside the <code>sopa/workflow/Snakefile</code> file, according to the partition names of your cluster.</p> <p>For more customization, see the snakemake CLI documentation.</p>"},{"location":"tutorials/snakemake/#toy-example","title":"Toy example","text":"<p>In the example below, we run the pipeline on a generated toy dataset. Running it locally can help test a new pipeline or config.</p> <p>Make sure you have installed everything as detailed in this tutorial, and then run the following command lines:</p> Cellpose usageBaysor usage <p>Make sure you have installed sopa with the Cellpose extra <pre><code>conda activate sopa    # or an environment that has `snakemake`\ncd workflow            # run this at the root of the 'sopa' directory\n\n# you can replace tuto.zarr by another path where the data will be saved\nsnakemake --config sdata_path=tuto.zarr --configfile=config/toy/uniform_cellpose.yaml --cores 1 --use-conda\n</code></pre></p> <p>Make sure you have installed sopa with the Baysor extra, and that you have installed the <code>baysor</code> command <pre><code>conda activate sopa    # or an environment that has `snakemake`\ncd workflow            # run this at the root of the 'sopa' directory\n\n# replace tuto.zarr by the path where you want the data to be saved\nsnakemake --config sdata_path=tuto.zarr --configfile=config/toy/uniform_baysor.yaml --cores 1 --use-conda\n</code></pre></p> <p>Notes</p> <p>On the above example, it executes snakemake sequentially (one core), which is enough for debugging purposes.</p> <p>You can then check <code>tuto.explorer</code> for output files. Notably, if you have installed the Xenium Explorer, double-click on <code>experiment.xenium</code> to visualize the results.</p>"},{"location":"tutorials/snakemake/#pipeline-outputs","title":"Pipeline outputs","text":"<p>The pipeline outputs consists in two directories located next to your raw data directory. They have the same name as your raw directory, but with extension <code>.zarr</code> and <code>.explorer</code> respectively (see below for more details).</p> <p>Info</p> <p>You can also change the path to the <code>.zarr</code> output, by providing <code>sdata_path=/your/path.zarr</code> just after <code>--config</code> on the snakemake execution line. This will also move the <code>.explorer</code> directory, that will be saved at <code>/your/path.explorer</code></p>"},{"location":"tutorials/snakemake/#spatialdata-directory","title":"<code>SpatialData</code> directory","text":"<p>If you are familiar with the <code>spatialdata</code> library, you can use the <code>.zarr</code> directory, corresponding to a <code>SpatialData</code> object: <pre><code>import spatialdata\n\nsdata = spatialdata.read_zarr(\"/path/to/data.zarr\")\n</code></pre></p>"},{"location":"tutorials/snakemake/#explorer-directory","title":"Explorer directory","text":"<p>The <code>.explorer</code> directory contains the following files:</p> <ul> <li> <p><code>report.html</code> a short quality control of you data, as an HTML report</p> </li> <li> <p><code>adata.h5ad</code> the AnnData object with spatial locations of the cells (see <code>adata.obsm['spatial']</code>), and also cell-by-gene table and/or the cell-by-channel table.</p> </li> <li> <p><code>experiment.xenium</code> the Xenium Explorer file: double-click on it to open it on the Xenium Explorer (download the software here)</p> </li> <li> <p>The other files are data files related and required by the Xenium Explorer</p> </li> </ul>"},{"location":"tutorials/snakemake/#create-your-own-config","title":"Create your own config","text":"<p>If the existing <code>config</code> files are not suited for your project, you can update an existing one or create a whole new one. For this, use this commented config to understand the purpose of each argument. Note that some sections are optional: in this case, remove the section or the argument, and Sopa will not run it.</p> <p>When running snakemake, you will then need to provide the relative or absolute path to your <code>.yaml</code> config, for instance <code>--configfile=/path/to/your/config.yaml</code>.</p>"},{"location":"tutorials/spatial/","title":"Spatial statistics","text":"In\u00a0[1]: Copied! <pre>import anndata\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport sopa\nimport sopa.spatial\n\nheatmap_kwargs = {\"vmax\": 40, \"cmap\": sns.cm.rocket_r, \"cbar_kws\": {'label': 'Mean hop distance'}}\n</pre> import anndata import seaborn as sns import matplotlib.pyplot as plt  import sopa import sopa.spatial  heatmap_kwargs = {\"vmax\": 40, \"cmap\": sns.cm.rocket_r, \"cbar_kws\": {'label': 'Mean hop distance'}} In\u00a0[2]: Copied! <pre>adata = anndata.read_h5ad(\"adata_liver_merscope.h5ad\")\n</pre> adata = anndata.read_h5ad(\"adata_liver_merscope.h5ad\") <p>Then, compute the Delaunay graph on your data. Especially, use the <code>radius</code> argument to drop long edges. In this examples, edges longer than 50 microns are removed.</p> <p>The later function comes from Squidpy.</p> In\u00a0[3]: Copied! <pre>sopa.spatial.spatial_neighbors(adata, radius=[0, 50])\n</pre> sopa.spatial.spatial_neighbors(adata, radius=[0, 50]) <pre>[INFO] (sopa.spatial._build) Computing delaunay graph\n</pre> In\u00a0[4]: Copied! <pre>cell_type_to_cell_type = sopa.spatial.mean_distance(adata, \"cell_type\", \"cell_type\")\n</pre> cell_type_to_cell_type = sopa.spatial.mean_distance(adata, \"cell_type\", \"cell_type\") <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 28/28 [00:08&lt;00:00,  3.37it/s]\n</pre> In\u00a0[5]: Copied! <pre>plt.figure(figsize=(7, 6))\nsns.heatmap(cell_type_to_cell_type, **heatmap_kwargs)\n</pre> plt.figure(figsize=(7, 6)) sns.heatmap(cell_type_to_cell_type, **heatmap_kwargs) Out[5]: <pre>&lt;Axes: xlabel='cell_type', ylabel='cell_type'&gt;</pre> <p>Similary, you can compute the mean hop-distance between all pairs of cell-types and niches:</p> In\u00a0[6]: Copied! <pre>cell_type_to_niche = sopa.spatial.mean_distance(adata, \"cell_type\", \"niches\")\n</pre> cell_type_to_niche = sopa.spatial.mean_distance(adata, \"cell_type\", \"niches\") <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:02&lt;00:00,  3.28it/s]\n</pre> In\u00a0[7]: Copied! <pre>plt.figure(figsize=(3, 6))\nsns.heatmap(cell_type_to_niche, **heatmap_kwargs)\n</pre> plt.figure(figsize=(3, 6)) sns.heatmap(cell_type_to_niche, **heatmap_kwargs) Out[7]: <pre>&lt;Axes: xlabel='niches', ylabel='cell_type'&gt;</pre> <p>Same between niches and niches:</p> In\u00a0[8]: Copied! <pre>niche_to_niche = sopa.spatial.mean_distance(adata, \"niches\")\n</pre> niche_to_niche = sopa.spatial.mean_distance(adata, \"niches\") <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:02&lt;00:00,  3.25it/s]\n</pre> In\u00a0[9]: Copied! <pre>plt.figure(figsize=(3, 3))\nsns.heatmap(niche_to_niche, **heatmap_kwargs)\n</pre> plt.figure(figsize=(3, 3)) sns.heatmap(niche_to_niche, **heatmap_kwargs) Out[9]: <pre>&lt;Axes: xlabel='niches', ylabel='niches'&gt;</pre> In\u00a0[10]: Copied! <pre>gdf = sopa.spatial.geometrize_niches(adata, \"niches\")\ngdf\n</pre> gdf = sopa.spatial.geometrize_niches(adata, \"niches\") gdf Out[10]: geometry niches length area roundness 0 POLYGON ((11256.961 7834.639, 11257.304 7835.6... Bile duct 371.136469 6941.104125 0.633244 3 POLYGON ((11122.354 8163.108, 11123.162 8163.7... Bile duct 393.638585 5539.287922 0.449230 6 POLYGON ((10936.163 381.622, 10936.478 381.898... Bile duct 1595.710237 24099.793633 0.118936 8 POLYGON ((11021.489 747.492, 11019.723 748.834... Bile duct 561.516074 5763.341860 0.229699 17 POLYGON ((11042.181 3981.166, 11043.124 3980.8... Bile duct 584.173216 6296.007422 0.231842 ... ... ... ... ... ... 2292 POLYGON ((2805.196 4508.688, 2805.687 4509.714... Vascular 589.849425 13760.673500 0.497012 2370 POLYGON ((459.355 560.935, 460.631 562.344, 46... Vascular 727.372986 7949.503667 0.188815 2378 POLYGON ((192.733 4605.956, 193.558 4606.628, ... Vascular 601.631439 8236.973094 0.285967 2388 POLYGON ((78.743 2939.361, 79.118 2940.362, 80... Vascular 390.753989 8232.263635 0.677520 2390 POLYGON ((10.051 4012.561, 10.497 4013.717, 18... Vascular 395.425837 9050.534716 0.727368 <p>118 rows \u00d7 5 columns</p> <p>Now, each occurence (or connected component) of each niche category is a Polygon. On this example, the Necrosis niche has 3 components, as shown below.</p> In\u00a0[11]: Copied! <pre>legend_kwds = {\"bbox_to_anchor\": (1.04, 0.5), \"loc\": \"center left\", \"borderaxespad\": 0, \"frameon\": False, \"title\": \"Niches\"}\n\ngdf.plot(column=\"niches\", legend=True, legend_kwds=legend_kwds)\n</pre> legend_kwds = {\"bbox_to_anchor\": (1.04, 0.5), \"loc\": \"center left\", \"borderaxespad\": 0, \"frameon\": False, \"title\": \"Niches\"}  gdf.plot(column=\"niches\", legend=True, legend_kwds=legend_kwds) Out[11]: <pre>&lt;Axes: &gt;</pre> In\u00a0[12]: Copied! <pre>df_niches_geometries = sopa.spatial.niches_geometry_stats(adata, \"niches\")\ndf_niches_geometries\n</pre> df_niches_geometries = sopa.spatial.niches_geometry_stats(adata, \"niches\") df_niches_geometries <pre>[INFO] (sopa.spatial.morpho) Computing pairwise distances between 118 components\n/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/geopandas/geoseries.py:660: FutureWarning: Returning a DataFrame from Series.apply when the supplied function returns a Series is deprecated and will be removed in a future version.\n  result = super().apply(func, args=args, **kwargs)\n</pre> Out[12]: n_components length area roundness min_distance_to_niche_Bile duct min_distance_to_niche_Lymphoid structure min_distance_to_niche_Necrosis min_distance_to_niche_Stroma min_distance_to_niche_Stromal border min_distance_to_niche_Tumour min_distance_to_niche_Tumour-myeloid min_distance_to_niche_Vascular niches Bile duct 53 871.163413 1.968860e+04 0.337805 0.000000 2380.538268 1449.461569 73.698113 606.466864 503.188672 1458.109531 554.878833 Lymphoid structure 2 1036.895946 6.074089e+04 0.655267 99.283752 0.000000 1293.705232 0.000000 484.004416 288.855609 778.042413 727.563948 Necrosis 3 14679.900601 1.859571e+06 0.144873 215.188214 2613.268586 0.000000 0.000000 530.994922 24.705659 0.000000 206.323638 Stroma 1 159551.459121 2.385822e+07 0.011777 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 Stromal border 10 32107.645354 1.562288e+06 0.023618 1282.747393 4533.620464 1263.667065 356.928689 0.000000 0.000000 624.666420 365.469128 Tumour 8 22964.491358 6.363175e+06 0.178266 258.930767 2124.252221 433.590282 2.529358 40.851952 0.000000 257.084459 121.688532 Tumour-myeloid 13 5625.146904 2.741475e+05 0.116237 531.479998 3349.152789 603.320975 0.000000 332.532881 79.196333 0.000000 694.707711 Vascular 28 808.856057 2.111648e+04 0.403680 1065.886005 3766.261346 1702.920627 401.167661 477.280906 283.654705 1370.371248 0.000000 In\u00a0[13]: Copied! <pre>fig, axes = plt.subplots(1, 4, figsize=(15, 6))\n\nfor i, name in enumerate([\"n_components\", \"length\", \"area\", \"roundness\"]):\n    vmax = df_niches_geometries[name].sort_values()[-2:].mean()\n    sns.heatmap(df_niches_geometries[[name]], cmap=\"viridis\", annot=True, fmt=\".2f\", vmax=vmax, ax=axes[i])\n\nplt.subplots_adjust(wspace=1.5)\n</pre> fig, axes = plt.subplots(1, 4, figsize=(15, 6))  for i, name in enumerate([\"n_components\", \"length\", \"area\", \"roundness\"]):     vmax = df_niches_geometries[name].sort_values()[-2:].mean()     sns.heatmap(df_niches_geometries[[name]], cmap=\"viridis\", annot=True, fmt=\".2f\", vmax=vmax, ax=axes[i])  plt.subplots_adjust(wspace=1.5) In\u00a0[14]: Copied! <pre>import networkx as nx\nfrom community import community_louvain\nfrom netgraph import Graph\n</pre> import networkx as nx from community import community_louvain from netgraph import Graph In\u00a0[15]: Copied! <pre>weights, node_color, node_size, node_shape = sopa.spatial.prepare_network(adata, \"cell_type\", \"niches\")\n</pre> weights, node_color, node_size, node_shape = sopa.spatial.prepare_network(adata, \"cell_type\", \"niches\") <pre>[INFO] (sopa.spatial.distance) Computing all distances for the 4 pairs of categories\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 28/28 [00:07&lt;00:00,  3.61it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:02&lt;00:00,  3.69it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 28/28 [00:07&lt;00:00,  3.52it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:02&lt;00:00,  3.48it/s]\n</pre> In\u00a0[16]: Copied! <pre>g = nx.from_pandas_adjacency(weights)\nnode_to_community = community_louvain.best_partition(g, resolution=1.35)\n</pre> g = nx.from_pandas_adjacency(weights) node_to_community = community_louvain.best_partition(g, resolution=1.35) In\u00a0[17]: Copied! <pre>Graph(g,\n      node_size=node_size,\n      node_color=node_color,\n      node_shape=node_shape,\n      node_edge_width=0,\n      node_layout='community',\n      node_layout_kwargs=dict(node_to_community=node_to_community),\n      node_labels=True,\n      node_label_fontdict=dict(size=6, weight=\"bold\"),\n      edge_alpha=1,\n      edge_width=0.5,\n      edge_layout_kwargs=dict(k=2000),\n      edge_layout='bundled',\n)\n</pre> Graph(g,       node_size=node_size,       node_color=node_color,       node_shape=node_shape,       node_edge_width=0,       node_layout='community',       node_layout_kwargs=dict(node_to_community=node_to_community),       node_labels=True,       node_label_fontdict=dict(size=6, weight=\"bold\"),       edge_alpha=1,       edge_width=0.5,       edge_layout_kwargs=dict(k=2000),       edge_layout='bundled', ) <pre>/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/netgraph/_edge_layout.py:978: RuntimeWarning: invalid value encountered in divide\n  displacement = compatibility * delta / distance_squared[..., None]\n/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/netgraph/_utils.py:360: RuntimeWarning: invalid value encountered in divide\n  v = v / np.linalg.norm(v, axis=-1)[:, None] # unit vector\n</pre> Out[17]: <pre>&lt;netgraph._main.Graph at 0x2b1668fd0&gt;</pre>"},{"location":"tutorials/spatial/#1-prepare-your-data","title":"1. Prepare your data\u00b6","text":"<p>You'll need the <code>AnnData</code> output of Sopa. If using the <code>SpatialData</code> object itself, simply extract the table.</p> <p>Make sure you have at least a cell-type annotation (i.e. a column in <code>adata.obs</code> corresponding to cell-types), and eventually a niche annotation (with algorithms such as STAGATE).</p>"},{"location":"tutorials/spatial/#optional-download-the-tutorial-data","title":"(Optional) Download the tutorial data\u00b6","text":"<p>The <code>.h5ad</code> file used in this tutorial is publicly available on Zenodo here.</p>"},{"location":"tutorials/spatial/#2-distances-between-cell-categories","title":"2. Distances between cell categories\u00b6","text":"<p>You can compute the mean hop-distance between all pairs of cell-types:</p> <p>Below, <code>'cell_type'</code> is the name of the column of <code>adata.obs</code> containing the cell-type annotation</p>"},{"location":"tutorials/spatial/#3-transform-niches-into-shapes","title":"3. Transform niches into shapes\u00b6","text":"<p>If desired, niches can be transformed into Shapely geometries. Each occurence of a specific niche will correspond to one Polygon. This makes efficient further operations on niches, such as the one in the next section.</p>"},{"location":"tutorials/spatial/#4-niches-geometries","title":"4. Niches geometries\u00b6","text":"<p>For each niche, we can compute geometric properties. Here, we computed some simple properties of each niche: their mean length (or perimeter), their mean area, and their mean roundness (score between 0 and 1, where high values means \"circle\"-like shape).</p> <p>NB: Since one niche can be divided into multiple connected components (or multiple occurences), we indeed need to average the above geometric properties over all connected components of one niche category</p>"},{"location":"tutorials/spatial/#5-cell-type-niche-network","title":"5. Cell-type / Niche network\u00b6","text":"<p>The distances between cell-types and/or niches can be summerized into one network, and plot with the Netgraph library. It provides a quick overview of the interactions happening in the micro-environment of one slide.</p> <p>To continue, you'll need to install Louvain and Netgraph:</p> <pre>!pip install python-louvain\n!pip install netgraph\n</pre>"}]}